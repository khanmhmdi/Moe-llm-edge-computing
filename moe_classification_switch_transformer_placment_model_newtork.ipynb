{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP7tGLHVMfDWYxob3hApRln",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khanmhmdi/Moe-llm-edge-computing/blob/main/moe_classification_switch_transformer_placment_model_newtork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w42BfQzfGsBb",
        "outputId": "8dffda50-7b6e-495d-d0bb-f169e17b3039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 13.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 510kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.94MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.18MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "\n",
            "--- Training Base MoE Model ---\n",
            "Train Epoch: 1 [0/60000]\n",
            "  Loss: 2.297522\n",
            "Train Epoch: 1 [6400/60000]\n",
            "  Loss: 0.366794\n",
            "Train Epoch: 1 [12800/60000]\n",
            "  Loss: 0.178432\n",
            "Train Epoch: 1 [19200/60000]\n",
            "  Loss: 0.115791\n",
            "Train Epoch: 1 [25600/60000]\n",
            "  Loss: 0.094710\n",
            "Train Epoch: 1 [32000/60000]\n",
            "  Loss: 0.105120\n",
            "Train Epoch: 1 [38400/60000]\n",
            "  Loss: 0.161633\n",
            "Train Epoch: 1 [44800/60000]\n",
            "  Loss: 0.068199\n",
            "Train Epoch: 1 [51200/60000]\n",
            "  Loss: 0.095102\n",
            "Train Epoch: 1 [57600/60000]\n",
            "  Loss: 0.041967\n",
            "Epoch 1 - Base Model Train Loss: 0.2030, Accuracy: 96.04%\n",
            "Base Model Test - Loss: 0.0701, Accuracy: 97.91%\n",
            "Block1 Dist (%): 50.0 0.0 0.0 0.0 0.0 0.0 50.0 0.0\n",
            "Block2 Dist (%): 0.0 50.0 0.0 42.3 0.0 0.0 7.7 0.0\n",
            "Base model saved to moe_mnist_balanced.pth.\n",
            "\n",
            "--- Training Placement Selector with Dynamic Topologies ---\n",
            "\n",
            "=== Epoch 1 ===\n",
            "Topology: Server(0.0) -> Devices[54.73470458907612, 95.63477400877034, 91.72978536573471, 99.37903113266981, 77.07910920036406, 80.85364434673137, 60.354908472654245, 64.63539449200837, 21.230958178199682, 74.63457060525377, 95.23733151791993, 24.996998643681607, 16.785834023764288, 77.17796094034598, 61.09424996147834, 54.09877538163841, 71.0677949213474, 94.95517268276664, 11.004849705510935, 49.206884631135246, 72.66389231749066, 67.39065234515706, 84.96500898628294, 59.243971520267245, 71.5648275671233, 75.14898500268191, 93.77361298170317, 31.475758926645806, 97.16847724796996, 49.65591829699514, 97.09839702375369, 87.41318516077673, 24.93540217298987, 61.03514230730377, 39.49088930313603, 95.92775643950358, 15.439051263327993, 70.06147524257943, 16.62406185230458, 77.92887849890573, 41.781626527075574, 57.56317161594734, 70.29049137075307, 49.960755117302824, 58.626410147467574, 89.30548465965559, 24.90308604108032, 85.52814042893253, 17.790733066773548, 96.173724651492, 84.12849152415806, 17.365534780320225, 98.19901982782805, 13.610478935855184, 65.28122393268995, 11.468335481913384, 79.97394515491087, 72.5912726318159, 97.09261466257023, 66.99158609217332, 37.3269598226656, 23.814569659975092, 16.53643445839926, 51.76607629722385, 11.439350166505246, 90.74129016490694, 33.017265297294564, 77.63921948358518, 52.82923010394866, 15.506880840626838, 51.10847821842293, 31.18260019342661, 98.46310107957916, 73.6648960787845, 90.5185168328001, 31.91722887616077, 71.14310030093195, 92.72131361160207, 56.50847685000915, 26.84722120195209, 45.15280414758737, 47.66828476532647, 72.62103509679113, 17.452422445941558, 12.713265854028698, 15.926889631604517, 75.16130905359896, 78.1136986900942, 10.476050735133866, 30.203880546889373, 89.99245464202541, 85.36243427786575, 69.6019965626835, 45.65650738511106, 99.6415102230367, 44.710831254779094, 26.83395052370637, 32.40066272917974, 90.61597701652305, 46.79880369518224]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-b56b333a06e0>:575: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  frozen_model.load_state_dict(torch.load(base_model_path, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Avg Loss: 23.6999, Accuracy: 56.89%\n",
            "Test on Topology: Server(0.0) -> Devices[62.609382515048075, 26.269712598076772, 44.577713458034864, 20.997381137930688, 45.409910440027566, 62.22075194963026, 76.17380442038989, 20.935885091402785, 99.11945550191179, 26.67405254444187, 88.83837554783396, 35.64235604278319, 43.488867153806815, 55.542833241068024, 31.974411276774546, 87.86594675046815, 32.29806184027448, 45.130979161431824, 55.74298945721101, 27.010539931626163, 53.08573303388902, 93.91441905595092, 77.12614485321669, 42.63751326662366, 70.46801907085819, 18.129118647612263, 17.89511304040232, 55.841184704269295, 39.14373714804305, 82.33049784400573, 36.59403516819238, 60.89631715639887, 97.56481550788334, 70.26761914466461, 15.558392374600801, 58.99453530165964, 66.4521497385991, 57.24895282451093, 74.9060293921244, 24.874021581255995, 52.53230674363054, 18.37453607998247, 80.96631175614677, 54.636341748586986, 87.48772422433788, 42.78045841450732, 65.6924611663735, 76.54816229221446, 11.055675535576684, 15.384540746412497, 45.39198041340736, 92.72857922288335, 53.83024284527085, 22.26981019398526, 95.71773416511306, 24.538579847679458, 12.308247015258889, 78.51315529834726, 86.79850250199462, 69.80545541205196, 28.02781334215472, 56.31183865596937, 17.680622515571965, 20.061999535272363, 61.08586131032924, 22.039742652080136, 15.99216682189872, 43.359598474250554, 25.039978486651215, 62.86845844765103, 61.02364925747757, 10.237395291554323, 85.47982204724893, 65.77083189422041, 43.376896829046004, 48.45171356949423, 22.17498844197138, 57.83768900057274, 83.71463231877745, 59.74309669200986, 10.45354855059192, 56.79351147681761, 16.01554814413069, 10.350160961175623, 30.997734063830215, 70.35785958022925, 74.14925009712488, 17.61438829559034, 56.45984815913209, 69.88799928786615, 97.0545038942213, 17.6591256928155, 79.79483605287125, 85.0355724197268, 68.70200559999051, 77.64501291869205, 92.13906487721981, 13.729848606845023, 36.58765729034819, 47.89322351919711] => Accuracy: 100.00%\n",
            "\n",
            "=== Epoch 2 ===\n",
            "Topology: Server(0.0) -> Devices[26.41387633047123, 82.90020093460411, 30.727659952060964, 61.25732159494077, 18.823441974267823, 78.59866146720654, 32.13642600969934, 18.225009385523585, 32.85665205239516, 77.05642404148728, 36.00435763992081, 93.26063050162739, 26.173651611052744, 91.52357469262658, 49.7853157713022, 11.279618306796168, 83.22758386096992, 91.5082406527793, 91.56220840264183, 63.04055786707354, 60.66512078192842, 80.02920430883538, 28.183956846148888, 74.69337818336926, 40.408108337904515, 51.8119297101441, 11.703572786957551, 10.01027817424927, 35.557979758185446, 92.59470883297382, 60.71144761551164, 58.665050221141804, 95.31550608434118, 52.245947969176235, 39.74652011484356, 20.098745329979153, 89.7315559693484, 50.22885236496047, 74.50157575495307, 28.854183344756922, 93.13346239847301, 33.567129075322626, 13.681210829036523, 58.61199545515359, 75.77357900661966, 38.7714531943254, 87.21525005820806, 28.90233756136596, 33.26634315246744, 99.93805221635681, 87.78589869776948, 63.827391493745175, 49.59864902636941, 32.43970751928714, 43.327868894185, 77.47162584065082, 17.72400425029374, 76.32611472053392, 52.89199541041934, 34.323294012016845, 91.22810139231517, 80.41111334060894, 31.482399667343575, 13.527034456813547, 34.07139386308923, 92.15584333866158, 66.16781158094454, 81.99692602053825, 36.9316755857744, 89.92888786231792, 28.332301818222007, 79.76178835455593, 43.53133279026806, 37.84350113837033, 75.68438512792676, 26.841714822689827, 32.505786776659036, 46.980056344645504, 18.153003942388942, 65.41669166381666, 16.622732259899923, 27.158243068177452, 14.223812127480752, 75.4995003186525, 77.45289638808423, 63.7872741083494, 91.48289106490007, 61.751774561731516, 81.24347231435188, 83.62157309284694, 34.70389055279156, 76.18602498836111, 83.10440616888133, 20.0653044699159, 54.26851800392652, 19.62472997711808, 34.02154892987886, 42.070847891929645, 47.34454511865168, 21.28861685859863]\n",
            "Epoch 2 - Avg Loss: 0.1097, Accuracy: 100.00%\n",
            "Test on Topology: Server(0.0) -> Devices[11.507256281558655, 96.04014695824056, 53.85673217945305, 67.73576725728729, 93.24755319938555, 20.329444953798387, 67.74872732293795, 48.51872807971737, 53.9212366009853, 70.81407968540341, 75.04636163094956, 62.033657093977034, 94.41063334133729, 15.298673479951054, 95.38063025147076, 64.28581161211282, 35.039861088232314, 12.356617049361382, 12.872851488177597, 81.76780817318362, 75.78684868461394, 44.17861554289036, 49.68895926047761, 52.38175010085618, 73.0704383105513, 31.165905496853405, 23.19691252880524, 27.681454126503166, 34.13059354823733, 97.16887384431506, 39.19534100747737, 46.19633955716506, 76.60725206646941, 10.355429846742068, 59.9163031778774, 95.83557600932001, 73.60299164115278, 83.25211196037512, 74.27360227557746, 42.83341485745923, 88.46140233170222, 92.86209932951066, 96.0270252693328, 99.74183576791229, 73.03616201187515, 64.30039066111449, 63.1942063324774, 74.07229954232288, 28.101958025727466, 82.90441607151404, 55.94063723642393, 22.323381497940424, 54.28673979130663, 84.90430574778482, 13.448051509999821, 32.68779859339136, 70.84009221062573, 88.0674884599098, 96.2764901853722, 55.03958696098568, 13.977256919383692, 18.932676773623026, 34.940102110753514, 94.95201303043706, 92.61942754271148, 84.4590261442231, 74.9742039302103, 37.7520373619362, 32.360898724729495, 87.81267254553751, 36.55513979191578, 30.75966412309722, 59.63569430776269, 59.658687779674416, 83.85024499412472, 84.512995159858, 14.356115334431445, 17.111391844757865, 85.64708331155127, 61.516558426136726, 77.94384554931081, 33.89579335079668, 64.7372502834271, 31.381797018269356, 56.361183500844746, 46.23308848679695, 85.7863334233821, 11.290537226846647, 69.0312237016642, 37.692049935638586, 44.03627136595576, 65.70914762386658, 86.00076149882936, 35.56418440241939, 93.16841439664957, 36.74045220305848, 94.30548954368955, 56.29999746308006, 60.159986385607866, 44.829411275247764] => Accuracy: 100.00%\n",
            "\n",
            "=== Epoch 3 ===\n",
            "Topology: Server(0.0) -> Devices[91.63186838521214, 61.84214945175548, 55.76204601858336, 70.7195928135568, 41.43164048699013, 33.22059987717896, 43.24460229178299, 48.13690708921661, 10.053949910822098, 71.57822918254311, 17.736506299234968, 47.817771759889034, 87.19336613281753, 78.57411413570696, 67.66024825876522, 39.15352444935962, 91.12581687985882, 62.353892479137485, 64.14321630330798, 97.2942001677408, 65.88546864443883, 12.152930092490184, 34.597811755824566, 80.7062740877429, 63.41565686855789, 93.13257156353984, 70.88870519893644, 80.55824910178863, 28.913014173741264, 92.77019312998192, 56.905384812196445, 94.977742992217, 81.77069153992468, 72.23811465579607, 39.402715885718635, 58.60061796718216, 73.11124046455325, 43.090438716810596, 26.516683832083427, 84.14374064272414, 37.824404880375596, 12.984692555932757, 45.897657478858925, 79.17631822388717, 87.59287657853706, 23.7427019627341, 63.84417728954588, 24.55836806824861, 84.18975061921164, 68.83165498786525, 90.27825349776079, 96.34976445560626, 53.25275332462732, 44.83079009432937, 93.79844818776934, 23.729418997441087, 66.46850065568651, 73.07576778729913, 80.86742758557004, 12.552307770872439, 29.781834731421508, 50.119213777770085, 43.477367296052066, 55.24252080673917, 68.04976979307466, 81.71444190517633, 47.7887621078171, 28.381910723251046, 30.24526018576512, 38.894247062055705, 56.75377256822295, 49.69770027390039, 59.24035668134903, 20.90969026770163, 12.911369405909488, 72.62814817792977, 97.09016588528692, 57.71185872085931, 85.66758467269176, 45.11751745898017, 85.24321001496146, 91.89123997284213, 53.96631503874353, 47.79592975269522, 43.252248653684575, 12.25185612510138, 90.2708467580136, 63.01488654946687, 47.52851200874201, 62.813977680280516, 42.627852020530355, 95.21985135835534, 16.909533663278506, 45.31689684794221, 83.28243571532617, 84.98727132218553, 85.94464656454169, 49.00938813233346, 58.05876865267484, 16.491643568372222]\n",
            "Epoch 3 - Avg Loss: 0.0178, Accuracy: 100.00%\n",
            "Test on Topology: Server(0.0) -> Devices[10.79360571348339, 49.62154584729591, 55.460786512663425, 99.44755667741141, 72.2814633945636, 34.558893228194684, 40.9773701932983, 57.04775131370659, 76.30054411966479, 47.322925204463395, 15.715180474055579, 24.34809820245168, 45.78141677838292, 34.04663637010402, 50.91917205407895, 67.36690897969632, 12.187234794575861, 70.53332926684556, 22.29525924252613, 79.1275839496839, 70.76677443325718, 39.66646762096977, 97.93408075489964, 75.73010817751444, 49.35195441892127, 69.43279005653712, 10.459620119809351, 70.11732429224908, 68.08565821075757, 56.840275793236465, 61.6956164587796, 88.15076077230093, 70.80556345826642, 76.40739239839488, 55.99185241345048, 15.938099414677591, 70.11814304357702, 95.44648548813934, 79.5579751170604, 72.80482577270718, 42.04703954764379, 57.85383873557162, 89.83883592077967, 47.47797184261758, 47.34699927810097, 98.01811374485165, 99.59014806582424, 73.90947964781564, 96.07010417476863, 67.03034137915826, 76.37577184319406, 43.4252425398151, 90.27539825937878, 66.50467514035094, 16.870606851028953, 76.55734554007341, 35.471506750597065, 91.41703459463716, 48.68175158551807, 97.8238438712093, 25.567273007190266, 12.316633063186147, 33.52691679448021, 73.70720194617647, 81.37718364880138, 59.214823193422674, 78.59817991852242, 81.24203318294687, 99.53036457203774, 93.26361209317339, 79.35370642131723, 26.946978162676334, 78.4242784609673, 35.23092797699953, 26.69508735920494, 23.70952765931792, 74.97032748335316, 54.223330418475854, 48.83273272486395, 81.91393647081392, 35.910323799895664, 24.612504473171327, 20.13962965938335, 37.42070354075487, 16.134234623877063, 92.25815664179221, 98.92729587582255, 57.98568204715158, 42.50032174178145, 12.159971403663842, 16.192552673049292, 29.95942034319686, 80.48460045138044, 31.91945500774833, 59.93676164015098, 35.54123954091715, 27.64674907511565, 89.42756910232097, 76.2065848357723, 25.472758576200565] => Accuracy: 100.00%\n",
            "\n",
            "=== Epoch 4 ===\n",
            "Topology: Server(0.0) -> Devices[34.00423875341042, 42.49046106458539, 77.58199401005446, 52.49357710591933, 93.09743392412247, 84.48093661247393, 69.2691232438479, 20.397380593397237, 20.77532503127636, 53.271457187921484, 92.56600536395077, 44.15775199206514, 84.31068792016549, 54.6919836080972, 95.87558092251402, 16.151653671254962, 43.173730583422184, 44.791725339456505, 11.87152900178903, 18.40174283806639, 76.80264546359453, 81.55926276763596, 40.97097635523261, 39.6265825370864, 14.650435628372414, 28.9052455464543, 20.06301314535947, 95.68095048615355, 57.6732122074502, 82.45094825212598, 28.112790037398202, 56.20949856664623, 46.32931709825242, 17.40173027039237, 84.90898174540196, 59.119097904531976, 52.79284163753435, 53.27924572741567, 66.46636139203993, 95.38361451004204, 92.63079020041143, 55.41350137377661, 90.62096606921143, 90.17901011241183, 50.58520473512371, 64.28082611986298, 94.62110370420449, 84.2161167161169, 69.27240434619745, 98.53870427408327, 63.38285395053294, 38.40334312024265, 61.176989320446935, 56.74409244286292, 56.76720762792165, 33.10253089326572, 79.5212674141598, 83.74402347121368, 81.75693342485451, 76.0664786397957, 85.6668614701666, 14.304135193838064, 26.653010953871096, 64.95475378298985, 50.128234904629586, 41.29147362913976, 44.606949070846355, 99.00521838958409, 56.70990824661877, 75.46083119356341, 43.260050457671646, 98.89021297667131, 15.639855656010297, 73.65564026552575, 48.59197009903882, 43.19937694834464, 75.61680139739806, 81.28428457969119, 90.0579096356225, 98.34072592548108, 55.672926936762764, 73.2702924677513, 33.711860018566284, 92.23427909429529, 38.5602436376421, 30.55337013290456, 35.936466628989095, 25.032954398926556, 34.537128753435894, 89.2418182728771, 65.33032815645296, 72.19857328463031, 23.812295284943584, 78.5877394681472, 23.342482134446133, 79.072322524952, 42.33953060904015, 38.91782141978983, 89.0548257062683, 47.338461361039755]\n",
            "Epoch 4 - Avg Loss: 0.0073, Accuracy: 100.00%\n",
            "Test on Topology: Server(0.0) -> Devices[31.122039955422146, 16.089115536432082, 92.80020271969846, 77.63192634923315, 87.01814213069149, 86.7173842550848, 43.56721977392809, 22.173127517868277, 97.59437280348315, 22.44820935291305, 75.61468814561735, 90.391182609697, 46.4138429842521, 94.66003312817384, 16.6381019325255, 59.97164091798044, 19.52962864989154, 41.09615955960011, 67.60491499105063, 88.83754438731363, 62.481939637013156, 25.322026926198888, 66.75655117893908, 72.20507615713166, 94.53557734346636, 37.689080254926665, 88.72278223300745, 62.72878016815706, 91.46912081846367, 93.29637867623013, 25.442811193474427, 69.20923683479987, 23.76633619437019, 96.51415411951972, 72.3479505545543, 87.19839418773473, 25.382164009373053, 57.39896421024713, 52.08369404790391, 16.57566904529795, 51.69243608394552, 37.64151691296211, 69.11840796114447, 58.376669467561115, 91.25617926414675, 57.29120161532317, 78.68652672845398, 58.44768493838813, 37.281419940337315, 82.49945197114958, 82.50669393821248, 86.91452036868547, 41.115121007374555, 53.45182627376488, 92.01453326261122, 86.81276544309925, 33.048291925843785, 42.165537690142685, 76.94293184070254, 10.965027366530848, 63.02361549315821, 48.53772487023137, 20.338574405003442, 99.27581208710072, 57.2137221300074, 31.62609982315478, 21.492623460636903, 91.62805500815558, 69.10307652645903, 98.25492185856629, 75.8938700542656, 37.35995410892649, 28.37982889547626, 80.16718802734563, 45.58375076844483, 76.88449391438233, 71.52277436335129, 32.26623731254625, 25.910250622266094, 22.691707799107334, 13.442710525989192, 91.5921839405053, 72.33748324152077, 57.707375835028714, 65.51020957357825, 58.39167630425094, 55.39375232925563, 87.78383164807006, 93.62662662110242, 70.19092493779198, 17.58419631992649, 38.700852044774194, 87.42754021107459, 32.85022867517671, 62.76409935722568, 88.01794816912009, 71.74240527726445, 53.61905566904206, 29.30650942951549, 45.97417639642771] => Accuracy: 100.00%\n",
            "\n",
            "=== Epoch 5 ===\n",
            "Topology: Server(0.0) -> Devices[55.54481307819227, 55.62326404378932, 32.1228186572194, 28.18112118105866, 12.824245709733015, 78.29413009930511, 92.27565968297213, 61.80456967626485, 80.41166000896995, 83.60499737904568, 60.57480973890707, 84.92046342383813, 22.692573130897507, 37.38564788661593, 95.52631949056956, 75.99826376028244, 78.2147940148244, 29.658103344831638, 37.817903364383724, 34.85803601802229, 47.161468464412714, 89.78991535960668, 94.0607125409819, 40.72934434821774, 66.47275107793033, 46.2827835711256, 55.68466873694762, 14.43445989349365, 73.84551085346274, 56.715830040079695, 99.38081031839668, 99.77180924851227, 91.63452458082418, 72.67396139547722, 29.688874316646697, 11.145459009404922, 58.7471232528437, 33.89868832554374, 80.78067430263485, 81.59310975998781, 17.1115845270694, 20.258797139778473, 69.98658408324073, 39.44962168253058, 53.46382611359013, 78.4337914791265, 88.63955530932519, 84.29539564872286, 72.40845361183682, 83.31136756707083, 14.559987488817487, 83.53150670496626, 14.880487072759541, 75.99036446275475, 93.15766747342983, 68.8906780043603, 50.896567117189875, 79.56627906793754, 86.87733546767137, 28.51510150831079, 79.12533112514068, 25.22996310914932, 49.57864874188415, 31.023572716166736, 63.17761457635383, 20.637227754206556, 46.25250075705426, 87.59987604319271, 87.51395747767585, 59.41615829407851, 50.7929150779263, 98.95642610918681, 13.146313228921198, 58.79440408243083, 81.98262387245491, 43.19464314465233, 32.962239701611665, 43.68122376745518, 70.87161518051673, 12.9008872121498, 37.06430994719253, 39.090213314085815, 11.2264775991333, 87.6484091984985, 48.489265701937136, 91.70878427403957, 89.83136288243792, 82.29826145228691, 83.50753234225598, 78.90952009186704, 60.7725367942954, 87.80932389613152, 48.92733549683276, 74.11825875303273, 94.26444591399098, 90.09128469492923, 77.72154115244416, 76.06581725895944, 48.54618886909536, 29.386912882862795]\n",
            "Epoch 5 - Avg Loss: 0.0048, Accuracy: 100.00%\n",
            "Test on Topology: Server(0.0) -> Devices[36.97589235574985, 42.48895561866785, 41.467634815603624, 62.06365845118966, 10.265462356477432, 89.75711125229759, 58.01989031719042, 25.529597447302866, 80.58669107385522, 10.942362944419305, 75.0908743855626, 71.04336015017762, 36.13946154493044, 16.22237153513736, 50.387362804232254, 34.234383206841215, 26.786573660153895, 74.29720077876765, 43.20770825007348, 47.13171958291639, 83.08122573134327, 26.063613406432545, 75.21399953111964, 21.60824657557977, 75.9650984664342, 24.260424069287453, 58.7835317923143, 20.11369164253507, 10.201951718446699, 58.776567799652035, 81.76312495271935, 47.62285127240912, 64.64115808473277, 22.171740169003655, 82.85506435111252, 57.02766028308434, 79.52795021264166, 19.358732207580044, 34.046758500966575, 35.641795853913315, 39.577530219999545, 44.419891769787924, 37.17699696998966, 91.15133639504401, 19.64223891168568, 37.2866534000774, 75.02382333270265, 55.24923965757544, 69.8558394357926, 94.44053456773572, 19.262772639240424, 39.34360234228498, 37.409900743879334, 78.70976352932315, 57.55566432926386, 20.848053193261272, 62.72919414696185, 52.4637961079207, 68.24426860460794, 49.44752690720301, 82.11673205041699, 69.18302368199004, 77.55013450560645, 89.40283268395011, 94.99688163297239, 32.69135040550094, 60.4814740885986, 83.35548006372638, 83.5738820969864, 54.79426563495478, 50.85766836971518, 38.03990560471382, 45.91096964263484, 55.36001844118108, 58.760358229315415, 89.26211342849761, 39.32696735140722, 70.24237139599887, 69.99029643214243, 48.217697981188685, 33.739327438175565, 71.07579999895896, 92.83313014516912, 97.92556109778775, 18.655919376365006, 33.364507327636446, 45.52792138342455, 37.228356326764356, 95.73857354706394, 48.05109079315898, 68.09841847360708, 47.44787519176859, 22.73514416022846, 40.761170638727975, 69.0221256696064, 15.845430872225382, 55.5057523119469, 47.49258078877766, 82.58419336413651, 18.47396517892148] => Accuracy: 100.00%\n",
            "Placement selector saved to dynamic_placement_selector.pth.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAHqCAYAAADVi/1VAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAadBJREFUeJzt3Xl8VOXd///3TJbJQhK2rBB2ZQ8iIuKGSpQtCIqi3i64tPRW9C7a1lu+ddeWahet1Rttfy1uWBUUlCAgokBVQEVZBQQEEsjGmpWsc35/DBkZCJCEyVyzvJ6PxzxycubMzPtwGbz45PqcY7MsyxIAAAAAAADgQ3bTAQAAAAAAABB6KEoBAAAAAADA5yhKAQAAAAAAwOcoSgEAAAAAAMDnKEoBAAAAAADA5yhKAQAAAAAAwOcoSgEAAAAAAMDnKEoBAAAAAADA5yhKAQAAAAAAwOcoSgHwidtvv11dunRp1msff/xx2Ww27wYCAADwAeZAAHByFKWAEGez2Rr1WLZsmemoRtx+++1q1aqV6RgAAMDLmAM13sSJE2Wz2fS///u/pqMACDI2y7Is0yEAmPPmm296fP/6669ryZIleuONNzz2X3nllUpOTm7259TU1MjpdMrhcDT5tbW1taqtrVVUVFSzP7+5br/9ds2ZM0dlZWU+/2wAANBymAM1TklJiZKTk5WSkqK6ujrt3r2b1VsAvCbcdAAAZt1yyy0e369atUpLliw5Yf/xKioqFBMT0+jPiYiIaFY+SQoPD1d4OH9dAQAA72EO1Djvvfee6urq9K9//UtXXHGFVqxYoWHDhhnN1BDLslRZWano6GjTUQA0Ae17AE7rsssuU79+/bRmzRpdeumliomJ0f/7f/9PkvTBBx9ozJgxSktLk8PhUPfu3fXUU0+prq7O4z2Ov57Crl27ZLPZ9Kc//Ul///vf1b17dzkcDg0ePFhff/21x2sbup6CzWbTvffeq3nz5qlfv35yOBzq27evFi1adEL+ZcuW6bzzzlNUVJS6d++uV155xevXaJg9e7YGDRqk6OhotW/fXrfccov27t3rcUxBQYHuuOMOdezYUQ6HQ6mpqRo3bpx27drlPuabb77RiBEj1L59e0VHR6tr16668847vZYTAAA0HnMgadasWbryyit1+eWXq3fv3po1a1aDx23ZskUTJ05UYmKioqOj1bNnT/32t7/1OGbv3r2666673H9mXbt21d13363q6uqTnq8kvfrqq7LZbB5zpi5duigrK0uLFy/Weeedp+joaL3yyiuSpJkzZ+qKK65QUlKSHA6H+vTpoxkzZjSYe+HChRo2bJji4uIUHx+vwYMH66233pIkPfbYY4qIiNC+fftOeN3kyZPVunVrVVZWnv4PEcBJsfQAQKMcOHBAo0aN0o033qhbbrnFvYz91VdfVatWrfTAAw+oVatW+vTTT/Xoo4+qpKREf/zjH0/7vm+99ZZKS0v1i1/8QjabTc8++6yuvfZa/fjjj6f9zeLnn3+u999/X/fcc4/i4uL0wgsvaMKECcrJyVG7du0kSd99951Gjhyp1NRUPfHEE6qrq9OTTz6pxMTEM/9DOerVV1/VHXfcocGDB2v69OkqLCzUX//6V33xxRf67rvv1Lp1a0nShAkTtGnTJt13333q0qWLioqKtGTJEuXk5Li/v+qqq5SYmKiHHnpIrVu31q5du/T+++97LSsAAGiaUJ4D5eXl6bPPPtNrr70mSbrpppv03HPP6cUXX1RkZKT7uPXr1+uSSy5RRESEJk+erC5dumjHjh2aP3++fve737nf6/zzz9fhw4c1efJk9erVS3v37tWcOXNUUVHh8X6NtXXrVt100036xS9+oZ///Ofq2bOnJGnGjBnq27evrr76aoWHh2v+/Pm655575HQ6NWXKFPfrX331Vd15553q27evpk2bptatW+u7777TokWL9F//9V+69dZb9eSTT+qdd97Rvffe635ddXW15syZowkTJhhtrQSCggUAx5gyZYp1/F8Nw4YNsyRZL7/88gnHV1RUnLDvF7/4hRUTE2NVVla6902aNMnq3Lmz+/udO3dakqx27dpZBw8edO//4IMPLEnW/Pnz3fsee+yxEzJJsiIjI63t27e7961bt86SZP3tb39z7xs7dqwVExNj7d27171v27ZtVnh4+Anv2ZBJkyZZsbGxJ32+urraSkpKsvr162cdOXLEvT87O9uSZD366KOWZVnWoUOHLEnWH//4x5O+19y5cy1J1tdff33aXAAAwLuYA53oT3/6kxUdHW2VlJRYlmVZP/zwgyXJmjt3rsdxl156qRUXF2ft3r3bY7/T6XRv33bbbZbdbm9wnlN/XEPna1mWNXPmTEuStXPnTve+zp07W5KsRYsWnXB8Q2MzYsQIq1u3bu7vDx8+bMXFxVlDhgzxmMMdn3vo0KHWkCFDPJ5///33LUnWZ599dsLnAGga2vcANIrD4dAdd9xxwv5j+/ZLS0u1f/9+XXLJJaqoqNCWLVtO+7433HCD2rRp4/7+kksukST9+OOPp31tZmamunfv7v4+IyND8fHx7tfW1dXpk08+0fjx45WWluY+rkePHho1atRp378xvvnmGxUVFemee+7x+E3ZmDFj1KtXLy1YsECS688pMjJSy5Yt06FDhxp8r/oVVdnZ2aqpqfFKPgAAcGZCeQ40a9YsjRkzRnFxcZKks846S4MGDfJo4du3b59WrFihO++8U506dfJ4fX0rntPp1Lx58zR27Fidd955J3xOcy+p0LVrV40YMeKE/ceOTXFxsfbv369hw4bpxx9/VHFxsSRpyZIlKi0t1UMPPXTCaqdj89x2221avXq1duzY4d43a9Yspaen++W1tYBAQ1EKQKN06NChwWXVmzZt0jXXXKOEhATFx8crMTHRfYHQ+v/pn8rxk5f6ydnJCjenem396+tfW1RUpCNHjqhHjx4nHNfQvubYvXu3JLmXix+rV69e7ucdDoeeeeYZLVy4UMnJybr00kv17LPPqqCgwH38sGHDNGHCBD3xxBNq3769xo0bp5kzZ6qqqsorWQEAQNOF6hxo8+bN+u6773TRRRdp+/bt7sdll12m7OxslZSUSPqpiNavX7+Tvte+fftUUlJyymOao2vXrg3u/+KLL5SZmanY2Fi1bt1aiYmJ7muB1Y9NfZHpdJluuOEGORwOdyGuuLhY2dnZuvnmm7kLIeAFFKUANEpDdzI5fPiwhg0bpnXr1unJJ5/U/PnztWTJEj3zzDOSXL8VO52wsLAG91uW1aKvNWHq1Kn64YcfNH36dEVFRemRRx5R79699d1330ly/VZuzpw5Wrlype69917t3btXd955pwYNGqSysjLD6QEACE2hOgd68803JUn333+/zjrrLPfjz3/+syorK/Xee+957bPqnazIc/zF4+s1NDY7duzQ8OHDtX//fv3lL3/RggULtGTJEt1///2SGjc2x2rTpo2ysrLcRak5c+aoqqrqtHdpBNA4XOgcQLMtW7ZMBw4c0Pvvv69LL73UvX/nzp0GU/0kKSlJUVFR2r59+wnPNbSvOTp37izJdaHNK664wuO5rVu3up+v1717d/3qV7/Sr371K23btk3nnHOO/vznP7snfpJ0wQUX6IILLtDvfvc7vfXWW7r55pv19ttv62c/+5lXMgMAgDMT7HMgy7L01ltv6fLLL9c999xzwvNPPfWUZs2apTvuuEPdunWTJG3cuPGk75eYmKj4+PhTHiP9tFrs8OHD7ssaSD+tTG+M+fPnq6qqSh9++KHHirLPPvvM47j69seNGzeedvXYbbfdpnHjxunrr7/WrFmzNHDgQPXt27fRmQCcHCulADRb/W/pjv2tXHV1tf7v//7PVCQPYWFhyszM1Lx585SXl+fev337di1cuNArn3HeeecpKSlJL7/8skeb3cKFC7V582aNGTNGklRRUXHCLYO7d++uuLg49+sOHTp0wm84zznnHEmihQ8AAD8S7HOgL774Qrt27dIdd9yh66677oTHDTfcoM8++0x5eXlKTEzUpZdeqn/961/KycnxeJ/6Px+73a7x48dr/vz5+uabb074vPrj6gtFK1ascD9XXl7uvvtfY8/92PeUXC13M2fO9DjuqquuUlxcnKZPn37CHO34+dioUaPUvn17PfPMM1q+fDmrpAAvYqUUgGa78MIL1aZNG02aNEn/8z//I5vNpjfeeMOv2ucef/xxffzxx7rooot09913q66uTi+++KL69euntWvXNuo9ampq9PTTT5+wv23btrrnnnv0zDPP6I477tCwYcN00003qbCwUH/961/VpUsX91LxH374QcOHD9fEiRPVp08fhYeHa+7cuSosLNSNN94oSXrttdf0f//3f7rmmmvUvXt3lZaW6h//+Ifi4+M1evRor/2ZAACAMxPsc6BZs2YpLCzM/cu141199dX67W9/q7ffflsPPPCAXnjhBV188cU699xzNXnyZHXt2lW7du3SggUL3J/1+9//Xh9//LGGDRumyZMnq3fv3srPz9fs2bP1+eefq3Xr1rrqqqvUqVMn3XXXXfrNb36jsLAw/etf/1JiYuIJBa+TueqqqxQZGamxY8fqF7/4hcrKyvSPf/xDSUlJys/Pdx8XHx+v5557Tj/72c80ePBg/dd//ZfatGmjdevWqaKiwqMQFhERoRtvvFEvvviiwsLCdNNNNzUqC4DToygFoNnatWun7Oxs/epXv9LDDz+sNm3a6JZbbtHw4cMbvBOKCYMGDdLChQv161//Wo888ojS09P15JNPavPmzY26M47k+s3nI488csL+7t2765577tHtt9+umJgY/eEPf9D//u//KjY2Vtdcc42eeeYZ99Lz9PR03XTTTVq6dKneeOMNhYeHq1evXnr33Xc1YcIESa4LnX/11Vd6++23VVhYqISEBJ1//vmaNWvWSS/kCQAAfC+Y50A1NTWaPXu2LrzwQrVt27bBY/r166euXbvqzTff1AMPPKABAwZo1apVeuSRRzRjxgxVVlaqc+fOmjhxovs1HTp00OrVq/XII49o1qxZKikpUYcOHTRq1CjFxMRIchV/5s6dq3vuuUePPPKIUlJSNHXqVLVp06bBOyA2pGfPnpozZ44efvhh/frXv1ZKSoruvvtuJSYm6s477/Q49q677lJSUpL+8Ic/6KmnnlJERIR69erl/qXisW677Ta9+OKLGj58uFJTUxuVBcDp2Sx/KucDgI+MHz9emzZt0rZt20xHAQAA8BnmQM2zbt06nXPOOXr99dd16623mo4DBA2uKQUg6B05csTj+23btumjjz7SZZddZiYQAACADzAH8p5//OMfatWqla699lrTUYCgQvsegKDXrVs33X777erWrZt2796tGTNmKDIyUg8++KDpaAAAAC2GOdCZmz9/vr7//nv9/e9/17333qvY2FjTkYCgQvsegKB3xx136LPPPlNBQYEcDoeGDh2q3//+9zr33HNNRwMAAGgxzIHOXJcuXVRYWKgRI0bojTfeUFxcnOlIQFChKAUAAAAAAACf45pSAAAAAAAA8DmKUgAAAAAAAPA5v7vQudPpVF5enuLi4mSz2UzHAQAAIcSyLJWWliotLU12e2D/7o45FQAAMKWxcyq/K0rl5eUpPT3ddAwAABDCcnNz1bFjR9MxzghzKgAAYNrp5lR+V5Sqv5tBbm6u4uPjDacBAAChpKSkROnp6UFxdyXmVAAAwJTGzqn8rihVv7w8Pj6eCRQAADAiGNrdmFMBAADTTjenCuyLJQAAAAAAACAgUZQCAAAAAACAz1GUAgAAAAAAgM9RlAIAAAAAAIDPUZQCAAAAAACAz1GUAgAAAAAAgM9RlAIAAAAAAIDPUZQCAAAAAACAz1GUAgAAAAAAgM9RlAIAAAAAAIDPUZQCAAAAAACAz4VcUarOaWnljgP6YO1erdxxQHVOy3QkAAAQZFasWKGxY8cqLS1NNptN8+bN83jesiw9+uijSk1NVXR0tDIzM7Vt2zaPYw4ePKibb75Z8fHxat26te666y6VlZX58CyAYzjrpMJl0q5/u74660wnQktivEML4x1a/Gy8w41+uo8t2pivJ+Z/r/ziSve+1IQoPTa2j0b2SzWYDAAABJPy8nINGDBAd955p6699toTnn/22Wf1wgsv6LXXXlPXrl31yCOPaMSIEfr+++8VFRUlSbr55puVn5+vJUuWqKamRnfccYcmT56st956y9eng1CX+7605pdSxZ6f9sV0lAb9VUo/8b9vBDjGO7Qw3qHFD8fbZlmWXy0VKikpUUJCgoqLixUfH++19120MV93v/mtjj9Z29GvM245l8IUAAAhriXmITabTXPnztX48eMluVZJpaWl6Ve/+pV+/etfS5KKi4uVnJysV199VTfeeKM2b96sPn366Ouvv9Z5550nSVq0aJFGjx6tPXv2KC0tzci5IATlvi/95zrpZLPoS+bwD9dgwniHFsY7tPh4vBs7DwmJlVJ1TktPzP/+hD96yTUcNklPzP9eV/ZJUZjd1sBRAAAA3rFz504VFBQoMzPTvS8hIUFDhgzRypUrdeONN2rlypVq3bq1uyAlSZmZmbLb7Vq9erWuueYaE9ERapx1rt+on3QWLWn1ZMlZI9nCfJkMLcGqk76eIsY7RDDeoeW0422T1kyVOoyT7L4d75AoSn2186BHy97xLEn5xZX6audBDe3eznfBAABAyCkoKJAkJScne+xPTk52P1dQUKCkpCSP58PDw9W2bVv3McerqqpSVVWV+/uSkhJvxkYo2vcfzxaPhlQfkL640Td5YB7jHVoY7xBiSRW5rr/3ky/z6SeHRFGqqPTkBanmHAcAAOBvpk+frieeeMJ0DASTI/mNOy6upxSVdPrj4N8qi6TSrac/jvEODox3aGnseDf2730vComiVFJclFePAwAAaK6UlBRJUmFhoVJTf7qeZWFhoc455xz3MUVFRR6vq62t1cGDB92vP960adP0wAMPuL8vKSlRenq6l9MjpEQ38nqr57/s89+sowUULpOWXn764xjv4MB4h5bGjndj/973IrvPP9GA87u2VWpClE52tSibXHfhO79rW1/GAgAAIahr165KSUnR0qVL3ftKSkq0evVqDR06VJI0dOhQHT58WGvWrHEf8+mnn8rpdGrIkCENvq/D4VB8fLzHAzgjiZe47sp0qll0TLrrOAQ+xju0MN6hxY/HOySKUmF2mx4b20fSyYfgsbF9uMg5AADwirKyMq1du1Zr166V5Lq4+dq1a5WTkyObzaapU6fq6aef1ocffqgNGzbotttuU1pamvsOfb1799bIkSP185//XF999ZW++OIL3Xvvvbrxxhsbdec9wCvsYa7bhDd4Ydyj8+ZBz/v8orhoIe7xlk78VxPjHXQY79Dix+MdEkUpSRrZL1UzbjlXKQmeLXphNun/bj5XI/v5fpkaAAAITt98840GDhyogQMHSpIeeOABDRw4UI8++qgk6cEHH9R9992nyZMna/DgwSorK9OiRYsUFfXTPGXWrFnq1auXhg8frtGjR+viiy/W3//+dyPngxCWfq2UePGJ+2M6crv4YJR+rWtcYzp47me8gxPjHVr8dLxtlmU19KsPY0pKSpSQkKDi4uIWWXZe57T01c6D2nu4Qr+du1FVtU7NvedCDezUxuufBQAAAktLz0N8KZjOBQbVHpHeT5Rqy6XzXpIi27iuOZJ4CSsogpmzznUXriP5jHcoYLxDi4/Gu7HzkJC40Pmxwuw2De3eTlI7rfhhvz5cl6fs9fkUpQAAAIDj5S90FaRiOkln3S3ZuNxFSLCHcXHrUMJ4hxY/G++Qad9rSFaGq2Vvwfp8OZ1+tWAMAAAAMG/3O66vnSdSkAIAeF1IF6WG9UxUnCNcBSWVWpNzyHQcAAAAwH/Ulkt7s13bnSaazQIACEohXZRyhIfpyr7JklyrpQAAAAActXeBVFchxXaV2p5nOg0AIAiFdFFKOqaFb0O+6mjhAwAAAFxy3nV9pXUPANBCQr4odXGPRCVER2hfaZW+2nnQdBwAAADAvJoyKW+Ba5vWPQBACwn5olRkuF0jjrbwZa/PM5wGAAAA8AN750t1lVKrHlKbgabTAACCVMgXpSQpKyNNkrRoY4Fq65yG0wAAAACG0boHAPABilKShnZvpzYxETpQXq1VP9LCBwAAgBBWUyLlLXRt07oHAGhBFKUkRYTZNbKf64LntPABAAAgpO35UHJWSfE9pdYZptMAAIIYRamjxh69C9+iTQWqoYUPAAAAoaq+da8TrXsAgJZFUeqoId3aqX0rhw5X1OiL7ftNxwEAAAB8r/qwlL/ItU3rHgCghVGUOirMbtPo/imSpOz1+YbTAAAAAAbs+UBy1kgJfaTW/UynAQAEOYpSxxjT39XCt3hTgapq6wynAQAAAHzs2NY9AABaGEWpYwzu0lbJ8Q6VVtbqPz/QwgcAAIAQUnVQyv/YtU1RCgDgAxSljmG32zS6P3fhAwAAQAjaM0+yaqXW/aWE3qbTAABCAEWp42RlpEmSlnxfqMoaWvgAAAAQImjdAwD4GEWp4wxMb620hCiVV9dp2dZ9puMAAAAALa9yv1TwiWubohQAwEcoSh3HbrdpTAYtfAAAAAghe+ZKVp3U5hwp/mzTaQAAIYKiVAPqW/iWbi5SRXWt4TQAAABAC9v9jutrpxvM5gAAhBSKUg3I6Jig9LbROlJTp8+20MIHAACAIFZZJBV95trudL3ZLACAkEJRqgE2m01j+rtWS9HCBwAAgKCW+75kOaW2g6S47qbTAABCCEWpk8g6el2pT7cUqayKFj4AAAAEKVr3AACGUJQ6ib5p8eraPlZVtU4t3VxoOg4AAADgfUcKpKLlrm1a9wAAPkZR6iRsNpt7tVT2+nzDaQAAAIAWkPueJEtqd77UqovpNACAEENR6hTGHC1KLd+6TyWVNYbTAAAAAF5G6x4AwCCKUqfQMzlOPZJaqbrOqSWbaOEDAABAEKnYK+373LVN6x4AwACKUqfg2cLHXfgAAAAQRHLmSLKk9hdKsemm0wAAQhBFqdOoL0r9Z9t+FVfQwgcAAIAgkfOu62uniWZzAABCFkWp0+iRFKdeKXGqdVpavKnAdBwAAADgzJXnSvu/lGSTOl1nOg0AIERRlGqE+tVS82nhAwAAQDDIme36mnixFNPBbBYAQMiiKNUIWRlpkqQvdxzQgbIqw2kAAACAM0TrHgDAD1CUaoQu7WPVr0O86pyWFnMXPgAAAASysl3SgdVyte5NMJ0GABDCKEo1Uv1qKe7CBwAAgIBW37qXNEyKTjWbBQAQ0ihKNdKY/q7/Ya/68YD2ldLCBwAAgABV37rXmdY9AIBZFKUaKb1tjAakt5bTkhZuzDcdBwAAAGi60h3SwW8km11Kp3UPAGAWRakmGHv0LnzZ6ylKAQAAIAC5W/cul6KSzGYBAIQ8ilJNMPpoC9/Xuw6qsKTScBoAAACgiWjdAwD4EYpSTZDWOlqDOreRZUkLWC0FAACAQFKyTTr0nWQLkzpeazoNAAAUpZoqy93Cx134AAAAEEDqV0klD5ei2pvNAgCAKEo12ej+qbLZpG9zDmvv4SOm4wAAAACNQ+seAMDPUJRqouT4KJ3fpa0k6SNa+AAAABAIirdIh9dLtnCp4zWm0wAAIImiVLPQwgcAAICAUr9KKuVKydHWbBYAAI6iKNUMI/ulym6T1u0pVs6BCtNxAAAAgFPLecf1tfMNZnMAAHAMilLNkBjn0NDu7SRJ2RtYLQUAAAA/dniTVPy9ZI+QOo4znQYAADeKUs2UlZEmSVrAdaUAAADgz9yteyOkyNZGowAAcCyKUs00om+Kwuw2bcor0c795abjAAAAACeyLFr3AAB+q0lFqenTp2vw4MGKi4tTUlKSxo8fr61bt3ocU1lZqSlTpqhdu3Zq1aqVJkyYoMLCQq+G9gdtYyN1UY/2kqTsdbTwAQAAwA8d3iCVbJXsDqnj1abTAADgoUlFqeXLl2vKlClatWqVlixZopqaGl111VUqL/9ppdD999+v+fPna/bs2Vq+fLny8vJ07bXXej24P/jpLny08AEAAMAP1bfupY2SIuLNZgEA4DjhTTl40aJFHt+/+uqrSkpK0po1a3TppZequLhY//znP/XWW2/piiuukCTNnDlTvXv31qpVq3TBBRd4L7kfGNEnRb8N26CthaXaVliqs5LjTEcCAAAAXCxL2n20da/TRLNZAABowBldU6q4uFiS1LZtW0nSmjVrVFNTo8zMTPcxvXr1UqdOnbRy5coG36OqqkolJSUej0CREBOhS85KlMRqKQAAAPiZQ2ulsu1SWJTUIct0GgAATtDsopTT6dTUqVN10UUXqV+/fpKkgoICRUZGqnXr1h7HJicnq6CgoMH3mT59uhISEtyP9PT05kYy4qcWvjxZlmU4DQAAAHBU/QXO08ZIEazoBwD4n2YXpaZMmaKNGzfq7bffPqMA06ZNU3FxsfuRm5t7Ru/na1f2SVZkuF079pVrS0Gp6TgAAADA0da9o9eTonUPAOCnmlWUuvfee5Wdna3PPvtMHTt2dO9PSUlRdXW1Dh8+7HF8YWGhUlJSGnwvh8Oh+Ph4j0cgiYuK0GVnu1r4FtDCBwAAAH9wcI1UvlMKi5E6jDGdBgCABjWpKGVZlu69917NnTtXn376qbp27erx/KBBgxQREaGlS5e6923dulU5OTkaOnSodxL7oawBaZJo4QMAAICfqG/d65AlhceazQIAwEk06e57U6ZM0VtvvaUPPvhAcXFx7utEJSQkKDo6WgkJCbrrrrv0wAMPqG3btoqPj9d9992noUOHBt2d9441vFeSoiLs2nWgQpvyStSvQ4LpSAAAAAhVtO4BAAJEk1ZKzZgxQ8XFxbrsssuUmprqfrzzzjvuY5577jllZWVpwoQJuvTSS5WSkqL333/f68H9SawjXFf0SpIkzV+fZzgNAAAAQtqBr6SKHNcKqbTRptMAAHBSTVop1ZjWtKioKL300kt66aWXmh0qEGVlpOmjDQVasD5fD43sJZvNZjoSAAAAQtHu+ta9q6XwaLNZAAA4hWbffQ+eLu+ZpJjIMO05dETr9hSbjgMAAIBQZDml3NmubVr3AAB+jqKUl0RHhml472RJUvY6WvgAAABgwP6VUsUeKTxOShtpOg0AAKdEUcqLsjJSJUkLNuTL6eQufAAAAPCx+gucdxwnhUWZzQIAwGlQlPKiYWcnKs4RrvziSn2Xe8h0HAAAAIQSWvcAAAGGopQXRUWE6co+rha++evyDacBAABASNn3uXQkX4pIkFKvMp0GAIDToijlZWOOtvB9tCFfdbTwAQAAwFfcrXvjpTCH0SgAADQGRSkvu+SsRMVHhauotEpf7zpoOg4AAABCgbNOyp3j2u58g9ksAAA0EkUpL4sMt2tE3xRJUvZ67sIHAAAAH9i3QqoslCLbSMnDTacBAKBRKEq1gKwBaZKkRRsLVFvnNJwGAAAAQc/duneNFBZpNgsAAI1EUaoFXNi9ndrERGh/WbVW76SFDwAAAC3IWSvlvufapnUPABBAKEq1gIgwu0b2o4UPAAAAPlC0TKraJznaScmXm04DAECjUZRqIVkZrha+hRsLVEMLHwAAAFqKu3XvWskeYTYLAABNQFGqhQzp2lbtW0XqcEWNvtxxwHQcAAAABCNnDa17AICARVGqhYQf28K3jhY+AAAAtICCT6Xqg5IjUUoaZjoNAABNQlGqBdW38C3eVKDqWlr4AAAA4GU5R1v3Ol0n2cPNZgEAoIkoSrWgwV3aKinOoZLKWv1n2z7TcQAAABBM6qql3Pdd250mms0CAEAzUJRqQWF2m0b3T5UkLVifbzgNAADwJ6WlpZo6dao6d+6s6OhoXXjhhfr666/dz1uWpUcffVSpqamKjo5WZmamtm3bZjAx/E7BJ1LNYSkqRUq8xHQaAACajKJUC8vKcBWlPv6+UJU1dYbTAAAAf/Gzn/1MS5Ys0RtvvKENGzboqquuUmZmpvbu3StJevbZZ/XCCy/o5Zdf1urVqxUbG6sRI0aosrLScHL4jZx3XF87XSfZw8xmAQCgGShKtbBzO7VRakKUyqpqtfwHWvgAAIB05MgRvffee3r22Wd16aWXqkePHnr88cfVo0cPzZgxQ5Zl6fnnn9fDDz+scePGKSMjQ6+//rry8vI0b9480/HhD+qqpD3zXNu07gEAAhRFqRZmt9s05mgLXzYtfAAAQFJtba3q6uoUFRXlsT86Olqff/65du7cqYKCAmVmZrqfS0hI0JAhQ7Ry5Upfx4U/yv9YqimRotOkxItMpwEAoFkoSvlA1gDXXfiWbi7UkWpa+AAACHVxcXEaOnSonnrqKeXl5amurk5vvvmmVq5cqfz8fBUUFEiSkpOTPV6XnJzsfu54VVVVKikp8XggiLlb966XbEzpAQCBif+D+cCAjgnq2CZaFdV1+mxrkek4AADAD7zxxhuyLEsdOnSQw+HQCy+8oJtuukl2e/OmZ9OnT1dCQoL7kZ6e7uXE8Bu1R6Q9H7i2ad0DAAQwilI+YLPZNCajvoUvz3AaAADgD7p3767ly5errKxMubm5+uqrr1RTU6Nu3bopJSVFklRYWOjxmsLCQvdzx5s2bZqKi4vdj9zc3BY/BxiSv1iqLZNi0qX2F5hOAwBAs1GU8pGxGa4Wvk+3FKm8qtZwGgAA4C9iY2OVmpqqQ4cOafHixRo3bpy6du2qlJQULV261H1cSUmJVq9eraFDhzb4Pg6HQ/Hx8R4PBCla9wAAQSLcdIBQ0TctXl3axWjXgQot3VKkq49eZwoAAISmxYsXy7Is9ezZU9u3b9dvfvMb9erVS3fccYdsNpumTp2qp59+WmeddZa6du2qRx55RGlpaRo/frzp6DCptkLaO9+1TeseACDA8asVH7HZbMo6uloqex0tfAAAhLri4mJNmTJFvXr10m233aaLL75YixcvVkREhCTpwQcf1H333afJkydr8ODBKisr06JFi064Yx9CTN5HUm25FNtZane+6TQAAJwRm2VZlukQxyopKVFCQoKKi4uDbtn55vwSjfrrfxQZbteahzMVFxVhOhIAADhGMM1DgulccIzPJ0o5s6Xev5EGPms6DQAADWrsPISVUj7UKyVO3RNjVV3r1JLvC0//AgAAAKBebbm0N9u13fkGs1kAAPACilI+dGwL34L1+YbTAAAAIKDszZbqjkitukltzjWdBgCAM0ZRyseyMlIlSSu27VNxRY3hNAAAAAgYOe+6vnaaKNlsZrMAAOAFFKV87KzkOPVMjlNNnaXF3xeYjgMAAIBAUFPqusi5ROseACBoUJQyoH61VDYtfAAAAGiMvfOlukop7iyp9QDTaQAA8AqKUgZkDXBdV+qL7ft1sLzacBoAAAD4PVr3AABBiKKUAV3bx6pvWrzqnJYWb6KFDwAAAKdQXSzlLXRt07oHAAgiFKUMGeNu4csznAQAAAB+be+HkrNaiu8lJfQznQYAAK+hKGVIVn9XC9/KHQe0r7TKcBoAAAD4rd31rXs30LoHAAgqFKUM6dQuRgM6JshpSYs2csFzAAAANKD6kFSw2LXd6XqzWQAA8DKKUgZlZbhWS3EXPgAAADRozweSs0ZK6Cu17ms6DQAAXkVRyqDRR68r9dWugyosqTScBgAAAH7n2NY9AACCDEUpgzq0jta5nVrLsqSPNrBaCgAAAMeoOiAVLHFt07oHAAhCFKUMo4UPAAAADdozT7JqpdYZUkIv02kAAPA6ilKGjclIlc0mrdl9SHmHj5iOAwAAAH+x+x3X18607gEAghNFKcOS46M0uEtbSbTwAQAA4KjKfVLhp67tThPNZgEAoIVQlPIDWUcveD6fFj4AAABI0p65klUntTlXiuthOg0AAC2CopQfGNUvVXabtC73sHIPVpiOAwAAANPcrXuskgIABC+KUn4gMc6hC7q1kyQtoIUPAAAgtB0plIqWuba56x4AIIhRlPITP92FL89wEgAAABi1533JckptB0utuplOAwBAi6Eo5SdG9ktRmN2mjXtLtGt/uek4AAAAMIXWPQBAiKAo5Sfaxkbqwu6uFj5WSwEAAISoI/lS0QrXNq17AIAgR1HKj4x1t/BxXSkAAICQlDNHkiW1u0CK7Ww6DQAALYqilB8Z0TdFEWE2bSko1faiMtNxAAAA4Gs577q+0roHAAgBFKX8SEJMhC7u0V4SLXwAAAAhp2KvtO9z1zatewCAEEBRys9kHdPCZ1mW4TQAAADwmZzZrq+JF0kxHc1mAQDAByhK+Zkr+yYrMsyu7UVl2lpYajoOAAAAfKW+da8TrXsAgNBAUcrPxEdFaFjPREnSAi54DgAAEBrKc6T9KyXZpPTrTKcBAMAnKEr5oayMVEm08AEAAISM+ta9pEukmDSzWQAA8BGKUn5oeO9kOcLt2rm/XJvySkzHAQAAQEtzt+7dYDYHAAA+RFHKD7VyhOuKXkmSXKulAAAAEMTKdkoHvpJsdin9WtNpAADwGYpSfqr+LnwLNuTRwgcAABDM3K17w6ToFLNZAADwIYpSfuryXomKjghT7sEjWr+n2HQcAAAAtBRa9wAAIYqilJ+KiQzX8N71LXx5htMAAACgRZRulw6uoXUPABCSKEr5MXcL3/p8OZ208AEAAASd+ta95CukqESzWQAA8DGKUn7ssp6JauUIV15xpb7LPWw6DgAAALyN1j0AQAijKOXHoiLCdGWfZEm08AEAAASdkh+kQ2slW7iUfo3pNAAA+BxFKT83pn+qJOmjDbTwAQAABJX6VVIpmZKjndksAAAYQFHKz11ydnvFRYWrsKRKX+86aDoOAAAAvGX3O66vnSaazQEAgCFNLkqtWLFCY8eOVVpammw2m+bNm+fx/O233y6bzebxGDlypLfyhhxHeJhG9E2RJC3YkG84DQAAALyi+HupeKNkj5DSx5tOAwCAEU0uSpWXl2vAgAF66aWXTnrMyJEjlZ+f7378+9//PqOQoS4ro76Fr0B1tPABAAAEvvq77qVcJUW2MZsFAABDwpv6glGjRmnUqFGnPMbhcCglJaXZoeDpoh7t1TomQvvLqrT6xwO6sEd705EAAADQXJZF6x4AAGqha0otW7ZMSUlJ6tmzp+6++24dOHCgJT4mZESE2TXyaAvf/PW08AEAAAS04k1SyWbJHil1HGc6DQAAxni9KDVy5Ei9/vrrWrp0qZ555hktX75co0aNUl1dXYPHV1VVqaSkxOOBE2VlpEmSFm3MV22d03AaAAAANFv9XfdSR0qRCWazAABgUJPb907nxhtvdG/3799fGRkZ6t69u5YtW6bhw4efcPz06dP1xBNPeDtG0LmgW1u1i43UgfJqfbnjgC49O9F0JAAAADQVrXsAALi1SPvesbp166b27dtr+/btDT4/bdo0FRcXux+5ubktHSkghYfZNbKfq4Uve32e4TQAAABolsPrpdIfJLtD6ni16TQAABjV4kWpPXv26MCBA0pNTW3weYfDofj4eI8HGvZTC1+Bqmtp4QMAAAg49auk0kZLEXFmswAAYFiTi1JlZWVau3at1q5dK0nauXOn1q5dq5ycHJWVlek3v/mNVq1apV27dmnp0qUaN26cevTooREjRng7e8g5v2tbJcY5VFJZqy+27zcdBwAAAE1hWT9dT4rWPQAAml6U+uabbzRw4EANHDhQkvTAAw9o4MCBevTRRxUWFqb169fr6quv1tlnn6277rpLgwYN0n/+8x85HA6vhw81YXabxvR3rTibTwsfAABAYDn0nVS2QwqLljpkmU4DAIBxTb7Q+WWXXSbLsk76/OLFi88oEE5tTEaqXv1yl5ZsKlRlTZ2iIsJMRwIAAEBjuFv3xkgRrcxmAQDAD7T4NaXgXYM6tVFKfJRKq2q14od9puMAAACgMY5t3etM6x4AABJFqYBjt9s0JsPVwpe9Pt9wGgAAADTKwW+k8l1SWIxrpRQAAKAoFYiyjhalPtnsauEDAACAn6tv3eswVgqPMZsFAAA/QVEqAJ2T3lodWkerorpOn20pMh0HAAAAp+LRuneD2SwAAPgRilIByGazuVdL0cIHAADg5/avkipypfBWUupI02kAAPAbFKUCVFZGmiRp6ZZClVfVGk4DAACAk6pfJdXhaik82mwWAAD8CEWpANWvQ7w6t4tRZY1Tn9LCBwAA4J8sp5Qz27VN6x4AAB4oSgUom82mMf3rW/jyDKcBAABAg/Z9KR3ZK0XES6lXmU4DAIBfoSgVwOpb+D7buk+llTWG0wAAAOAE7ta9cVJYlNksAAD4GYpSAax3apy6JcaqutapTzYXmo4DAACAYznrpNw5rm1a9wAAOAFFqQDmugufa7XUAu7CBwAA4F/2fS4dyZciWkspV5pOAwCA36EoFeCyMlzXlVr+wz4VH6GFDwAAwG/Ut+6lXyOFRZrNAgCAH6IoFeDOTo7T2cmtVFNn6eNNBabjAAAAQJKctT+17nWaaDYLAAB+iqJUEKhv4cumhQ8AAMA/FK2QKoukyLZSynDTaQAA8EsUpYJAfQvfF9v361B5teE0AAAA+Kl171rJHmE2CwAAfoqiVBDolthKfVLjVeu0tJgWPgAAALOctVLue65tWvcAADgpilJBYszR1VK08AEAABhW+JlUtV9ytJeSLzedBgAAv0VRKkiMPXpdqS937Nf+sirDaQAAAEKYu3VvgmQPN5sFAAA/RlEqSHRqF6OMjglyWtKijbTwAQAAGOGskXLfd23TugcAwClRlAoiWe4WvjzDSQAAAEJUwVKp+qAUlSQlDTOdBgAAv0ZRKoiM7u8qSq3eeVBFJZWG0wAAAISgnHdcX9Ovk+xhZrMAAODnKEoFkY5tYjSwU2tZlvTRBi54DgAA4FN11VLuXNc2rXsAAJwWRakgk3X0gucLKEoBAAD4VsESqaZYik6VEi82nQYAAL9HUSrIjDnawvf1rkPKLz5iOA0AAEAI2U3rHgAATUFRKsikJERpcJc2kqQF61ktBQAA4BN1ldLeD1zbnW8wmwUAgABBUSoI1bfwZVOUAgDAL9XV1emRRx5R165dFR0dre7du+upp56SZVnuYyzL0qOPPqrU1FRFR0crMzNT27ZtM5gap5T/sVRTIkV3kNoPNZ0GAICAQFEqCI3qnyK7TVqbe1i5BytMxwEAAMd55plnNGPGDL344ovavHmznnnmGT377LP629/+5j7m2Wef1QsvvKCXX35Zq1evVmxsrEaMGKHKSu6w65fqW/c6XS/ZmGIDANAY/B8zCCXFRWlI13aSuAsfAAD+6Msvv9S4ceM0ZswYdenSRdddd52uuuoqffXVV5Jcq6Sef/55Pfzwwxo3bpwyMjL0+uuvKy8vT/PmzTMbHieqPSLt/dC1TeseAACNRlEqSI3JcF3wnBY+AAD8z4UXXqilS5fqhx9+kCStW7dOn3/+uUaNGiVJ2rlzpwoKCpSZmel+TUJCgoYMGaKVK1c2+J5VVVUqKSnxeMBH8hdKtWVSTCep3RDTaQAACBgUpYLUqH4pCrPbtGFvsXbtLzcdBwAAHOOhhx7SjTfeqF69eikiIkIDBw7U1KlTdfPNN0uSCgoKJEnJycker0tOTnY/d7zp06crISHB/UhPT2/Zk8BPdr/r+trpeslmM5sFAIAAQlEqSLVr5dCF3V0tfAto4QMAwK+8++67mjVrlt566y19++23eu211/SnP/1Jr732WrPfc9q0aSouLnY/cnNzvZgYJ1VbIe2d79qmdQ8AgCahKBXEsmjhAwDAL/3mN79xr5bq37+/br31Vt1///2aPn26JCklJUWSVFhY6PG6wsJC93PHczgcio+P93jAB/IWSHUVUmxXqe15ptMAABBQKEoFsRF9UxRut2lzfol27CszHQcAABxVUVEhu91zGhYWFian0ylJ6tq1q1JSUrR06VL38yUlJVq9erWGDh3q06w4jfrWvc4Tad0DAKCJKEoFsdYxkbr4rPaSpOx1rJYCAMBfjB07Vr/73e+0YMEC7dq1S3PnztVf/vIXXXPNNZIkm82mqVOn6umnn9aHH36oDRs26LbbblNaWprGjx9vNjx+UlPmWiklSZ0mms0CAEAACjcdAC0rKyNNy7buU/b6PP0y8yzTcQAAgKS//e1veuSRR3TPPfeoqKhIaWlp+sUvfqFHH33UfcyDDz6o8vJyTZ48WYcPH9bFF1+sRYsWKSoqymByeNibLdUdkVp1l9oMNJ0GAICAY7MsyzId4lglJSVKSEhQcXEx10LwgpLKGp331CeqrnPq4/sv1dnJcaYjAQDgt4JpHhJM5+K3Vlwr7Zkr9f1/0oDfmU4DAIDfaOw8hPa9IBcfFaFLz06UJGWvyzOcBgAAIEjUlEh5H7m2ad0DAKBZKEqFgGPvwudnC+MAAAAC0575krNKijtbap1hOg0AAAGJolQIyOyTLEe4XT/uL9f3+SWm4wAAAAS+nPq77t3AXfcAAGgmilIhoJUjXJf3TJIkLVjPXfgAAADOSPVhKX+Ra5vWPQAAmo2iVIjIGkALHwAAgFfs+VByVksJfaTW/UynAQAgYFGUChFX9EpSdESYcg5WaMPeYtNxAAAAAld96x6rpAAAOCMUpUJETGS4rujtauHLpoUPAACgeaoPSQUfu7YpSgEAcEYoSoWQsUfvwreAFj4AAIDmyZ0nOWuk1v2lhN6m0wAAENAoSoWQy3omKTYyTHsPH9F3uYdNxwEAAAg8Oe+4vrJKCgCAM0ZRKoRERYQps0+yJCl7HS18AAAATVJ1QCr4xLVNUQoAgDNGUSrEZGWkSZI+2pAvp5MWPgAAgEbLnStZdVKbc6T4s02nAQAg4FGUCjGXnt1ecVHhKiip1JqcQ6bjAAAABA5a9wAA8CqKUiHGER6mq/qkSJKy1+UZTgMAABAgKvdJhZ+6tilKAQDgFRSlQlDW0bvwfbSxQHW08AEAAJxe7vuS5ZTaDpLiuptOAwBAUKAoFYIu6tFeCdER2ldapdU7D5iOAwAA4P9o3QMAwOsoSoWgyHC7RvY92sK3nrvwAQAAnNKRAqlouWubohQAAF5DUSpEZQ1wtfAt2lig2jqn4TQAAAB+LPc9V+teu/OlVl1MpwEAIGhQlApRQ7u1U9vYSB0sr9bKH2nhAwAAOKmcd11fO91gNgcAAEGGolSICg+za2S/+rvw0cIHAADQoIo8qeg/ru1O15nNAgBAkKEoFcLq78K3aFOBqmtp4QMAADhB7hxJltR+qBTbyXQaAACCCkWpEDakazslxjlUfKRGX+zYbzoOAACA/6F1DwCAFkNRKoSF2W0aTQsfAABAwyr2SPu+cG3TugcAgNdRlApxYzLSJEkff1+gqto6w2kAAAD8SM5s19fEi6WYDmazAAAQhChKhbjzOrdRSnyUSitrteIHWvgAAADcdtO6BwBAS6IoFeLsdptG93dd8HzB+jzDaQAAAPxE+W7pwCpJNqnTBNNpAAAIShSloKwBrqLUku8LVVlDCx8AAIC7dS9pmBSdajYLAABBiqIUNDC9tTq0jlZ5dZ2WbS0yHQcAAMC8+ta9zhPN5gAAIIhRlIJsNpvGZLh+Azh/PXfhAwAAIa7sR+ng15LNLnW81nQaAACCFkUpSJKyjhalPt1cpIrqWsNpAAAADHK37l0uRSebzQIAQBCjKAVJUv8OCerUNkZHaur06RZa+AAAQAijdQ8AAJ+gKAVJni182eto4QMAACGqdLt06FvJFkbrHgAALazJRakVK1Zo7NixSktLk81m07x58zyetyxLjz76qFJTUxUdHa3MzExt27bNW3nRgupb+D7bWqSyKlr4AABACMo5ukoqebgU1d5sFgAAglyTi1Ll5eUaMGCAXnrppQaff/bZZ/XCCy/o5Zdf1urVqxUbG6sRI0aosrLyjMOiZfVJjVe39rGqqnVq6eZC03EAAAB8b/c7rq+07gEA0OKaXJQaNWqUnn76aV1zzTUnPGdZlp5//nk9/PDDGjdunDIyMvT6668rLy/vhBVV8D82m829Wmo+LXwAACDUFG+RDq+XbOFSxxPnugAAwLu8ek2pnTt3qqCgQJmZme59CQkJGjJkiFauXNnga6qqqlRSUuLxgDljMtIkSSt+2KfiIzWG0wAAAPhQ/V33Uq6UHG3NZgEAIAR4tShVUFAgSUpO9rx1bnJysvu5402fPl0JCQnuR3p6ujcjoYl6psTprKRWqq5zasn3tPABAIAQkkPrHgAAvmT87nvTpk1TcXGx+5Gbm2s6UsjLOrpaasH6PMNJAAAAfOTwJql4k2SPkDqON50GAICQ4NWiVEpKiiSpsNBzhU1hYaH7ueM5HA7Fx8d7PGDWmKPXlfrPtv06XFFtOA0AAIAPuFv3RkiRrY1GAQAgVHi1KNW1a1elpKRo6dKl7n0lJSVavXq1hg4d6s2PQgvqkdRKvVLiVOu0tHhTw22XAAAAQcOyjmndu8FsFgAAQkiTi1JlZWVau3at1q5dK8l1cfO1a9cqJydHNptNU6dO1dNPP60PP/xQGzZs0G233aa0tDSNHz/ey9HRksYOcLXwZa/nLnwAACDIFW+USrZIdofU8WrTaQAACBnhTX3BN998o8svv9z9/QMPPCBJmjRpkl599VU9+OCDKi8v1+TJk3X48GFdfPHFWrRokaKioryXGi0uKyNVf1y8VV/uOKADZVVq18phOhIAAEDL2H10lVTaSCmCS0kAAOArTS5KXXbZZbIs66TP22w2Pfnkk3ryySfPKBjM6twuVv07JGjD3mIt2lSgm4d0Nh0JAADA+yxLynnXtd2J1j0AAHzJ+N334L+yjl7wPHsdLXwAACBIHV4nlW6TwqKkDlmm0wAAEFIoSuGkRvd3FaVW7zygotJKw2kAAABagLt1b7QUEWc2CwAAIYaiFE4qvW2MzklvLaclLdzAXfgAAECQoXUPAACjKErhlOpb+BZwFz4AABBsDn0rlf0ohcVIHcaYTgMAQMihKIVTGnO0KPX17oMqKKaFDwAABJH61r0OWVJ4rNksAACEIIpSOKXUhGid17mNLEtasIHVUgAAIEh4tO5NNJsFAIAQRVEKp+W+C9/6PMNJAAAAvOTAV1L5btcKqbRRptMAABCSKErhtEb3T5XNJn2Xc1h7DlWYjgMAAHDm6ldJdbhaCo8xmwUAgBBFUQqnlRQfpSFd20qSPqKFDwAABDrLKeXMdm3TugcAgDEUpdAoYzLSJEnZ3IUPAAAEuv2rpIpcKTxOShtpOg0AACGLohQaZVS/FNlt0vo9xdp9oNx0HAAAgOarb93rOE4KizKbBQCAEEZRCo3SvpVDF3ZvL4m78AEAgABG6x4AAH6DohQazX0XvnUUpQAAQIDa94V0JE+KSJBSrzKdBgCAkEZRCo02om+Kwu02fZ9foh/3lZmOAwAA0HTu1r3xUpjDaBQAAEIdRSk0WpvYSF3Uw9XCxwXPAQBAwHHWSTlzXNu07gEAYBxFKTRJfQvfAopSAAAg0Oz7j1RZIEW2kVIyTacBACDkUZRCk1zVN0URYTZtLSzVtsJS03EAAAAaz926d40UFmk2CwAAoCiFpkmIjtClZyVKkuazWgoAAAQKZy2tewAA+BmKUmiyrAFH78K3Pk+WZRlOAwAA0AhFy6WqfZKjnZRyhek0AABAFKXQDJm9kxUZbteP+8q1pYAWPgAAEADcrXvXSvYIs1kAAIAkilJohrioCF3e09XCl70+z3AaAACA03DWSLnvubY732A2CwAAcKMohWbJykiTJGWvz6eFDwAA+LfCz6SqA5IjUUoaZjoNAAA4iqIUmuWKXkmKirBr94EKbdxbYjoOAADAye1+x/U1fYJkDzebBQAAuFGUQrPEOsI1vFeyJFr4AACAH6urlvbMdW3TugcAgF+hKIVmy8qovwsfLXwAAMBPFS6Vqg9JUclS4iWm0wAAgGNQlEKzXd4rSTGRYdp7+IjW5h42HQcAAOBE7ta96yR7mNksAADAA0UpNFtURJgye9e38OUbTgMAAHCcuippzzzXNq17AAD4HYpSOCP1LXwL1ufL6aSFDwAA+JGCJVJNsRSdJiVeZDoNAAA4DkUpnJFhPRMV5whXQUmlvs05ZDoOAADAT+pb9zpdL9mY9gIA4G/4vzPOiCM8TFf2pYUPAAD4mbpKac8Hru1OE81mAQAADaIohTPmbuHbkK86WvgAAIA/yFsk1ZZKMR2l9heYTgMAABpAUQpn7OIeiUqIjtC+0ip9tfOg6TgAAABSzruur50m0roHAICf4v/QOGOR4XaNONrCt2BDnuE0AAD4vy5dushms53wmDJliiSpsrJSU6ZMUbt27dSqVStNmDBBhYWFhlMHkNoj0t4PXdu07gEA4LcoSsErsjLSJEkLNxSots5pOA0AAP7t66+/Vn5+vvuxZMkSSdL1118vSbr//vs1f/58zZ49W8uXL1deXp6uvfZak5EDS95HUm25FNtZane+6TQAAOAkwk0HQHAY2r2d2sRE6EB5tVb9eFAXn9XedCQAAPxWYmKix/d/+MMf1L17dw0bNkzFxcX65z//qbfeektXXHGFJGnmzJnq3bu3Vq1apQsu4PpIp+XRumczmwUAAJwUK6XgFRFhdo3s57rgefZ6WvgAAGis6upqvfnmm7rzzjtls9m0Zs0a1dTUKDMz031Mr1691KlTJ61cudJg0gBRWy7tzXZt07oHAIBfoygFrxl79C58izYVqIYWPgAAGmXevHk6fPiwbr/9dklSQUGBIiMj1bp1a4/jkpOTVVBQcNL3qaqqUklJiccjJO1dINVVSK26SW0HmU4DAABOgaIUvGZIt3Zq3ypShytq9MX2/abjAAAQEP75z39q1KhRSktLO6P3mT59uhISEtyP9PR0LyUMMLTuAQAQMChKwWvC7DaNcrfw5RtOAwCA/9u9e7c++eQT/exnP3PvS0lJUXV1tQ4fPuxxbGFhoVJSUk76XtOmTVNxcbH7kZub21Kx/VdNqZS3wLVN6x4AAH6PohS8KutoC9/iTQWqqq0znAYAAP82c+ZMJSUlacyYMe59gwYNUkREhJYuXeret3XrVuXk5Gjo0KEnfS+Hw6H4+HiPR8jZmy3VVUpxZ0ltzjGdBgAAnAZ334NXDe7SVsnxDhWWVOnzbfs1vHey6UgAAPglp9OpmTNnatKkSQoP/2lKlpCQoLvuuksPPPCA2rZtq/j4eN13330aOnQod947HVr3AAAIKKyUglfZ7TaN7k8LHwAAp/PJJ58oJydHd9555wnPPffcc8rKytKECRN06aWXKiUlRe+//76BlAGkpkTKW+ja7nyD2SwAAKBRKErB67IyXBdqXfJ9oSpraOEDAKAhV111lSzL0tlnn33Cc1FRUXrppZd08OBBlZeX6/333z/l9aQgac+HkrNKiu8lJfQznQYAADQCRSl43cD01kpLiFJZVa2Wbd1nOg4AAAgFtO4BABBwKErB6+x2m8Zk1Lfw5RlOAwAAgl71YSl/kWubu+4BABAwKEqhRdS38C3dXKQj1bTwAQCAFrTnA8lZIyX0lVr3NZ0GAAA0EkUptIiMjglKbxutIzV1+nRLkek4AAAgmO1+x/WVVVIAAAQUilJoETabTWP6u1ZL0cIHAABaTNVBqWCJa5uiFAAAAYWiFFpM1tHrSn26pUhlVbWG0wAAgKC0Z55k1UqtM6SEXqbTAACAJqAohRbTNy1eXdvHqqrWqaWbC03HAQAAwai+da/zDWZzAACAJqMohRZjs9ncq6Wy1+cbTgMAAIJO5X6pcKlrO/16s1kAAECTUZRCixpztCi1fOs+lVTWGE4DAACCyp65klUntRkoxZ9lOg0AAGgiilJoUT2T49QjqZWq65xasokWPgAA4EW07gEAENAoSqFFHdvCt2ADLXwAAMBLKoukos9c251o3QMAIBBRlEKLqy9K/WfbPhVX0MIHAAC8IPc9yXJKbc+TWnUznQYAADQDRSm0uB5JceqVEqeaOkuLNxWYjgMAAILB7nddX2ndAwAgYFGUgk/Ur5aavz7PcBIAABDwjhRIRctd27TuAQAQsChKwSeyMtIkSV/uOKCD5dWG0wAAgICWM0eSJbW7QIrtbDoNAABoJopS8Iku7WPVr0O86pyWFm2khQ8AAJyBnPrWvYlmcwAAgDNCUQo+M6a/a7VUNi18AACguSr2Svs+d22nX2c2CwAAOCMUpeAz9deVWvXjAe0rrTKcBgAABKT61r3Ei6TYdNNpAADAGaAoBZ9JbxujAemt5bSkRRvzTccBAACBqL51rxOtewAABDqKUvCpse678FGUAgAATVSeK+3/UpKN1j0AAIIARSn41Oj+rqLU17sOqrCk0nAaAAAQUHJmu74mXSLFpJnNAgAAzhhFKfhUWutoDercRpYlLWC1FAAAaApa9wAACCoUpeBz9Rc8X7CBohQAAGiksl3SgdWSzS6lTzCdBgAAeIHXi1KPP/64bDabx6NXr17e/hgEsNH9U2WzSWt2H1Le4SOm4wAAgEDgbt0bJkWnmM0CAAC8okVWSvXt21f5+fnux+eff94SH4MAlRwfpfO7tJVECx8AAGgkWvcAAAg6LVKUCg8PV0pKivvRvn37lvgYBLD6Fr7s9XmGkwAAAL9XukM6+A2tewAABJkWKUpt27ZNaWlp6tatm26++Wbl5OS0xMcggI3slyq7TVq3p1g5BypMxwEAAP6svnUv+QopKtFsFgAA4DVeL0oNGTJEr776qhYtWqQZM2Zo586duuSSS1RaWtrg8VVVVSopKfF4IPglxjk0tHs7SVzwHAAAnEbOO66vnW4wmwMAAHiV14tSo0aN0vXXX6+MjAyNGDFCH330kQ4fPqx33323weOnT5+uhIQE9yM9Pd3bkeCnsjLSJNHCBwAATqHkB+nQWskWJqVfYzoNAADwohZp3ztW69atdfbZZ2v79u0NPj9t2jQVFxe7H7m5uS0dCX5iRN8Uhdlt2pRXop37y03HAQAA/qi+dS8lU3K0M5sFAAB4VYsXpcrKyrRjxw6lpqY2+LzD4VB8fLzHA6GhbWykLurhugh+9jpWSwEAgAbQugcAQNDyelHq17/+tZYvX65du3bpyy+/1DXXXKOwsDDddNNN3v4oBIH6u/BxXSkAAHCC4s3S4Q2SPUJKH286DQAA8DKvF6X27Nmjm266ST179tTEiRPVrl07rVq1SomJ3CkFJxrRJ0URYTZtKSjV9qKGL4YPAABClLt170opso3ZLAAAwOvCvf2Gb7/9trffEkEsISZCl5yVqE+3FGn+unzdf2Wc6UgAAMBf0LoHAEBQa/FrSgGnU9/Cl70+T5ZlGU4DAAD8wuFNUvH3kj1S6jjOdBoAANACKErBuCv7JCsy3K4d+8q1tZAWPgAAoJ9WSaWOlCITzGYBAAAtgqIUjIuLitBlZ7uuOZa9jgueAwAQ8ixLynnXtd1potksAACgxVCUgl8YQwsfAACod3iDVLJVsjukjmNNpwEAAC2EohT8QmbvZEVF2LXrQIU25ZWYjgMAAEyqb91LGy1FxJvNAgAAWgxFKfiFWEe4ruiVJEnKXk8LHwAAIcuypN207gEAEAooSsFvZGWkSaKFDwCAkHZorVS2XQqLljpkmU4DAABaEEUp+I3LeyYpJjJMew4d0bo9xabjAAAAE9yte2OkiFZmswAAgBZFUQp+IzoyTMN7J0uSstflGU4DAAB87tjWvc607gEAEOwoSsGvZB29C99HG/LldNLCBwBASDn4jVS+UwqLca2UAgAAQY2iFPzKsLMTFecIV15xpb7LPWQ6DgAA8KWco6ukOoyVwmPMZgEAAC2OohT8SlREmK7s42rhm7+Ou/ABABAyaN0DACDkUJSC3xlzTAtfHS18AACEhgOrpYocKbyVlDrKdBoAAOADFKXgdy45K1HxUeEqKq3SN7sOmo4DAAB8oX6VVIerpfBos1kAAIBPUJSC34kMt2tE3xRJUvZ6WvgAAAh6llPKne3a7nyD2SwAAMBnKErBL2UNSJMkLdyYr9o6p+E0AACgRe1fKVXskSLipdSrTKcBAAA+QlEKfunC7u3UJiZC+8uqtXonLXwAAAQ1d+veOCksymwWAADgMxSl4Jciwuwa2a++hS/PcBoAANBinHW07gEAEKIoSsFvZWW4WvgWbSxQDS18AAAEp/1fSEfypYgEKeVK02kAAIAPUZSC3xrSta3at4rUoYoafbnjgOk4AACgJdS37qVfI4VFms0CAAB8iqIU/Fb4sS1862jhAwAg6DjrpNw5ru1OtO4BABBqKErBr9W38C3eVKDqWlr4AAAIKvtWSJWFUmRbKWW46TQAAMDHKErBrw3u0lZJcQ6VVNbq8+37TMcBAADe5G7du1ayR5jNAgAAfI6iFPxamN2m0f1TJUnZ6/INpwEAAF7jrJVy33Ntd5poNgsAADCCohT8XlaGqyj18feFqqypM5wGAAB4RdEyqWqf5GgvJV9uOg0AADCAohT83rmd2ig1IUplVbVa/gMtfAAABIXd77i+pk+Q7OFmswAAACMoSsHv2e02jTnawrdgPS18AAAEPGeNlPu+a5vWPQAAQhZFKQSErAGuu/B9srlQR6pp4QMAIKAVfCpVH5SikqSkS02nAQAAhlCUQkAY0DFBHdtEq6K6Tp9tLTIdBwAAnImc+ta962jdAwAghFGUQkCw2Wwac/SC59nr8wynAQAAzVZXLeXOdW3TugcAQEijKIWAMTbD1cL36ZYilVfVGk4DAACapeATqeawFJ0qJV5sOg0AADCIohQCRt+0eHVpF6PKGqeWbqGFDwCAgOTRuhdmNgsAADCKohQChs1mU9bR1VLZ62jhAwAg4NRVSXvmubZp3QMAIORRlEJAqb+u1LIf9qm0ssZwGgAA0CT5i6WaEim6g5R4oek0AADAMIpSCCi9UuLUPTFW1bVOfbK50HQcAADQFDnvur52ul6yMQ0FACDUMRtAQPFs4cs3nAYAADRa7RFpzweubVr3AACAKEohAGUdbeFbsW2fiito4QMAICDkL5Jqy6SYTlL7C0ynAQAAfoCiFALOWclx6pkcp5o6S4u/LzAdBwAANIZH657NbBYAAOAXKEohINWvllqwnhY+AAD8Xm2FtHe+a7vzDWazAAAAv0FRCgEpa4DrulJfbN+vQ+XVhtMAAIBTyvtIqi2XYrtIbc8znQYAAPgJilIISF3bx6pvWrxqnZYWbaKFDwAQePbu3atbbrlF7dq1U3R0tPr3769vvvnG/bxlWXr00UeVmpqq6OhoZWZmatu2bQYTnwF3695EWvcAAIAbRSkErDFHW/iy1+cZTgIAQNMcOnRIF110kSIiIrRw4UJ9//33+vOf/6w2bdq4j3n22Wf1wgsv6OWXX9bq1asVGxurESNGqLKy0mDyZqgpk/Zmu7Zp3QMAAMcINx0AaK6s/ml6dtFWrdxxQPtKq5QY5zAdCQCARnnmmWeUnp6umTNnuvd17drVvW1Zlp5//nk9/PDDGjdunCTp9ddfV3JysubNm6cbb7zR55mbLW+BVHdEatVdajPQdBoAAOBHWCmFgNWpXYwGdEyQ0xItfACAgPLhhx/qvPPO0/XXX6+kpCQNHDhQ//jHP9zP79y5UwUFBcrMzHTvS0hI0JAhQ7Ry5UoTkZuP1j0AAHASFKUQ0LIyXBc8z15HCx8AIHD8+OOPmjFjhs466ywtXrxYd999t/7nf/5Hr732miSpoMD1y5bk5GSP1yUnJ7ufO15VVZVKSko8HsbVlLouci7RugcAAE5AUQoBbfTR60p9teugCksC7BobAICQ5XQ6de655+r3v/+9Bg4cqMmTJ+vnP/+5Xn755Wa/5/Tp05WQkOB+pKenezFxM+2dL9VVSnFnS60zTKcBAAB+hqIUAlqH1tE6t1NrWZb00YZ803EAAGiU1NRU9enTx2Nf7969lZOTI0lKSUmRJBUWFnocU1hY6H7ueNOmTVNxcbH7kZub2wLJm6i+da/zDbTuAQCAE1CUQsCrb+FbsJ6iFAAgMFx00UXaunWrx74ffvhBnTt3luS66HlKSoqWLl3qfr6kpESrV6/W0KFDG3xPh8Oh+Ph4j4dR1cVS3kLXdqeJZrMAAAC/RFEKAW90/1TZbNI3uw8p7/AR03EAADit+++/X6tWrdLvf/97bd++XW+99Zb+/ve/a8qUKZIkm82mqVOn6umnn9aHH36oDRs26LbbblNaWprGjx9vNnxj7f1QclZL8b2lhL6m0wAAAD9EUQoBLyUhSoM7t5VECx8AIDAMHjxYc+fO1b///W/169dPTz31lJ5//nndfPPN7mMefPBB3XfffZo8ebIGDx6ssrIyLVq0SFFRUQaTN8Hud1xfad0DAAAnYbMsyzId4lglJSVKSEhQcXGx+WXnCBivr9ylRz/YpAHprfXBlItMxwEABKhgmocYPZfqQ9L7yZKzRhrzvZTQ27efDwAAjGrsPISVUggKo/qlym6T1uUeVu7BCtNxAAAIbXs+cBWkWvenIAUAAE6KohSCQmKcQxd0aydJWkALHwAAZtW37nGBcwAAcAoUpRA0xmSkSpKy1+cZTgIAQAirOiAVfOLapigFAABOgaIUgsaofqkKs9u0cW+Jdu0vNx0HAIDQtGeeZNVKbc6R4s82nQYAAPgxilIIGm1jI3Vhd1r4AAAwitY9AADQSBSlEFTGZqRJkuavo4UPAACfq9wnFX7q2qYoBQAAToOiFILKiL4pigizaUtBqbYXlZmOAwBAaMl9X7LqpLaDpLjuptMAAAA/R1EKQSUhJkIX92gviQueAwDgcznvur6ySgoAADQCRSkEnayjLXwL1nNdKQAAfOZIoVS0zLVNUQoAADQCRSkEnSv7JisyzK5tRWXaWlBqOg4AAKEh9z3JckrtzpdadTGdBgAABACKUgg68VERGtYzURItfAAA+AytewAAoIkoSiEoZWWkSpKy1+fLsizDaQAACHJH8qWiFa7tTtebzQIAAAIGRSkEpeG9k+UIt2vn/nJ9n19iOg4AAMEtZ44kS2o/VIrtZDoNAAAIEBSlEJRaOcJ1Ra8kSa7VUgAAoAXRugcAAJqBohSCVv1d+OasydUH3+3Vyh0HVOeklQ8AAK+q2CPt+9y1TeseAABognDTAYCWUut0SpL2lVbrl++slSSlJkTpsbF9NLJfqsFkaCl1Tktf7TyootJKJcVF6fyubRVmt5mOhRbCeIcWxtsPOeukff+RdvzL9X37i6SYDmYzAQCAgNJiRamXXnpJf/zjH1VQUKABAwbob3/7m84///yW+jjAw6KN+Zr69toT9hcUV+ruN7/VjFvOpTAVZBZtzNcT879XfnGlex9FyODFeIcWxtsP5b4vrfmla5VUveJNrv3p15rLBQAAAorNaoFbk73zzju67bbb9PLLL2vIkCF6/vnnNXv2bG3dulVJSUmnfG1JSYkSEhJUXFys+Ph4b0dDCKhzWrr4mU89/vFyvLaxkfrL9QMUEW6X3WZTmN2mMLvc2z/tO2bbZpPdrmO2jz53zH7PY/kNvq8s2pivu9/8Vsf/ZVY/AhQhgwvjHVp8Pd7BNA9psXPJfV/6z3XSyUblkjkUpgAACHGNnYe0SFFqyJAhGjx4sF588UVJktPpVHp6uu677z499NBDp3xtME0GYcbKHQd00z9WmY4hSZ7FrKOFqmOLVmFHi1g2m07Ybz9aKDthX33hzG5TmM2zGGa3/bT/xGOPLbKpgX3HvMfx7+s+Vg0W7Boq7IXZbLKdQcHv2D8vu00nLfidrghpk5SSEKXP//cKWn2CAOMdWkyMdzDNQ1rkXJx10oddPFdIebBJMR2lq3dK9jDvfCYAAAg4jZ2HeL19r7q6WmvWrNG0adPc++x2uzIzM7Vy5coTjq+qqlJVVZX7+5KSEm9HQogpKj35CqljpSVEqVVUuOqclixLqrMs1TktOZ3W0W3JecI+66d9jSjn1jkt1cmS6s7wpHCC+gKVJUs1dScfDEtSfnGlBj21RJHhdtmO+XerTT9947m/fl/D/8j1OLYJ73f8e3q8exOPb8znemZuxPvYTv1+nnkbk6uJn3+SP4Rjjy+prDnlKsj68b76xc+VEB1x0uNO9ud0KjY17UXN+YymOtl/o6d8TZM/o8kf0YzPaPgVh8qrGzXeX+08qKHd2zXxU9Es+/5zioKUJFlSRa7ruOTLfJUKAAAEKK8Xpfbv36+6ujolJyd77E9OTtaWLVtOOH769Ol64oknvB0DISwpLqpRx/154jln9I8Yy3IVpuoLVT8VsHRCAcuzmOUqeHk8b7kKX8e+37H7PV53zD73tsc+VzbP1+skxx5XhPPI4nqvho9t/Pm2eMGvkQ4fqWn2WCPwbMrjFxyhpLG/jIAXHMn37nEAACCkGb/73rRp0/TAAw+4vy8pKVF6errBRAh053dtq9SEKBUUVzZYsqhv9zi/a9sz+hyb7af2OXhXUwp+3+w6qP9p4KL2x/vDtf3Vv2PCMZ/R0Oces33Mfz2e+z1zNrzf410b8T5Ne89js51ks9nncpLoJ38PX/7ZyNIPhaV6Yel2nc59V/TQWclxDT7XAl3rDXxGM17ThCJrsz+jia9pzp9UU/98T3X0jqIyvbLix9O+R2N/GQEviG7k9bsaexwAAAhpXi9KtW/fXmFhYSosLPTYX1hYqJSUlBOOdzgccjgc3o6BEBZmt+mxsX1095vfyibPf/DUl48eG9uHYpIfa0rBb0xGmqYv3HLaIuT156Uz5kGgzmlp9jd7TjveUzPPZryDQJ3T0ofr8lr8lwxogsRLXNeMqtirhkuKR68plXiJr5MBAIAAZPf2G0ZGRmrQoEFaunSpe5/T6dTSpUs1dOhQb38c0KCR/VI145ZzlZLg+dvzlIQo7swVZOqLkNKJ17GhCBl8GO/Qwnj7IXuYNOivR785yagMep6LnAMAgEZpkbvvvfPOO5o0aZJeeeUVnX/++Xr++ef17rvvasuWLSdca+p4wXTXG5hX57T01c6DKiqtVFKc67fp/OMlOC3amK8n5n/vcVHk1IQoPTa2D0XIIMR4hxZfjncwzUNa9Fxy35fW/NLzoucx6a6CVPq13v0sAAAQcBo7D2mRopQkvfjii/rjH/+ogoICnXPOOXrhhRc0ZMiQ074umCaDAHyLImRoYbxDi6/GO5jmIS1+Ls461132juS7riGVeAkrpAAAgCQ/KEo1VzBNBgEAQGAJpnlIMJ0LAAAILI2dh3j9mlIAAAAAAADA6VCUAgAAAAAAgM9RlAIAAAAAAIDPUZQCAAAAAACAz1GUAgAAAAAAgM9RlAIAAAAAAIDPUZQCAAAAAACAz1GUAgAAAAAAgM9RlAIAAAAAAIDPUZQCAAAAAACAz1GUAgAAAAAAgM+Fmw5wPMuyJEklJSWGkwAAgFBTP/+on48EMuZUAADAlMbOqfyuKFVaWipJSk9PN5wEAACEqtLSUiUkJJiOcUaYUwEAANNON6eyWX72q0Cn06m8vDzFxcXJZrO1yGeUlJQoPT1dubm5io+Pb5HP8EecN+cdCjhvzjsUcN4td96WZam0tFRpaWmy2wP7KgfMqVoO5815hwLOm/MOBZy3+TmV362Ustvt6tixo08+Kz4+PqT+w6vHeYcWzju0cN6hhfNuGYG+Qqoec6qWx3mHFs47tHDeoYXzbhmNmVMF9q8AAQAAAAAAEJAoSgEAAAAAAMDnQrIo5XA49Nhjj8nhcJiO4lOcN+cdCjhvzjsUcN6hdd7+LFTHhPPmvEMB5815hwLO2/x5+92FzgEAAAAAABD8QnKlFAAAAAAAAMyiKAUAAAAAAACfoygFAAAAAAAAnwvaotRLL72kLl26KCoqSkOGDNFXX311yuNnz56tXr16KSoqSv3799dHH33ko6Te1ZTzfvXVV2Wz2TweUVFRPkzrHStWrNDYsWOVlpYmm82mefPmnfY1y5Yt07nnniuHw6EePXro1VdfbfGc3tbU8162bNkJ422z2VRQUOCbwF4wffp0DR48WHFxcUpKStL48eO1devW074u0H++m3PewfDzPWPGDGVkZCg+Pl7x8fEaOnSoFi5ceMrXBPpYS00/72AY64b84Q9/kM1m09SpU095XDCMub9jTsWc6lSYUzGnCiTMqZhTMac6OVNjHpRFqXfeeUcPPPCAHnvsMX377bcaMGCARowYoaKiogaP//LLL3XTTTfprrvu0nfffafx48dr/Pjx2rhxo4+Tn5mmnrckxcfHKz8/3/3YvXu3DxN7R3l5uQYMGKCXXnqpUcfv3LlTY8aM0eWXX661a9dq6tSp+tnPfqbFixe3cFLvaup519u6davHmCclJbVQQu9bvny5pkyZolWrVmnJkiWqqanRVVddpfLy8pO+Jhh+vptz3lLg/3x37NhRf/jDH7RmzRp98803uuKKKzRu3Dht2rSpweODYaylpp+3FPhjfbyvv/5ar7zyijIyMk55XLCMuT9jTsWc6lSYUzGnCrSfb+ZUzKmYUzXM6JhbQej888+3pkyZ4v6+rq7OSktLs6ZPn97g8RMnTrTGjBnjsW/IkCHWL37xixbN6W1NPe+ZM2daCQkJPkrnG5KsuXPnnvKYBx980Orbt6/HvhtuuMEaMWJECyZrWY05788++8ySZB06dMgnmXyhqKjIkmQtX778pMcEy8/3sRpz3sH4821ZltWmTRvr//v//r8GnwvGsa53qvMOtrEuLS21zjrrLGvJkiXWsGHDrF/+8pcnPTaYx9xfMKdyYU7VMOZUh3ySyReYUzGnOlYwjnU95lQNMznmQbdSqrq6WmvWrFFmZqZ7n91uV2ZmplauXNnga1auXOlxvCSNGDHipMf7o+actySVlZWpc+fOSk9PP23VOFgEw3ifiXPOOUepqam68sor9cUXX5iOc0aKi4slSW3btj3pMcE43o05bym4fr7r6ur09ttvq7y8XEOHDm3wmGAc68actxRcYz1lyhSNGTPmhLFsSDCOuT9hTsWc6nSCYbzPBHOqwB9v5lTMqY4XTGMdKHOqoCtK7d+/X3V1dUpOTvbYn5ycfNI+74KCgiYd74+ac949e/bUv/71L33wwQd688035XQ6deGFF2rPnj2+iGzMyca7pKRER44cMZSq5aWmpurll1/We++9p/fee0/p6em67LLL9O2335qO1ixOp1NTp07VRRddpH79+p30uGD4+T5WY887WH6+N2zYoFatWsnhcOi///u/NXfuXPXp06fBY4NprJty3sEy1pL09ttv69tvv9X06dMbdXwwjbk/Yk7FnOp0mFMxpwq0n+9jMadiTnW8YBlrKbDmVOEt/gnwW0OHDvWoEl944YXq3bu3XnnlFT311FMGk6El9OzZUz179nR/f+GFF2rHjh167rnn9MYbbxhM1jxTpkzRxo0b9fnnn5uO4lONPe9g+fnu2bOn1q5dq+LiYs2ZM0eTJk3S8uXLTzqZCBZNOe9gGevc3Fz98pe/1JIlS4LioqIILcHyc4jGYU4VHJhTMac6XrCMdaDNqYKuKNW+fXuFhYWpsLDQY39hYaFSUlIafE1KSkqTjvdHzTnv40VERGjgwIHavn17S0T0Gycb7/j4eEVHRxtKZcb5558fkBOQe++9V9nZ2VqxYoU6dux4ymOD4ee7XlPO+3iB+vMdGRmpHj16SJIGDRqkr7/+Wn/961/1yiuvnHBsMI11U877eIE61mvWrFFRUZHOPfdc9766ujqtWLFCL774oqqqqhQWFubxmmAac3/EnIo51ekwp/oJc6rAwpyKORVzKv+ZUwVd+15kZKQGDRqkpUuXuvc5nU4tXbr0pL2jQ4cO9ThekpYsWXLKXlN/05zzPl5dXZ02bNig1NTUlorpF4JhvL1l7dq1ATXelmXp3nvv1dy5c/Xpp5+qa9eup31NMIx3c877eMHy8+10OlVVVdXgc8Ew1idzqvM+XqCO9fDhw7VhwwatXbvW/TjvvPN08803a+3atSdMnqTgHnN/wJyKOdXpBMN4ewtzqsDAnOonzKlOL1DHOuDmVC1+KXUD3n77bcvhcFivvvqq9f3331uTJ0+2WrdubRUUFFiWZVm33nqr9dBDD7mP/+KLL6zw8HDrT3/6k7V582brsccesyIiIqwNGzaYOoVmaep5P/HEE9bixYutHTt2WGvWrLFuvPFGKyoqytq0aZOpU2iW0tJS67vvvrO+++47S5L1l7/8xfruu++s3bt3W5ZlWQ899JB16623uo//8ccfrZiYGOs3v/mNtXnzZuull16ywsLCrEWLFpk6hWZp6nk/99xz1rx586xt27ZZGzZssH75y19adrvd+uSTT0ydQpPdfffdVkJCgrVs2TIrPz/f/aioqHAfE4w/380572D4+X7ooYes5cuXWzt37rTWr19vPfTQQ5bNZrM+/vhjy7KCc6wtq+nnHQxjfTLH3ykmWMfcnzGnYk7FnIo5Vb1g+PlmTsWcijmViz+NeVAWpSzLsv72t79ZnTp1siIjI63zzz/fWrVqlfu5YcOGWZMmTfI4/t1337XOPvtsKzIy0urbt6+1YMECHyf2jqac99SpU93HJicnW6NHj7a+/fZbA6nPTP1teY9/1J/rpEmTrGHDhp3wmnPOOceKjIy0unXrZs2cOdPnuc9UU8/7mWeesbp3725FRUVZbdu2tS677DLr008/NRO+mRo6X0ke4xeMP9/NOe9g+Pm+8847rc6dO1uRkZFWYmKiNXz4cPckwrKCc6wtq+nnHQxjfTLHT6CCdcz9HXMq5lTMqZhT1Qv0n2/mVMypmFP99L2/jLnNsizL++uvAAAAAAAAgJMLumtKAQAAAAAAwP9RlAIAAAAAAIDPUZQCAAAAAACAz1GUAgAAAAAAgM9RlAIAAAAAAIDPUZQCAAAAAACAz1GUAgAAAAAAgM9RlAIAAAAAAIDPUZQCAEk2m03z5s0zHQMAACCgMacC0BQUpQAYd/vtt8tms53wGDlypOloAAAAAYM5FYBAE246AABI0siRIzVz5kyPfQ6Hw1AaAACAwMScCkAgYaUUAL/gcDiUkpLi8WjTpo0k1zLwGTNmaNSoUYqOjla3bt00Z84cj9dv2LBBV1xxhaKjo9WuXTtNnjxZZWVlHsf861//Ut++feVwOJSamqp7773X4/n9+/frmmuuUUxMjM466yx9+OGHLXvSAAAAXsacCkAgoSgFICA88sgjmjBhgtatW6ebb75ZN954ozZv3ixJKi8v14gRI9SmTRt9/fXXmj17tj755BOPCdKMGTM0ZcoUTZ48WRs2bNCHH36oHj16eHzGE088oYkTJ2r9+vUaPXq0br75Zh08eNCn5wkAANCSmFMB8CsWABg2adIkKywszIqNjfV4/O53v7Msy7IkWf/93//t8ZohQ4ZYd999t2VZlvX3v//datOmjVVWVuZ+fsGCBZbdbrcKCgosy7KstLQ067e//e1JM0iyHn74Yff3ZWVlliRr4cKFXjtPAACAlsScCkCg4ZpSAPzC5ZdfrhkzZnjsa9u2rXt76NChHs8NHTpUa9eulSRt3rxZAwYMUGxsrPv5iy66SE6nU1u3bpXNZlNeXp6GDx9+ygwZGRnu7djYWMXHx6uoqKi5pwQAAOBzzKkABBKKUgD8Qmxs7AlLv70lOjq6UcdFRER4fG+z2eR0OlsiEgAAQItgTgUgkHBNKQABYdWqVSd837t3b0lS7969tW7dOpWXl7uf/+KLL2S329WzZ0/FxcWpS5cuWrp0qU8zAwAA+BvmVAD8CSulAPiFqqoqFRQUeOwLDw9X+/btJUmzZ8/Weeedp4svvlizZs3SV199pX/+85+SpJtvvlmPPfaYJk2apMcff1z79u3Tfffdp1tvvVXJycmSpMcff1z//d//raSkJI0aNUqlpaX64osvdN999/n2RAEAAFoQcyoAgYSiFAC/sGjRIqWmpnrs69mzp7Zs2SLJdReXt99+W/fcc49SU1P173//W3369JEkxcTEaPHixfrlL3+pwYMHKyYmRhMmTNBf/vIX93tNmjRJlZWVeu655/TrX/9a7du313XXXee7EwQAAPAB5lQAAonNsizLdAgAOBWbzaa5c+dq/PjxpqMAAAAELOZUAPwN15QCAAAAAACAz1GUAgAAAAAAgM/RvgcAAAAAAACfY6UUAAAAAAAAfI6iFAAAAAAAAHyOohQAAAAAAAB8jqIUAAAAAAAAfI6iFAAAAAAAAHyOohQAAAAAAAB8jqIUAAAAAAAAfI6iFAAAAAAAAHyOohQAAAAAAAB87v8Hva58C/YG/dsAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# ------------------------------\n",
        "# 1. DataLoader for MNIST\n",
        "# ------------------------------\n",
        "def get_data_loaders(batch_size=64):\n",
        "    \"\"\"\n",
        "    Returns train and test DataLoader for MNIST dataset.\n",
        "    \"\"\"\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "    test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# 2. MoE Components\n",
        "# ------------------------------\n",
        "\n",
        "class GatingNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    A gating network that outputs a distribution over experts\n",
        "    and the top-k selected expert indices.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, num_experts, top_k=1):\n",
        "        super(GatingNetwork, self).__init__()\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(in_channels, num_experts)\n",
        "        self.top_k = top_k\n",
        "        # We'll store the last top_k indices for external use (placement training)\n",
        "        self.last_topk_indices = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        pooled = self.global_pool(x).view(batch_size, -1)\n",
        "        logits = self.fc(pooled)  # shape: (batch_size, num_experts)\n",
        "\n",
        "        topk_logits, topk_indices = torch.topk(logits, self.top_k, dim=1)\n",
        "        topk_weights = F.softmax(topk_logits, dim=1)\n",
        "\n",
        "        # Create a sparse weights tensor (batch_size, num_experts) with zeros everywhere\n",
        "        sparse_weights = torch.zeros_like(logits)\n",
        "        sparse_weights.scatter_(1, topk_indices, topk_weights)\n",
        "\n",
        "        # Store these indices for later usage (placement)\n",
        "        self.last_topk_indices = topk_indices.detach()\n",
        "\n",
        "        return sparse_weights, topk_indices\n",
        "\n",
        "\n",
        "class Expert(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple CNN expert: Conv -> BN -> ReLU.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Expert, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(self.bn(self.conv(x)))\n",
        "\n",
        "\n",
        "class MoEBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Mixture-of-Experts block:\n",
        "     - Gating network to select top_k experts\n",
        "     - Weighted sum of expert outputs\n",
        "     - Optional load-balance calculation\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, num_experts=4, top_k=1):\n",
        "        super(MoEBlock, self).__init__()\n",
        "        self.num_experts = num_experts\n",
        "        self.top_k = top_k\n",
        "        self.experts = nn.ModuleList([Expert(in_channels, out_channels)\n",
        "                                      for _ in range(num_experts)])\n",
        "        self.gate = GatingNetwork(in_channels, num_experts, top_k=top_k)\n",
        "        self.out_conv = nn.Conv2d(out_channels, out_channels, kernel_size=1)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # gating\n",
        "        gate_weights, topk_indices = self.gate(x)\n",
        "\n",
        "        # Compute each expert’s output\n",
        "        expert_outputs = [expert(x) for expert in self.experts]\n",
        "        # Stack along a new dimension => shape: (batch, num_experts, C, H, W)\n",
        "        expert_stack = torch.stack(expert_outputs, dim=1)\n",
        "        # Reshape gate weights => (batch, num_experts, 1, 1, 1)\n",
        "        gate_weights = gate_weights.view(-1, self.num_experts, 1, 1, 1)\n",
        "        # Weighted sum\n",
        "        out = (expert_stack * gate_weights).sum(dim=1)\n",
        "\n",
        "        # A little post-processing\n",
        "        out = self.relu(self.bn(self.out_conv(out)))\n",
        "\n",
        "        # (Optional) load balance loss or usage stats\n",
        "        # We'll define them as placeholders so the signature remains\n",
        "        batch_size = x.size(0)\n",
        "        importance = gate_weights.squeeze().sum(0)\n",
        "        diversity = (gate_weights.squeeze() > 0).float().sum(0)\n",
        "        mean_importance = importance / batch_size\n",
        "        mean_diversity = diversity / batch_size\n",
        "        load_balance_loss = (mean_importance * mean_diversity).sum()\n",
        "\n",
        "        # Expert distribution\n",
        "        flat_indices = topk_indices.view(-1)\n",
        "        counts = torch.bincount(flat_indices, minlength=self.num_experts)\n",
        "        proportions = counts.float() / (batch_size * self.top_k)\n",
        "\n",
        "        return out, load_balance_loss, proportions\n",
        "\n",
        "\n",
        "class MoEClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple 2-layer MoE CNN for MNIST classification.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=10, num_experts=4, top_k=1):\n",
        "        super(MoEClassifier, self).__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "\n",
        "        self.moe_block1 = MoEBlock(32, 64, num_experts, top_k)\n",
        "        self.moe_block2 = MoEBlock(64, 128, num_experts, top_k)\n",
        "\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lb_loss = 0.0\n",
        "        gate_dists = []\n",
        "\n",
        "        x = self.initial(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x, lb1, dist1 = self.moe_block1(x)\n",
        "        lb_loss += lb1\n",
        "        gate_dists.append(dist1)\n",
        "\n",
        "        x = self.pool(x)\n",
        "        x, lb2, dist2 = self.moe_block2(x)\n",
        "        lb_loss += lb2\n",
        "        gate_dists.append(dist2)\n",
        "\n",
        "        x = self.global_pool(x).view(x.size(0), -1)\n",
        "        logits = self.fc(x)\n",
        "\n",
        "        return logits, lb_loss, gate_dists\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# 3. Training and Testing (Base Model)\n",
        "# ------------------------------\n",
        "def train_base_model(model, device, train_loader, optimizer, criterion, epoch, aux_coeff):\n",
        "    \"\"\"\n",
        "    Train loop for the MoE base model.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits, aux_loss, gate_dists = model(data)\n",
        "        loss = criterion(logits, target) + aux_coeff * aux_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        pred = logits.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)}]\")\n",
        "            print(f\"  Loss: {loss.item():.6f}\")\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    accuracy = 100.0 * correct / len(train_loader.dataset)\n",
        "    print(f\"Epoch {epoch} - Base Model Train Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "def tes_base_model(model, device, test_loader, criterion):\n",
        "    \"\"\"\n",
        "    Test loop for the MoE base model.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    # For distribution stats\n",
        "    gate1_total = torch.zeros(model.moe_block1.num_experts).to(device)\n",
        "    gate2_total = torch.zeros(model.moe_block2.num_experts).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            batch_size = data.size(0)\n",
        "            logits, _, gate_dists = model(data)\n",
        "\n",
        "            loss = criterion(logits, target)\n",
        "            test_loss += loss.item()\n",
        "            pred = logits.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            total_samples += batch_size\n",
        "\n",
        "            # Accumulate gating distribution\n",
        "            gate1_total += gate_dists[0] * batch_size\n",
        "            gate2_total += gate_dists[1] * batch_size\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    accuracy = 100.0 * correct / total_samples\n",
        "    print(f\"Base Model Test - Loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    # Print average distribution\n",
        "    gate1_avg = (gate1_total / total_samples).cpu().numpy()\n",
        "    gate2_avg = (gate2_total / total_samples).cpu().numpy()\n",
        "    print(\"Block1 Dist (%):\", \" \".join([f\"{100*d:.1f}\" for d in gate1_avg]))\n",
        "    print(\"Block2 Dist (%):\", \" \".join([f\"{100*d:.1f}\" for d in gate2_avg]))\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# 4. Network Topology (Server <-> Devices)\n",
        "# ------------------------------\n",
        "# class NetworkTopology:\n",
        "#     \"\"\"\n",
        "#     Minimal example: server is ID=0, devices are 1..N.\n",
        "#     'comm_cost[i]' is cost from server to device i.\n",
        "#     \"\"\"\n",
        "#     def __init__(self, num_devices=3, base_cost=5.0):\n",
        "#         self.num_devices = num_devices\n",
        "#         # cost[0] for server => 0\n",
        "#         # cost[i] for device i => base_cost + small random\n",
        "#         self.comm_cost = [0.0]\n",
        "#         for i in range(1, num_devices+1):\n",
        "#             cost_i = base_cost + np.random.rand() * 2.0\n",
        "#             self.comm_cost.append(cost_i)\n",
        "\n",
        "#     def get_cost(self, device_id):\n",
        "#         return self.comm_cost[device_id]\n",
        "\n",
        "# ------------------------------\n",
        "# Modified Network Topology Class\n",
        "# ------------------------------\n",
        "class DynamicNetworkTopology:\n",
        "    \"\"\"\n",
        "    Generates new random costs for server-device links every time reset() is called.\n",
        "    Server is ID=0, devices are 1..N.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_devices=3, base_cost_range=(3.0, 7.0)):\n",
        "        self.num_devices = num_devices\n",
        "        self.base_cost_range = base_cost_range\n",
        "        self.comm_cost = [0.0]  # Server cost is always 0\n",
        "        self.reset()  # Initialize first topology\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Generate new random costs for device links\"\"\"\n",
        "        self.comm_cost = [0.0]  # Server\n",
        "        for _ in range(self.num_devices):\n",
        "            base_cost = np.random.uniform(*self.base_cost_range)\n",
        "            self.comm_cost.append(base_cost)\n",
        "\n",
        "    def get_cost(self, device_id):\n",
        "        return self.comm_cost[device_id]\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Topology: Server(0.0) -> Devices{self.comm_cost[1:]}\"\n",
        "\n",
        "# ------------------------------\n",
        "# 5. Placement Selector Model\n",
        "# ------------------------------\n",
        "class PlacementSelector(nn.Module):\n",
        "    \"\"\"\n",
        "    Predicts device placements for each selected expert.\n",
        "    For demonstration: uses an embedding of (layer_id, expert_id) to\n",
        "    produce a distribution over device_id in [0..num_devices].\n",
        "    \"\"\"\n",
        "    def __init__(self, num_layers, num_experts, num_devices=3, embedding_dim=16):\n",
        "        super(PlacementSelector, self).__init__()\n",
        "        self.num_devices = num_devices\n",
        "        # total_expert_keys = num_layers * num_experts\n",
        "        self.num_layers = num_layers\n",
        "        self.num_experts = num_experts\n",
        "\n",
        "        # We create a single embedding to handle (layer_id, expert_id) => index\n",
        "        self.embedding = nn.Embedding(num_layers * num_experts, embedding_dim)\n",
        "        # Output distribution over [0..num_devices], i.e. (num_devices+1) possibilities\n",
        "        self.fc = nn.Linear(embedding_dim, num_devices+1)\n",
        "\n",
        "    def forward(self, layer_ids, expert_ids):\n",
        "        \"\"\"\n",
        "        :param layer_ids:   (batch, top_k)\n",
        "        :param expert_ids:  (batch, top_k)\n",
        "        :return: device_probs => (batch, top_k, num_devices+1)\n",
        "        \"\"\"\n",
        "        # Convert (layer_id, expert_id) to single index\n",
        "        # index = layer_id * num_experts + expert_id\n",
        "        combined_key = layer_ids * self.num_experts + expert_ids\n",
        "        flat_key = combined_key.view(-1)\n",
        "        emb = self.embedding(flat_key)  # shape: (batch*top_k, embedding_dim)\n",
        "        logits = self.fc(emb)           # shape: (batch*top_k, num_devices+1)\n",
        "        device_probs = F.softmax(logits, dim=-1)\n",
        "        # Reshape\n",
        "        B, K = combined_key.shape\n",
        "        device_probs = device_probs.view(B, K, -1)\n",
        "        return device_probs\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# 6. Communication-Cost–Based Loss (Corrected)\n",
        "# ------------------------------\n",
        "def compute_placement_loss(device_probs, topology):\n",
        "    \"\"\"\n",
        "    Returns differentiable loss based on expected cost, correct count, and total experts.\n",
        "    \"\"\"\n",
        "    batch_size, top_k, num_dev_plus_one = device_probs.size()\n",
        "\n",
        "    # Convert topology costs to a tensor on the correct device\n",
        "    device_costs = torch.tensor(topology.comm_cost, device=device_probs.device, dtype=torch.float32)  # shape: (num_devices+1,)\n",
        "\n",
        "    # Calculate expected cost for each expert (batch_size, top_k)\n",
        "    expected_cost_per_expert = torch.einsum('bkd,d->bk', device_probs, device_costs)\n",
        "\n",
        "    # The ideal cost is 0.0 (server), so loss is just the average expected cost\n",
        "    loss = expected_cost_per_expert.mean()\n",
        "\n",
        "    # Calculate accuracy: how often server (device 0) is chosen\n",
        "    chosen_devices = torch.argmax(device_probs, dim=-1)  # (batch_size, top_k)\n",
        "    correct = (chosen_devices == 0).sum().item()\n",
        "    total_experts = batch_size * top_k\n",
        "\n",
        "    return loss, correct, total_experts\n",
        "\n",
        "\n",
        "# # ------------------------------\n",
        "# # 7. Train the Placement Selector (Updated with corrected loss)\n",
        "# # ------------------------------\n",
        "# def train_placement_selector(base_model, placement_model, device,\n",
        "#                              train_loader, optimizer, topology, num_layers):\n",
        "#     \"\"\"\n",
        "#     Trains placement selector with differentiable loss.\n",
        "#     \"\"\"\n",
        "#     base_model.eval()\n",
        "#     placement_model.train()\n",
        "\n",
        "#     total_loss = 0.0\n",
        "#     total_correct = 0\n",
        "#     total_experts = 0\n",
        "\n",
        "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
        "#         data = data.to(device)\n",
        "#         _ = target.to(device)  # not needed for placement training\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         # Forward pass to get top-k indices\n",
        "#         with torch.no_grad():\n",
        "#             _ = base_model(data)\n",
        "\n",
        "#         # Get expert selections from both MoE blocks\n",
        "#         topk_indices_block1 = base_model.moe_block1.gate.last_topk_indices\n",
        "#         layer_ids_block1 = torch.zeros_like(topk_indices_block1, device=device)\n",
        "\n",
        "#         topk_indices_block2 = base_model.moe_block2.gate.last_topk_indices\n",
        "#         layer_ids_block2 = torch.ones_like(topk_indices_block2, device=device)\n",
        "\n",
        "#         # Get placement predictions\n",
        "#         device_probs_block1 = placement_model(layer_ids_block1, topk_indices_block1)\n",
        "#         device_probs_block2 = placement_model(layer_ids_block2, topk_indices_block2)\n",
        "\n",
        "#         # Calculate loss and accuracy metrics\n",
        "#         loss_block1, correct1, total1 = compute_placement_loss(device_probs_block1, topology)\n",
        "#         loss_block2, correct2, total2 = compute_placement_loss(device_probs_block2, topology)\n",
        "#         loss = loss_block1 + loss_block2\n",
        "\n",
        "#         # Update accuracy counters\n",
        "#         total_correct += correct1 + correct2\n",
        "#         total_experts += total1 + total2\n",
        "\n",
        "#         # Backpropagation\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         # Track loss\n",
        "#         total_loss += loss.item()\n",
        "\n",
        "#         # Print batch stats\n",
        "#         if batch_idx % 100 == 0 and total1 + total2 > 0:\n",
        "#             batch_acc = ((correct1 + correct2) / (total1 + total2)) * 100.0\n",
        "#             print(f\"[{batch_idx}/{len(train_loader)}] Placement Loss: {loss.item():.4f}, Accuracy: {batch_acc:.2f}%\")\n",
        "\n",
        "#     # Calculate final metrics\n",
        "#     avg_loss = total_loss / len(train_loader)\n",
        "#     overall_acc = (total_correct / total_experts) * 100.0 if total_experts > 0 else 0.0\n",
        "#     print(f\"Placement Training - Avg Cost Loss: {avg_loss:.4f}, Accuracy: {overall_acc:.2f}%\")\n",
        "\n",
        "# ------------------------------\n",
        "# Modified Training Function\n",
        "# ------------------------------\n",
        "def train_placement_selector(base_model, placement_model, device,\n",
        "                             train_loader, optimizer, topology_config,\n",
        "                             num_layers, num_epochs):\n",
        "    \"\"\"\n",
        "    Now handles dynamic topology changes between epochs\n",
        "    \"\"\"\n",
        "    # Track metrics across epochs\n",
        "    epoch_losses = []\n",
        "    epoch_accuracies = []\n",
        "    topology_samples = []\n",
        "\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        # Create new topology for this epoch\n",
        "        current_topology = DynamicNetworkTopology(**topology_config)\n",
        "        topology_samples.append(current_topology)\n",
        "        print(f\"\\n=== Epoch {epoch} ===\")\n",
        "        print(current_topology)\n",
        "\n",
        "        # Training loop with current topology\n",
        "        base_model.eval()\n",
        "        placement_model.train()\n",
        "\n",
        "        total_loss = 0.0\n",
        "        total_correct = 0\n",
        "        total_experts = 0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data = data.to(device)\n",
        "            _ = target.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass to get top-k indices\n",
        "            with torch.no_grad():\n",
        "                _ = base_model(data)\n",
        "\n",
        "            # Get expert selections from both MoE blocks\n",
        "            topk_indices_block1 = base_model.moe_block1.gate.last_topk_indices\n",
        "            layer_ids_block1 = torch.zeros_like(topk_indices_block1, device=device)\n",
        "\n",
        "            topk_indices_block2 = base_model.moe_block2.gate.last_topk_indices\n",
        "            layer_ids_block2 = torch.ones_like(topk_indices_block2, device=device)\n",
        "\n",
        "            # Get placement predictions\n",
        "            device_probs_block1 = placement_model(layer_ids_block1, topk_indices_block1)\n",
        "            device_probs_block2 = placement_model(layer_ids_block2, topk_indices_block2)\n",
        "\n",
        "            # Calculate loss and accuracy metrics\n",
        "            loss_block1, correct1, total1 = compute_placement_loss(device_probs_block1, current_topology)\n",
        "            loss_block2, correct2, total2 = compute_placement_loss(device_probs_block2, current_topology)\n",
        "            loss = loss_block1 + loss_block2\n",
        "\n",
        "            # Update counters\n",
        "            total_correct += correct1 + correct2\n",
        "            total_experts += total1 + total2\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Backpropagation\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Calculate epoch metrics\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        accuracy = (total_correct / total_experts) * 100 if total_experts > 0 else 0\n",
        "        epoch_losses.append(avg_loss)\n",
        "        epoch_accuracies.append(accuracy)\n",
        "\n",
        "        print(f\"Epoch {epoch} - Avg Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "        # Test on new unseen topology\n",
        "        test_topology = DynamicNetworkTopology(**topology_config)\n",
        "        test_placement_selector(placement_model, base_model, device,\n",
        "                               train_loader, test_topology)\n",
        "\n",
        "    return epoch_losses, epoch_accuracies, topology_samples\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Test Function with Dynamic Topology\n",
        "# ------------------------------\n",
        "def test_placement_selector(placement_model, base_model, device,\n",
        "                           test_loader, topology):\n",
        "    \"\"\"Evaluate placement selector on a new topology\"\"\"\n",
        "    placement_model.eval()\n",
        "    base_model.eval()\n",
        "\n",
        "    total_correct = 0\n",
        "    total_experts = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, _ in test_loader:\n",
        "            data = data.to(device)\n",
        "\n",
        "            # Forward pass through base model\n",
        "            _ = base_model(data)\n",
        "\n",
        "            # Get expert selections\n",
        "            topk_indices_block1 = base_model.moe_block1.gate.last_topk_indices\n",
        "            layer_ids_block1 = torch.zeros_like(topk_indices_block1, device=device)\n",
        "\n",
        "            topk_indices_block2 = base_model.moe_block2.gate.last_topk_indices\n",
        "            layer_ids_block2 = torch.ones_like(topk_indices_block2, device=device)\n",
        "\n",
        "            # Get placements\n",
        "            device_probs_block1 = placement_model(layer_ids_block1, topk_indices_block1)\n",
        "            device_probs_block2 = placement_model(layer_ids_block2, topk_indices_block2)\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, correct1, total1 = compute_placement_loss(device_probs_block1, topology)\n",
        "            _, correct2, total2 = compute_placement_loss(device_probs_block2, topology)\n",
        "\n",
        "            total_correct += correct1 + correct2\n",
        "            total_experts += total1 + total2\n",
        "\n",
        "    accuracy = (total_correct / total_experts) * 100 if total_experts > 0 else 0\n",
        "    print(f\"Test on {topology} => Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# 8. Main: Train base model, then freeze & train placement\n",
        "# ------------------------------\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    # Prepare data\n",
        "    train_loader, test_loader = get_data_loaders(batch_size=64)\n",
        "\n",
        "    # -------------------------\n",
        "    # A) Train the base MoE model\n",
        "    # -------------------------\n",
        "    num_experts = 8\n",
        "    top_k = 2\n",
        "    base_model = MoEClassifier(num_experts=num_experts, top_k=top_k).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(base_model.parameters(), lr=0.001)\n",
        "    aux_coeff = 0.01\n",
        "    print(\"\\n--- Training Base MoE Model ---\")\n",
        "    base_epochs = 1  # keep it small for demo\n",
        "    for epoch in range(1, base_epochs+1):\n",
        "        train_base_model(base_model, device, train_loader, optimizer, criterion, epoch, aux_coeff)\n",
        "        tes_base_model(base_model, device, test_loader, criterion)\n",
        "\n",
        "    # Save the trained model\n",
        "    base_model_path = \"moe_mnist_balanced.pth\"\n",
        "    torch.save(base_model.state_dict(), base_model_path)\n",
        "    print(f\"Base model saved to {base_model_path}.\")\n",
        "\n",
        "    # -------------------------\n",
        "    # B) Load the pretrained MoE in a frozen state\n",
        "    # -------------------------\n",
        "    frozen_model = MoEClassifier(num_experts=num_experts, top_k=top_k).to(device)\n",
        "    frozen_model.load_state_dict(torch.load(base_model_path, map_location=device))\n",
        "\n",
        "    for param in frozen_model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # -------------------------\n",
        "    # C) Create a topology and the PlacementSelector\n",
        "    # -------------------------\n",
        "    # Create placement model with dynamic topology\n",
        "    topology_config = {\n",
        "        \"num_devices\": 100,\n",
        "        \"base_cost_range\": (10,100)  # Random costs between 2-8 each epoch\n",
        "    }\n",
        "\n",
        "    placement_model = PlacementSelector(num_layers=2,\n",
        "                                       num_experts=num_experts,\n",
        "                                       num_devices=topology_config[\"num_devices\"],\n",
        "                                       embedding_dim=16).to(device)\n",
        "\n",
        "    placement_optimizer = optim.Adam(placement_model.parameters(), lr=1e-3)\n",
        "\n",
        "    # -------------------------\n",
        "    # D) Train the placement selector\n",
        "    # -------------------------\n",
        "    # Train with dynamic topologies\n",
        "    print(\"\\n--- Training Placement Selector with Dynamic Topologies ---\")\n",
        "    losses, accs, topologies = train_placement_selector(\n",
        "        frozen_model, placement_model, device,\n",
        "        train_loader, placement_optimizer,\n",
        "        topology_config=topology_config,\n",
        "        num_layers=2,\n",
        "        num_epochs=5\n",
        "    )\n",
        "\n",
        "    # Save model and visualize training\n",
        "    placement_path = \"dynamic_placement_selector.pth\"\n",
        "    torch.save(placement_model.state_dict(), placement_path)\n",
        "    print(f\"Placement selector saved to {placement_path}.\")\n",
        "\n",
        "    # Plot training progress\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(losses, marker='o')\n",
        "    plt.title(\"Training Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(accs, marker='o', color='orange')\n",
        "    plt.title(\"Training Accuracy\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Make sure we're not cluttering with old plots, etc.\n",
        "    # You can remove or comment out these lines if desired\n",
        "    if not os.path.exists(\"./data\"):\n",
        "        os.makedirs(\"./data\")\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "laTvYrdJGtA6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}