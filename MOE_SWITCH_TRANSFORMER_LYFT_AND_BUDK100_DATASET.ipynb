{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyND4YeurLxdMNNfMMp7MYZ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khanmhmdi/Moe-llm-edge-computing/blob/main/MOE_SWITCH_TRANSFORMER_LYFT_AND_BUDK100_DATASET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nre7nNJA9Tk3",
        "outputId": "bb233cb9-72b6-4b48-cf1f-6d4e1d6abc3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmentation logits shape: torch.Size([2, 21, 224, 224])\n",
            "Backward pass successful!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Image patch embedding\n",
        "# -----------------------------\n",
        "class PatchEmbedding(nn.Module):\n",
        "    def __init__(self, img_size=224, patch_size=16, in_channels=3, embed_dim=768):\n",
        "        super().__init__()\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = (img_size // patch_size) ** 2\n",
        "        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, self.num_patches, embed_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, C, H, W]\n",
        "        x = self.proj(x)  # [B, embed_dim, H/patch_size, W/patch_size]\n",
        "        x = x.flatten(2)  # [B, embed_dim, num_patches]\n",
        "        x = x.transpose(1, 2)  # [B, num_patches, embed_dim]\n",
        "        x += self.pos_embedding\n",
        "        return x\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Switch MoE Feed-forward module\n",
        "# -----------------------------\n",
        "class ExpertFFN(nn.Module):\n",
        "    def __init__(self, embed_dim, expansion=4):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(embed_dim, embed_dim * expansion)\n",
        "        self.fc2 = nn.Linear(embed_dim * expansion, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.gelu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class SwitchFFN(nn.Module):\n",
        "    def __init__(self, embed_dim, num_experts=4, expansion=4, capacity_factor=1.0):\n",
        "        super().__init__()\n",
        "        self.num_experts = num_experts\n",
        "        self.capacity_factor = capacity_factor\n",
        "\n",
        "        # Instantiate experts as a ModuleList\n",
        "        self.experts = nn.ModuleList([ExpertFFN(embed_dim, expansion=expansion) for _ in range(num_experts)])\n",
        "        # Gating network (top-1 gating)\n",
        "        self.gate = nn.Linear(embed_dim, num_experts)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, num_tokens, embed_dim]\n",
        "        B, N, D = x.shape\n",
        "        logits = self.gate(x)  # [B, N, num_experts]\n",
        "        # Choose top-1 expert for each token\n",
        "        indices = logits.argmax(dim=-1)  # [B, N]\n",
        "\n",
        "        # Create output tensor\n",
        "        output = torch.zeros_like(x)\n",
        "        # For auxiliary loss (optional, not computed here)\n",
        "        expert_counts = torch.zeros(x.size(0), self.num_experts, device=x.device)\n",
        "\n",
        "        # Dispatch tokens to experts (this is a basic loop version; for efficiency, consider vectorizing or using libraries)\n",
        "        for expert_id in range(self.num_experts):\n",
        "            # Find tokens assigned to this expert\n",
        "            mask = (indices == expert_id)  # [B, N] boolean mask\n",
        "            if mask.sum() == 0:\n",
        "                continue\n",
        "            # Get the indices of tokens to be processed\n",
        "            selected_tokens = x[mask]  # [num_selected, D]\n",
        "            expert_output = self.experts[expert_id](selected_tokens)  # Process tokens\n",
        "            output[mask] = expert_output\n",
        "            expert_counts[:, expert_id] += mask.sum(dim=-1).float()\n",
        "        return output, expert_counts  # return expert counts if you want to add auxiliary loss\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Switch Transformer Layer\n",
        "# -----------------------------\n",
        "class SwitchTransformerLayer(nn.Module):\n",
        "    def __init__(self, embed_dim, num_experts=4, expansion=4, num_heads=8, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.switch_ffn = SwitchFFN(embed_dim, num_experts=num_experts, expansion=expansion)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Self-attention block\n",
        "        attn_out, _ = self.self_attn(x, x, x)\n",
        "        x = x + self.dropout(attn_out)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # Switch MoE FFN block\n",
        "        ffn_out, expert_counts = self.switch_ffn(x)\n",
        "        x = x + self.dropout(ffn_out)\n",
        "        x = self.norm2(x)\n",
        "        return x, expert_counts\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Encoder with multiple Switch Transformer Layers\n",
        "# -----------------------------\n",
        "class SwitchTransformerEncoder(nn.Module):\n",
        "    def __init__(self, depth, embed_dim, num_experts=4, expansion=4, num_heads=8, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            SwitchTransformerLayer(embed_dim, num_experts, expansion, num_heads, dropout)\n",
        "            for _ in range(depth)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        expert_loss = 0.0  # sum of auxiliary losses from each layer (if computed)\n",
        "        for layer in self.layers:\n",
        "            x, expert_counts = layer(x)\n",
        "            # Optionally: Compute a load-balancing loss with expert_counts here\n",
        "            # For instance, a simple loss that penalizes deviation from even load distribution.\n",
        "            # expert_loss += compute_auxiliary_loss(expert_counts)\n",
        "        return x, expert_loss\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Segmentation Decoder\n",
        "# -----------------------------\n",
        "class SegmentationDecoder(nn.Module):\n",
        "    def __init__(self, embed_dim, num_patches, img_size=224, patch_size=16, num_classes=21):\n",
        "        super().__init__()\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches_side = img_size // patch_size\n",
        "\n",
        "        # A simple decoder that reshape tokens back to spatial map and applies a conv layer.\n",
        "        self.conv1 = nn.Conv2d(embed_dim, embed_dim // 2, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(embed_dim // 2)\n",
        "        self.conv2 = nn.Conv2d(embed_dim // 2, num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, num_patches, embed_dim]\n",
        "        B, N, D = x.shape\n",
        "        H = W = self.num_patches_side\n",
        "        x = x.transpose(1, 2).reshape(B, D, H, W)  # [B, D, H, W]\n",
        "\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        # Upsample to original image size\n",
        "        x = F.interpolate(x, size=(self.img_size, self.img_size), mode='bilinear', align_corners=False)\n",
        "        logits = self.conv2(x)  # [B, num_classes, img_size, img_size]\n",
        "        return logits\n",
        "\n",
        "# -----------------------------\n",
        "# 6. Full Model\n",
        "# -----------------------------\n",
        "class SwitchTransformerSegmentationModel(nn.Module):\n",
        "    def __init__(self, img_size=224, patch_size=16, in_channels=3, embed_dim=768, depth=6,\n",
        "                 num_experts=4, expansion=4, num_heads=8, dropout=0.1, num_classes=21):\n",
        "        super().__init__()\n",
        "        self.patch_embedding = PatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n",
        "        num_patches = (img_size // patch_size) ** 2\n",
        "        self.encoder = SwitchTransformerEncoder(depth, embed_dim, num_experts, expansion, num_heads, dropout)\n",
        "        self.decoder = SegmentationDecoder(embed_dim, num_patches, img_size, patch_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, in_channels, img_size, img_size]\n",
        "        x = self.patch_embedding(x)\n",
        "        x, aux_loss = self.encoder(x)\n",
        "        segmentation_logits = self.decoder(x)\n",
        "        return segmentation_logits, aux_loss\n",
        "\n",
        "# -----------------------------\n",
        "# 7. Example Training Loop\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Example input\n",
        "    img = torch.randn(2, 3, 224, 224)  # batch of 2 images\n",
        "    model = SwitchTransformerSegmentationModel(img_size=224, patch_size=16, in_channels=3,\n",
        "                                                 embed_dim=768, depth=6, num_experts=4,\n",
        "                                                 expansion=4, num_heads=8, dropout=0.1, num_classes=21)\n",
        "    logits, aux_loss = model(img)\n",
        "    print(\"Segmentation logits shape:\", logits.shape)  # should be [B, num_classes, 224, 224]\n",
        "\n",
        "    # Define segmentation loss (e.g., cross entropy)\n",
        "    targets = torch.randint(0, 21, (2, 224, 224))  # random segmentation maps\n",
        "    seg_loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "    loss = seg_loss + 0.01 * aux_loss  # combine with auxiliary load balancing loss\n",
        "    loss.backward()\n",
        "    print(\"Backward pass successful!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "kumaresanmanickavelu_lyft_udacity_challenge_path = kagglehub.dataset_download('kumaresanmanickavelu/lyft-udacity-challenge')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ytb0Uwr0__os",
        "outputId": "8f2cb86e-c84e-4470-f384-e2a2bf186e8c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.7).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/kumaresanmanickavelu/lyft-udacity-challenge?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.11G/5.11G [04:13<00:00, 21.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IU9hpvS1BrGk",
        "outputId": "f3ceb654-d6db-4eea-d648-459b1d1c597a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(kumaresanmanickavelu_lyft_udacity_challenge_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bM2_s1a1Bu1d",
        "outputId": "abf558bb-45dc-4e8e-b0c1-4839db61c183"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cache/kagglehub/datasets/kumaresanmanickavelu/lyft-udacity-challenge/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Update the base path to the new location\n",
        "base_path = '/root/.cache/kagglehub/datasets/kumaresanmanickavelu/lyft-udacity-challenge/versions/1/dataa/dataA/'\n",
        "\n",
        "# Update the image and mask paths\n",
        "image_path = os.path.join(base_path, 'CameraRGB/')\n",
        "mask_path = os.path.join(base_path, 'CameraSeg/')\n",
        "\n",
        "# List the files in the image and mask directories\n",
        "image_list = os.listdir(image_path)\n",
        "mask_list = os.listdir(mask_path)\n",
        "\n",
        "# Create full paths for the images and masks\n",
        "image_list = [os.path.join(image_path, i) for i in image_list]\n",
        "mask_list = [os.path.join(mask_path, i) for i in mask_list]\n",
        "\n",
        "# Print the first few paths to verify\n",
        "print(\"First 5 image paths:\", image_list[:5])\n",
        "print(\"First 5 mask paths:\", mask_list[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvCsY7CuAzYS",
        "outputId": "ecbbdb39-3214-4bc5-d630-b6b18ffb2d59"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 image paths: ['/root/.cache/kagglehub/datasets/kumaresanmanickavelu/lyft-udacity-challenge/versions/1/dataa/dataA/CameraRGB/F68-11.png', '/root/.cache/kagglehub/datasets/kumaresanmanickavelu/lyft-udacity-challenge/versions/1/dataa/dataA/CameraRGB/F70-90.png', '/root/.cache/kagglehub/datasets/kumaresanmanickavelu/lyft-udacity-challenge/versions/1/dataa/dataA/CameraRGB/F3-11.png', '/root/.cache/kagglehub/datasets/kumaresanmanickavelu/lyft-udacity-challenge/versions/1/dataa/dataA/CameraRGB/06_00_240.png', '/root/.cache/kagglehub/datasets/kumaresanmanickavelu/lyft-udacity-challenge/versions/1/dataa/dataA/CameraRGB/09_00_210.png']\n",
            "First 5 mask paths: ['/root/.cache/kagglehub/datasets/kumaresanmanickavelu/lyft-udacity-challenge/versions/1/dataa/dataA/CameraSeg/F68-11.png', '/root/.cache/kagglehub/datasets/kumaresanmanickavelu/lyft-udacity-challenge/versions/1/dataa/dataA/CameraSeg/F70-90.png', '/root/.cache/kagglehub/datasets/kumaresanmanickavelu/lyft-udacity-challenge/versions/1/dataa/dataA/CameraSeg/F3-11.png', '/root/.cache/kagglehub/datasets/kumaresanmanickavelu/lyft-udacity-challenge/versions/1/dataa/dataA/CameraSeg/06_00_240.png', '/root/.cache/kagglehub/datasets/kumaresanmanickavelu/lyft-udacity-challenge/versions/1/dataa/dataA/CameraSeg/09_00_210.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import imageio\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "mPx9JeLEATzJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Define your Dataset class\n",
        "# -----------------------------\n",
        "class LyftSegmentationDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for segmentation that loads images and masks from disk.\n",
        "    Assumes images are in RGB and masks are single-channel with integer labels.\n",
        "    \"\"\"\n",
        "    def __init__(self, image_list, mask_list, transform_image=None, transform_mask=None):\n",
        "        assert len(image_list) == len(mask_list), \"Image and mask lists must be equal length.\"\n",
        "        self.image_list = image_list\n",
        "        self.mask_list = mask_list\n",
        "        self.transform_image = transform_image\n",
        "        self.transform_mask = transform_mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_list[idx]).convert(\"RGB\")\n",
        "        mask = Image.open(self.mask_list[idx]).convert(\"L\")  # Convert to single channel\n",
        "\n",
        "        if self.transform_image:\n",
        "            image = self.transform_image(image)\n",
        "        if self.transform_mask:\n",
        "            mask = self.transform_mask(mask)\n",
        "        else:\n",
        "            mask = torch.from_numpy(np.array(mask, dtype=np.int64))\n",
        "        return image, mask\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Define image and mask transformations\n",
        "# -----------------------------\n",
        "img_size = 224  # Defined image size\n",
        "transform_image = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),  # [0, 1] float tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transform_mask = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size), interpolation=Image.NEAREST),\n",
        "    transforms.Lambda(lambda x: torch.from_numpy(np.array(x, dtype=np.int64)))\n",
        "])\n",
        "\n",
        "# -----------------------------\n",
        "# 3. File lists for images and masks\n",
        "# -----------------------------\n",
        "# image_path = '/kaggle/input/lyft-udacity-challenge/dataa/dataA/CameraRGB/'\n",
        "# mask_path = '/kaggle/input/lyft-udacity-challenge/dataa/dataA/CameraSeg/'\n",
        "\n",
        "# image_list = sorted([os.path.join(image_path, i) for i in os.listdir(image_path)])\n",
        "# mask_list = sorted([os.path.join(mask_path, i) for i in os.listdir(mask_path)])\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Define the Switch Transformer Segmentation Model and components\n",
        "# -----------------------------\n",
        "class PatchEmbedding(nn.Module):\n",
        "    def __init__(self, img_size=224, patch_size=16, in_channels=3, embed_dim=768):\n",
        "        super().__init__()\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = (img_size // patch_size) ** 2\n",
        "        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, self.num_patches, embed_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, in_channels, H, W]\n",
        "        x = self.proj(x)                    # [B, embed_dim, H/patch_size, W/patch_size]\n",
        "        x = x.flatten(2)                    # [B, embed_dim, num_patches]\n",
        "        x = x.transpose(1, 2)               # [B, num_patches, embed_dim]\n",
        "        x += self.pos_embedding             # Add position embedding\n",
        "        return x\n",
        "\n",
        "class ExpertFFN(nn.Module):\n",
        "    def __init__(self, embed_dim, expansion=4):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(embed_dim, embed_dim * expansion)\n",
        "        self.fc2 = nn.Linear(embed_dim * expansion, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.gelu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class SwitchFFN(nn.Module):\n",
        "    def __init__(self, embed_dim, num_experts=4, expansion=4):\n",
        "        super().__init__()\n",
        "        self.num_experts = num_experts\n",
        "        self.experts = nn.ModuleList([ExpertFFN(embed_dim, expansion) for _ in range(num_experts)])\n",
        "        self.gate = nn.Linear(embed_dim, num_experts)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, D = x.shape\n",
        "        logits = self.gate(x)               # [B, N, num_experts]\n",
        "        indices = logits.argmax(dim=-1)     # [B, N] - select expert index with highest score\n",
        "        output = torch.zeros_like(x)\n",
        "        expert_counts = torch.zeros(B, self.num_experts, device=x.device)\n",
        "        for expert_id in range(self.num_experts):\n",
        "            mask = (indices == expert_id)   # Boolean mask [B, N]\n",
        "            if mask.sum() == 0:\n",
        "                continue\n",
        "            selected_tokens = x[mask]       # [num_selected, D]\n",
        "            expert_output = self.experts[expert_id](selected_tokens)\n",
        "            output[mask] = expert_output\n",
        "            expert_counts[:, expert_id] += mask.float().sum(dim=1) if mask.dim() == 2 else mask.float().sum(dim=0)\n",
        "        return output, expert_counts\n",
        "\n",
        "class SwitchTransformerLayer(nn.Module):\n",
        "    def __init__(self, embed_dim, num_experts=4, expansion=4, num_heads=8, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.switch_ffn = SwitchFFN(embed_dim, num_experts=num_experts, expansion=expansion)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_out, _ = self.self_attn(x, x, x)\n",
        "        x = x + self.dropout(attn_out)\n",
        "        x = self.norm1(x)\n",
        "        ffn_out, expert_counts = self.switch_ffn(x)\n",
        "        x = x + self.dropout(ffn_out)\n",
        "        x = self.norm2(x)\n",
        "        return x, expert_counts\n",
        "\n",
        "class SwitchTransformerEncoder(nn.Module):\n",
        "    def __init__(self, depth, embed_dim, num_experts=4, expansion=4, num_heads=8, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            SwitchTransformerLayer(embed_dim, num_experts, expansion, num_heads, dropout)\n",
        "            for _ in range(depth)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        aux_loss = 0.0\n",
        "        for layer in self.layers:\n",
        "            x, expert_counts = layer(x)\n",
        "            # Optionally, incorporate an auxiliary loss for load balancing here if desired.\n",
        "        return x, aux_loss\n",
        "\n",
        "class SegmentationDecoder(nn.Module):\n",
        "    def __init__(self, embed_dim, img_size=224, patch_size=16, num_classes=21):\n",
        "        super().__init__()\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches_side = img_size // patch_size\n",
        "        self.conv1 = nn.Conv2d(embed_dim, embed_dim // 2, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(embed_dim // 2)\n",
        "        self.conv2 = nn.Conv2d(embed_dim // 2, num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, D = x.shape\n",
        "        H = W = self.num_patches_side\n",
        "        x = x.transpose(1, 2).reshape(B, D, H, W)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.interpolate(x, size=(self.img_size, self.img_size), mode='bilinear', align_corners=False)\n",
        "        logits = self.conv2(x)\n",
        "        return logits\n",
        "\n",
        "class SwitchTransformerSegmentationModel(nn.Module):\n",
        "    def __init__(self, img_size=224, patch_size=16, in_channels=3, embed_dim=768, depth=6,\n",
        "                 num_experts=4, expansion=4, num_heads=8, dropout=0.1, num_classes=21):\n",
        "        super().__init__()\n",
        "        self.patch_embedding = PatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n",
        "        self.encoder = SwitchTransformerEncoder(depth, embed_dim, num_experts, expansion, num_heads, dropout)\n",
        "        self.decoder = SegmentationDecoder(embed_dim, img_size, patch_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_embedding(x)\n",
        "        x, aux_loss = self.encoder(x)\n",
        "        segmentation_logits = self.decoder(x)\n",
        "        return segmentation_logits, aux_loss\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Define Dice Score Function\n",
        "# -----------------------------\n",
        "def dice_score(pred, target, num_classes, epsilon=1e-6):\n",
        "    \"\"\"\n",
        "    Computes the Dice score per class and returns the average score.\n",
        "    pred: tensor of shape [B, H, W] with predicted classes.\n",
        "    target: tensor of shape [B, H, W] with ground truth classes.\n",
        "    \"\"\"\n",
        "    dice = 0.0\n",
        "    for cls in range(num_classes):\n",
        "        pred_cls = (pred == cls).float()\n",
        "        target_cls = (target == cls).float()\n",
        "        intersection = (pred_cls * target_cls).sum()\n",
        "        union = pred_cls.sum() + target_cls.sum()\n",
        "        dice += (2 * intersection + epsilon) / (union + epsilon)\n",
        "    return dice / num_classes\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define your class colors (adjust the number of classes/colors as needed)\n",
        "class_colors = {\n",
        "    0: (1, 0, 0),   # red  (often used for background, or class 0)\n",
        "    1: (0, 1, 0),   # green (class 1)\n",
        "    2: (0, 0, 1),   # blue  (class 2)\n",
        "    3: (1, 0, 1)    # magenta (class 3)\n",
        "}\n",
        "\n",
        "\n",
        "def colorize_mask(mask, class_colors):\n",
        "    \"\"\"\n",
        "    Colorize a segmentation mask given a mapping from class labels to colors.\n",
        "\n",
        "    Parameters:\n",
        "        mask (np.ndarray): 2D array (height, width) of class indices.\n",
        "        class_colors (dict): dictionary mapping class indices to RGB tuples.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: colorized mask of shape (height, width, 3) for visualization.\n",
        "    \"\"\"\n",
        "    # Create an empty array with an extra channel for color (RGB)\n",
        "    h, w = mask.shape\n",
        "    color_mask = np.zeros((h, w, 3), dtype=np.float32)\n",
        "\n",
        "    # Assign colors for each class present in the mask\n",
        "    for class_id, color in class_colors.items():\n",
        "        color_mask[mask == class_id] = color\n",
        "\n",
        "    return color_mask\n",
        "\n",
        "# -----------------------------\n",
        "# 6. Helper function to plot predictions\n",
        "# -----------------------------\n",
        "def plot_prediction_and_mask(image, pred_mask, true_mask, class_colors):\n",
        "    \"\"\"\n",
        "    Plot the original image, prediction mask, and ground truth mask.\n",
        "\n",
        "    Parameters:\n",
        "        image (np.ndarray): the input image of shape (height, width, 3).\n",
        "        pred_mask (np.ndarray): predicted segmentation mask (class indices).\n",
        "        true_mask (np.ndarray): ground truth segmentation mask (class indices).\n",
        "        class_colors (dict): mapping from class labels to colors.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create color masks for the predicted and true masks\n",
        "    pred_color_mask = colorize_mask(pred_mask, class_colors)\n",
        "    true_color_mask = colorize_mask(true_mask, class_colors)\n",
        "\n",
        "    # Plotting using matplotlib\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "    # Show original image\n",
        "    axes[0].imshow(image)\n",
        "    axes[0].set_title(\"Original Image\")\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Show predicted mask\n",
        "    axes[1].imshow(pred_color_mask)\n",
        "    axes[1].set_title(\"Predicted Mask\")\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # Show ground truth mask\n",
        "    axes[2].imshow(true_color_mask)\n",
        "    axes[2].set_title(\"Ground Truth Mask\")\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 7. Training loop with Dice score and prediction plotting\n",
        "# -----------------------------\n",
        "def train(model, dataloader, optimizer, device, num_epochs=5, aux_loss_weight=0.01, num_classes=21, plot_freq=10):\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()  # segmentation cross-entropy loss\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        running_dice = 0.0\n",
        "        for i, (images, masks) in enumerate(dataloader):\n",
        "            images = images.to(device)      # [B, 3, H, W]\n",
        "            masks = masks.to(device)        # [B, H, W]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            seg_logits, aux_loss = model(images)\n",
        "            # seg_logits shape: [B, num_classes, H, W]\n",
        "            seg_loss = criterion(seg_logits, masks)\n",
        "            loss = seg_loss + aux_loss_weight * aux_loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Calculate Dice score on training mini-batch:\n",
        "            preds = torch.argmax(seg_logits, dim=1)  # shape: [B, H, W]\n",
        "            batch_dice = dice_score(preds, masks, num_classes)\n",
        "            running_dice += batch_dice.item() if isinstance(batch_dice, torch.Tensor) else batch_dice\n",
        "\n",
        "            # Every plot_freq iterations, plot a few example predictions from the current batch.\n",
        "            # if (i + 1) % plot_freq == 0:\n",
        "            #     print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n",
        "            #     # Plot first few images. Adjust n_samples as desired.\n",
        "            #     plot_predictions(images, masks, preds, n_samples=3, title_prefix=\"Train\")\n",
        "\n",
        "            if (i + 1) % 5 == 0:\n",
        "                avg_loss = running_loss / (i+1)\n",
        "                avg_dice = running_dice / (i+1)\n",
        "                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Avg Loss: {avg_loss:.4f}, Avg Dice: {avg_dice:.4f}\")\n",
        "        print(f\"End of epoch {epoch+1}: Avg Loss: {running_loss/len(dataloader):.4f}, Avg Dice: {running_dice/len(dataloader):.4f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 8. Evaluation loop with prediction plotting\n",
        "# -----------------------------\n",
        "def evaluate(model, dataloader, device, num_classes, n_samples_to_plot=3):\n",
        "    model.eval()\n",
        "    total_dice = 0.0\n",
        "    count = 0\n",
        "    plotted = False  # flag to plot only once per evaluation run\n",
        "    with torch.no_grad():\n",
        "        for images, masks in dataloader:\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)  # [B, H, W]\n",
        "            seg_logits, _ = model(images)\n",
        "            preds = torch.argmax(seg_logits, dim=1)  # [B, H, W]\n",
        "            batch_dice = dice_score(preds, masks, num_classes)\n",
        "            total_dice += batch_dice.item() if isinstance(batch_dice, torch.Tensor) else batch_dice\n",
        "            count += 1\n",
        "\n",
        "            # Optionally plot predictions from one batch during evaluation\n",
        "            if not plotted:\n",
        "                plot_prediction_and_mask(images, masks, preds, n_samples=n_samples_to_plot, title_prefix=\"Eval\")\n",
        "                plotted = True\n",
        "\n",
        "    avg_dice = total_dice / count\n",
        "    print(f\"Average Dice score on Validation: {avg_dice:.4f}\")\n",
        "    return avg_dice\n",
        "\n",
        "# -----------------------------\n",
        "# 9. Main: Dataset setup, model instantiation, training, and evaluation\n",
        "# -----------------------------\n",
        "# def main():\n",
        "    # Hyperparameters\n",
        "num_epochs = 50\n",
        "batch_size = 16\n",
        "learning_rate = 1e-4\n",
        "num_classes = 13  # Adjust this based on your segmentation classes\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create full dataset\n",
        "full_dataset = LyftSegmentationDataset(\n",
        "    image_list=image_list,\n",
        "    mask_list=mask_list,\n",
        "    transform_image=transform_image,\n",
        "    transform_mask=transform_mask\n",
        ")\n",
        "\n",
        "# Split the dataset into training and validation sets (80-20 split)\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Instantiate model\n",
        "model = SwitchTransformerSegmentationModel(\n",
        "    img_size=img_size,\n",
        "    patch_size=16,\n",
        "    in_channels=3,\n",
        "    embed_dim=256,    # Reduced embed_dim to speed testing; adjust as needed\n",
        "    depth=3,          # Adjust depth as required\n",
        "    num_experts=4,\n",
        "    expansion=4,\n",
        "    num_heads=4,\n",
        "    dropout=0.1,\n",
        "    num_classes=num_classes\n",
        ")\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model with Dice score monitoring and prediction plotting\n",
        "print(\"Starting training...\")\n",
        "train(model, train_loader, optimizer, device, num_epochs=num_epochs, aux_loss_weight=0.01, num_classes=num_classes, plot_freq=10)\n",
        "print(\"Training completed!\")\n",
        "\n",
        "# Evaluate the model using Dice score and plot predictions from the validation set\n",
        "print(\"Evaluating model performance...\")\n",
        "evaluate(model, val_loader, device, num_classes, n_samples_to_plot=3)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-7jLnysC9Uvz",
        "outputId": "cd3d7b5a-02b8-461a-a8f6-7431fae9ede5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Epoch [1/50], Step [5/50], Avg Loss: 2.2019, Avg Dice: 0.1030\n",
            "Epoch [1/50], Step [10/50], Avg Loss: 1.9340, Avg Dice: 0.1568\n",
            "Epoch [1/50], Step [15/50], Avg Loss: 1.7855, Avg Dice: 0.2019\n",
            "Epoch [1/50], Step [20/50], Avg Loss: 1.6643, Avg Dice: 0.2339\n",
            "Epoch [1/50], Step [25/50], Avg Loss: 1.5654, Avg Dice: 0.2811\n",
            "Epoch [1/50], Step [30/50], Avg Loss: 1.4856, Avg Dice: 0.3328\n",
            "Epoch [1/50], Step [35/50], Avg Loss: 1.4177, Avg Dice: 0.3854\n",
            "Epoch [1/50], Step [40/50], Avg Loss: 1.3622, Avg Dice: 0.4288\n",
            "Epoch [1/50], Step [45/50], Avg Loss: 1.3170, Avg Dice: 0.4624\n",
            "Epoch [1/50], Step [50/50], Avg Loss: 1.2730, Avg Dice: 0.4896\n",
            "End of epoch 1: Avg Loss: 1.2730, Avg Dice: 0.4896\n",
            "Epoch [2/50], Step [5/50], Avg Loss: 0.8502, Avg Dice: 0.7959\n",
            "Epoch [2/50], Step [10/50], Avg Loss: 0.8439, Avg Dice: 0.8028\n",
            "Epoch [2/50], Step [15/50], Avg Loss: 0.8236, Avg Dice: 0.8062\n",
            "Epoch [2/50], Step [20/50], Avg Loss: 0.8168, Avg Dice: 0.8069\n",
            "Epoch [2/50], Step [25/50], Avg Loss: 0.8085, Avg Dice: 0.8073\n",
            "Epoch [2/50], Step [30/50], Avg Loss: 0.7955, Avg Dice: 0.8080\n",
            "Epoch [2/50], Step [35/50], Avg Loss: 0.7841, Avg Dice: 0.8085\n",
            "Epoch [2/50], Step [40/50], Avg Loss: 0.7768, Avg Dice: 0.8088\n",
            "Epoch [2/50], Step [45/50], Avg Loss: 0.7667, Avg Dice: 0.8092\n",
            "Epoch [2/50], Step [50/50], Avg Loss: 0.7574, Avg Dice: 0.8095\n",
            "End of epoch 2: Avg Loss: 0.7574, Avg Dice: 0.8095\n",
            "Epoch [3/50], Step [5/50], Avg Loss: 0.6682, Avg Dice: 0.8134\n",
            "Epoch [3/50], Step [10/50], Avg Loss: 0.6615, Avg Dice: 0.8129\n",
            "Epoch [3/50], Step [15/50], Avg Loss: 0.6525, Avg Dice: 0.8132\n",
            "Epoch [3/50], Step [20/50], Avg Loss: 0.6431, Avg Dice: 0.8134\n",
            "Epoch [3/50], Step [25/50], Avg Loss: 0.6376, Avg Dice: 0.8137\n",
            "Epoch [3/50], Step [30/50], Avg Loss: 0.6296, Avg Dice: 0.8141\n",
            "Epoch [3/50], Step [35/50], Avg Loss: 0.6247, Avg Dice: 0.8140\n",
            "Epoch [3/50], Step [40/50], Avg Loss: 0.6196, Avg Dice: 0.8141\n",
            "Epoch [3/50], Step [45/50], Avg Loss: 0.6125, Avg Dice: 0.8143\n",
            "Epoch [3/50], Step [50/50], Avg Loss: 0.6088, Avg Dice: 0.8144\n",
            "End of epoch 3: Avg Loss: 0.6088, Avg Dice: 0.8144\n",
            "Epoch [4/50], Step [5/50], Avg Loss: 0.5589, Avg Dice: 0.8161\n",
            "Epoch [4/50], Step [10/50], Avg Loss: 0.5468, Avg Dice: 0.8169\n",
            "Epoch [4/50], Step [15/50], Avg Loss: 0.5485, Avg Dice: 0.8165\n",
            "Epoch [4/50], Step [20/50], Avg Loss: 0.5448, Avg Dice: 0.8165\n",
            "Epoch [4/50], Step [25/50], Avg Loss: 0.5345, Avg Dice: 0.8171\n",
            "Epoch [4/50], Step [30/50], Avg Loss: 0.5346, Avg Dice: 0.8168\n",
            "Epoch [4/50], Step [35/50], Avg Loss: 0.5318, Avg Dice: 0.8168\n",
            "Epoch [4/50], Step [40/50], Avg Loss: 0.5256, Avg Dice: 0.8171\n",
            "Epoch [4/50], Step [45/50], Avg Loss: 0.5230, Avg Dice: 0.8172\n",
            "Epoch [4/50], Step [50/50], Avg Loss: 0.5203, Avg Dice: 0.8173\n",
            "End of epoch 4: Avg Loss: 0.5203, Avg Dice: 0.8173\n",
            "Epoch [5/50], Step [5/50], Avg Loss: 0.4788, Avg Dice: 0.8188\n",
            "Epoch [5/50], Step [10/50], Avg Loss: 0.4849, Avg Dice: 0.8185\n",
            "Epoch [5/50], Step [15/50], Avg Loss: 0.4770, Avg Dice: 0.8189\n",
            "Epoch [5/50], Step [20/50], Avg Loss: 0.4740, Avg Dice: 0.8191\n",
            "Epoch [5/50], Step [25/50], Avg Loss: 0.4718, Avg Dice: 0.8193\n",
            "Epoch [5/50], Step [30/50], Avg Loss: 0.4712, Avg Dice: 0.8193\n",
            "Epoch [5/50], Step [35/50], Avg Loss: 0.4687, Avg Dice: 0.8193\n",
            "Epoch [5/50], Step [40/50], Avg Loss: 0.4648, Avg Dice: 0.8195\n",
            "Epoch [5/50], Step [45/50], Avg Loss: 0.4629, Avg Dice: 0.8195\n",
            "Epoch [5/50], Step [50/50], Avg Loss: 0.4611, Avg Dice: 0.8195\n",
            "End of epoch 5: Avg Loss: 0.4611, Avg Dice: 0.8195\n",
            "Epoch [6/50], Step [5/50], Avg Loss: 0.4381, Avg Dice: 0.8202\n",
            "Epoch [6/50], Step [10/50], Avg Loss: 0.4364, Avg Dice: 0.8200\n",
            "Epoch [6/50], Step [15/50], Avg Loss: 0.4327, Avg Dice: 0.8203\n",
            "Epoch [6/50], Step [20/50], Avg Loss: 0.4290, Avg Dice: 0.8206\n",
            "Epoch [6/50], Step [25/50], Avg Loss: 0.4301, Avg Dice: 0.8201\n",
            "Epoch [6/50], Step [30/50], Avg Loss: 0.4277, Avg Dice: 0.8204\n",
            "Epoch [6/50], Step [35/50], Avg Loss: 0.4251, Avg Dice: 0.8206\n",
            "Epoch [6/50], Step [40/50], Avg Loss: 0.4235, Avg Dice: 0.8206\n",
            "Epoch [6/50], Step [45/50], Avg Loss: 0.4209, Avg Dice: 0.8207\n",
            "Epoch [6/50], Step [50/50], Avg Loss: 0.4192, Avg Dice: 0.8208\n",
            "End of epoch 6: Avg Loss: 0.4192, Avg Dice: 0.8208\n",
            "Epoch [7/50], Step [5/50], Avg Loss: 0.4047, Avg Dice: 0.8213\n",
            "Epoch [7/50], Step [10/50], Avg Loss: 0.3969, Avg Dice: 0.8220\n",
            "Epoch [7/50], Step [15/50], Avg Loss: 0.3909, Avg Dice: 0.8224\n",
            "Epoch [7/50], Step [20/50], Avg Loss: 0.3926, Avg Dice: 0.8221\n",
            "Epoch [7/50], Step [25/50], Avg Loss: 0.3915, Avg Dice: 0.8221\n",
            "Epoch [7/50], Step [30/50], Avg Loss: 0.3918, Avg Dice: 0.8222\n",
            "Epoch [7/50], Step [35/50], Avg Loss: 0.3920, Avg Dice: 0.8222\n",
            "Epoch [7/50], Step [40/50], Avg Loss: 0.3907, Avg Dice: 0.8222\n",
            "Epoch [7/50], Step [45/50], Avg Loss: 0.3881, Avg Dice: 0.8224\n",
            "Epoch [7/50], Step [50/50], Avg Loss: 0.3863, Avg Dice: 0.8224\n",
            "End of epoch 7: Avg Loss: 0.3863, Avg Dice: 0.8224\n",
            "Epoch [8/50], Step [5/50], Avg Loss: 0.3764, Avg Dice: 0.8223\n",
            "Epoch [8/50], Step [10/50], Avg Loss: 0.3749, Avg Dice: 0.8223\n",
            "Epoch [8/50], Step [15/50], Avg Loss: 0.3767, Avg Dice: 0.8218\n",
            "Epoch [8/50], Step [20/50], Avg Loss: 0.3712, Avg Dice: 0.8224\n",
            "Epoch [8/50], Step [25/50], Avg Loss: 0.3706, Avg Dice: 0.8227\n",
            "Epoch [8/50], Step [30/50], Avg Loss: 0.3699, Avg Dice: 0.8228\n",
            "Epoch [8/50], Step [35/50], Avg Loss: 0.3677, Avg Dice: 0.8231\n",
            "Epoch [8/50], Step [40/50], Avg Loss: 0.3680, Avg Dice: 0.8231\n",
            "Epoch [8/50], Step [45/50], Avg Loss: 0.3651, Avg Dice: 0.8233\n",
            "Epoch [8/50], Step [50/50], Avg Loss: 0.3616, Avg Dice: 0.8236\n",
            "End of epoch 8: Avg Loss: 0.3616, Avg Dice: 0.8236\n",
            "Epoch [9/50], Step [5/50], Avg Loss: 0.3574, Avg Dice: 0.8243\n",
            "Epoch [9/50], Step [10/50], Avg Loss: 0.3553, Avg Dice: 0.8246\n",
            "Epoch [9/50], Step [15/50], Avg Loss: 0.3533, Avg Dice: 0.8245\n",
            "Epoch [9/50], Step [20/50], Avg Loss: 0.3490, Avg Dice: 0.8248\n",
            "Epoch [9/50], Step [25/50], Avg Loss: 0.3477, Avg Dice: 0.8248\n",
            "Epoch [9/50], Step [30/50], Avg Loss: 0.3486, Avg Dice: 0.8247\n",
            "Epoch [9/50], Step [35/50], Avg Loss: 0.3470, Avg Dice: 0.8248\n",
            "Epoch [9/50], Step [40/50], Avg Loss: 0.3468, Avg Dice: 0.8247\n",
            "Epoch [9/50], Step [45/50], Avg Loss: 0.3458, Avg Dice: 0.8248\n",
            "Epoch [9/50], Step [50/50], Avg Loss: 0.3421, Avg Dice: 0.8251\n",
            "End of epoch 9: Avg Loss: 0.3421, Avg Dice: 0.8251\n",
            "Epoch [10/50], Step [5/50], Avg Loss: 0.3259, Avg Dice: 0.8263\n",
            "Epoch [10/50], Step [10/50], Avg Loss: 0.3254, Avg Dice: 0.8263\n",
            "Epoch [10/50], Step [15/50], Avg Loss: 0.3261, Avg Dice: 0.8261\n",
            "Epoch [10/50], Step [20/50], Avg Loss: 0.3261, Avg Dice: 0.8261\n",
            "Epoch [10/50], Step [25/50], Avg Loss: 0.3251, Avg Dice: 0.8264\n",
            "Epoch [10/50], Step [30/50], Avg Loss: 0.3289, Avg Dice: 0.8262\n",
            "Epoch [10/50], Step [35/50], Avg Loss: 0.3307, Avg Dice: 0.8261\n",
            "Epoch [10/50], Step [40/50], Avg Loss: 0.3282, Avg Dice: 0.8263\n",
            "Epoch [10/50], Step [45/50], Avg Loss: 0.3275, Avg Dice: 0.8263\n",
            "Epoch [10/50], Step [50/50], Avg Loss: 0.3268, Avg Dice: 0.8264\n",
            "End of epoch 10: Avg Loss: 0.3268, Avg Dice: 0.8264\n",
            "Epoch [11/50], Step [5/50], Avg Loss: 0.3036, Avg Dice: 0.8285\n",
            "Epoch [11/50], Step [10/50], Avg Loss: 0.3115, Avg Dice: 0.8285\n",
            "Epoch [11/50], Step [15/50], Avg Loss: 0.3122, Avg Dice: 0.8285\n",
            "Epoch [11/50], Step [20/50], Avg Loss: 0.3107, Avg Dice: 0.8290\n",
            "Epoch [11/50], Step [25/50], Avg Loss: 0.3101, Avg Dice: 0.8289\n",
            "Epoch [11/50], Step [30/50], Avg Loss: 0.3132, Avg Dice: 0.8286\n",
            "Epoch [11/50], Step [35/50], Avg Loss: 0.3131, Avg Dice: 0.8285\n",
            "Epoch [11/50], Step [40/50], Avg Loss: 0.3125, Avg Dice: 0.8287\n",
            "Epoch [11/50], Step [45/50], Avg Loss: 0.3116, Avg Dice: 0.8288\n",
            "Epoch [11/50], Step [50/50], Avg Loss: 0.3105, Avg Dice: 0.8290\n",
            "End of epoch 11: Avg Loss: 0.3105, Avg Dice: 0.8290\n",
            "Epoch [12/50], Step [5/50], Avg Loss: 0.3055, Avg Dice: 0.8295\n",
            "Epoch [12/50], Step [10/50], Avg Loss: 0.3050, Avg Dice: 0.8292\n",
            "Epoch [12/50], Step [15/50], Avg Loss: 0.3045, Avg Dice: 0.8301\n",
            "Epoch [12/50], Step [20/50], Avg Loss: 0.3032, Avg Dice: 0.8301\n",
            "Epoch [12/50], Step [25/50], Avg Loss: 0.3010, Avg Dice: 0.8303\n",
            "Epoch [12/50], Step [30/50], Avg Loss: 0.3009, Avg Dice: 0.8302\n",
            "Epoch [12/50], Step [35/50], Avg Loss: 0.3019, Avg Dice: 0.8300\n",
            "Epoch [12/50], Step [40/50], Avg Loss: 0.3019, Avg Dice: 0.8302\n",
            "Epoch [12/50], Step [45/50], Avg Loss: 0.3013, Avg Dice: 0.8306\n",
            "Epoch [12/50], Step [50/50], Avg Loss: 0.3008, Avg Dice: 0.8306\n",
            "End of epoch 12: Avg Loss: 0.3008, Avg Dice: 0.8306\n",
            "Epoch [13/50], Step [5/50], Avg Loss: 0.2916, Avg Dice: 0.8307\n",
            "Epoch [13/50], Step [10/50], Avg Loss: 0.2974, Avg Dice: 0.8309\n",
            "Epoch [13/50], Step [15/50], Avg Loss: 0.2970, Avg Dice: 0.8314\n",
            "Epoch [13/50], Step [20/50], Avg Loss: 0.3003, Avg Dice: 0.8318\n",
            "Epoch [13/50], Step [30/50], Avg Loss: 0.3018, Avg Dice: 0.8312\n",
            "Epoch [13/50], Step [35/50], Avg Loss: 0.2984, Avg Dice: 0.8313\n",
            "Epoch [13/50], Step [40/50], Avg Loss: 0.2960, Avg Dice: 0.8316\n",
            "Epoch [13/50], Step [45/50], Avg Loss: 0.2959, Avg Dice: 0.8317\n",
            "Epoch [13/50], Step [50/50], Avg Loss: 0.2947, Avg Dice: 0.8319\n",
            "End of epoch 13: Avg Loss: 0.2947, Avg Dice: 0.8319\n",
            "Epoch [14/50], Step [5/50], Avg Loss: 0.2852, Avg Dice: 0.8340\n",
            "Epoch [14/50], Step [10/50], Avg Loss: 0.2832, Avg Dice: 0.8335\n",
            "Epoch [14/50], Step [15/50], Avg Loss: 0.2823, Avg Dice: 0.8344\n",
            "Epoch [14/50], Step [20/50], Avg Loss: 0.2832, Avg Dice: 0.8340\n",
            "Epoch [14/50], Step [25/50], Avg Loss: 0.2813, Avg Dice: 0.8342\n",
            "Epoch [14/50], Step [30/50], Avg Loss: 0.2817, Avg Dice: 0.8343\n",
            "Epoch [14/50], Step [35/50], Avg Loss: 0.2819, Avg Dice: 0.8347\n",
            "Epoch [14/50], Step [40/50], Avg Loss: 0.2808, Avg Dice: 0.8348\n",
            "Epoch [14/50], Step [45/50], Avg Loss: 0.2810, Avg Dice: 0.8349\n",
            "Epoch [14/50], Step [50/50], Avg Loss: 0.2809, Avg Dice: 0.8350\n",
            "End of epoch 14: Avg Loss: 0.2809, Avg Dice: 0.8350\n",
            "Epoch [15/50], Step [5/50], Avg Loss: 0.2602, Avg Dice: 0.8367\n",
            "Epoch [15/50], Step [10/50], Avg Loss: 0.2708, Avg Dice: 0.8374\n",
            "Epoch [15/50], Step [15/50], Avg Loss: 0.2738, Avg Dice: 0.8377\n",
            "Epoch [15/50], Step [20/50], Avg Loss: 0.2736, Avg Dice: 0.8380\n",
            "Epoch [15/50], Step [25/50], Avg Loss: 0.2725, Avg Dice: 0.8380\n",
            "Epoch [15/50], Step [30/50], Avg Loss: 0.2708, Avg Dice: 0.8377\n",
            "Epoch [15/50], Step [35/50], Avg Loss: 0.2713, Avg Dice: 0.8377\n",
            "Epoch [15/50], Step [40/50], Avg Loss: 0.2703, Avg Dice: 0.8380\n",
            "Epoch [15/50], Step [45/50], Avg Loss: 0.2723, Avg Dice: 0.8376\n",
            "Epoch [15/50], Step [50/50], Avg Loss: 0.2728, Avg Dice: 0.8376\n",
            "End of epoch 15: Avg Loss: 0.2728, Avg Dice: 0.8376\n",
            "Epoch [16/50], Step [5/50], Avg Loss: 0.2737, Avg Dice: 0.8380\n",
            "Epoch [16/50], Step [10/50], Avg Loss: 0.2686, Avg Dice: 0.8398\n",
            "Epoch [16/50], Step [15/50], Avg Loss: 0.2731, Avg Dice: 0.8383\n",
            "Epoch [16/50], Step [20/50], Avg Loss: 0.2734, Avg Dice: 0.8381\n",
            "Epoch [16/50], Step [25/50], Avg Loss: 0.2704, Avg Dice: 0.8381\n",
            "Epoch [16/50], Step [30/50], Avg Loss: 0.2692, Avg Dice: 0.8379\n",
            "Epoch [16/50], Step [35/50], Avg Loss: 0.2681, Avg Dice: 0.8380\n",
            "Epoch [16/50], Step [40/50], Avg Loss: 0.2674, Avg Dice: 0.8383\n",
            "Epoch [16/50], Step [45/50], Avg Loss: 0.2672, Avg Dice: 0.8385\n",
            "Epoch [16/50], Step [50/50], Avg Loss: 0.2673, Avg Dice: 0.8385\n",
            "End of epoch 16: Avg Loss: 0.2673, Avg Dice: 0.8385\n",
            "Epoch [17/50], Step [5/50], Avg Loss: 0.2670, Avg Dice: 0.8405\n",
            "Epoch [17/50], Step [10/50], Avg Loss: 0.2620, Avg Dice: 0.8421\n",
            "Epoch [17/50], Step [15/50], Avg Loss: 0.2596, Avg Dice: 0.8418\n",
            "Epoch [17/50], Step [20/50], Avg Loss: 0.2629, Avg Dice: 0.8408\n",
            "Epoch [17/50], Step [25/50], Avg Loss: 0.2615, Avg Dice: 0.8408\n",
            "Epoch [17/50], Step [30/50], Avg Loss: 0.2614, Avg Dice: 0.8410\n",
            "Epoch [17/50], Step [35/50], Avg Loss: 0.2601, Avg Dice: 0.8410\n",
            "Epoch [17/50], Step [40/50], Avg Loss: 0.2603, Avg Dice: 0.8404\n",
            "Epoch [17/50], Step [45/50], Avg Loss: 0.2610, Avg Dice: 0.8404\n",
            "Epoch [17/50], Step [50/50], Avg Loss: 0.2608, Avg Dice: 0.8405\n",
            "End of epoch 17: Avg Loss: 0.2608, Avg Dice: 0.8405\n",
            "Epoch [18/50], Step [5/50], Avg Loss: 0.2730, Avg Dice: 0.8450\n",
            "Epoch [18/50], Step [10/50], Avg Loss: 0.2625, Avg Dice: 0.8446\n",
            "Epoch [18/50], Step [15/50], Avg Loss: 0.2575, Avg Dice: 0.8435\n",
            "Epoch [18/50], Step [20/50], Avg Loss: 0.2529, Avg Dice: 0.8431\n",
            "Epoch [18/50], Step [25/50], Avg Loss: 0.2526, Avg Dice: 0.8430\n",
            "Epoch [18/50], Step [30/50], Avg Loss: 0.2517, Avg Dice: 0.8431\n",
            "Epoch [18/50], Step [35/50], Avg Loss: 0.2526, Avg Dice: 0.8437\n",
            "Epoch [18/50], Step [40/50], Avg Loss: 0.2534, Avg Dice: 0.8436\n",
            "Epoch [18/50], Step [45/50], Avg Loss: 0.2533, Avg Dice: 0.8435\n",
            "Epoch [18/50], Step [50/50], Avg Loss: 0.2534, Avg Dice: 0.8432\n",
            "End of epoch 18: Avg Loss: 0.2534, Avg Dice: 0.8432\n",
            "Epoch [19/50], Step [5/50], Avg Loss: 0.2393, Avg Dice: 0.8421\n",
            "Epoch [19/50], Step [10/50], Avg Loss: 0.2419, Avg Dice: 0.8407\n",
            "Epoch [19/50], Step [15/50], Avg Loss: 0.2429, Avg Dice: 0.8417\n",
            "Epoch [19/50], Step [20/50], Avg Loss: 0.2406, Avg Dice: 0.8431\n",
            "Epoch [19/50], Step [25/50], Avg Loss: 0.2415, Avg Dice: 0.8430\n",
            "Epoch [19/50], Step [30/50], Avg Loss: 0.2432, Avg Dice: 0.8433\n",
            "Epoch [19/50], Step [35/50], Avg Loss: 0.2447, Avg Dice: 0.8437\n",
            "Epoch [19/50], Step [40/50], Avg Loss: 0.2450, Avg Dice: 0.8437\n",
            "Epoch [19/50], Step [45/50], Avg Loss: 0.2486, Avg Dice: 0.8435\n",
            "Epoch [19/50], Step [50/50], Avg Loss: 0.2482, Avg Dice: 0.8435\n",
            "End of epoch 19: Avg Loss: 0.2482, Avg Dice: 0.8435\n",
            "Epoch [20/50], Step [5/50], Avg Loss: 0.2501, Avg Dice: 0.8418\n",
            "Epoch [20/50], Step [10/50], Avg Loss: 0.2474, Avg Dice: 0.8440\n",
            "Epoch [20/50], Step [15/50], Avg Loss: 0.2484, Avg Dice: 0.8446\n",
            "Epoch [20/50], Step [20/50], Avg Loss: 0.2446, Avg Dice: 0.8460\n",
            "Epoch [20/50], Step [25/50], Avg Loss: 0.2460, Avg Dice: 0.8457\n",
            "Epoch [20/50], Step [30/50], Avg Loss: 0.2452, Avg Dice: 0.8457\n",
            "Epoch [20/50], Step [35/50], Avg Loss: 0.2443, Avg Dice: 0.8457\n",
            "Epoch [20/50], Step [40/50], Avg Loss: 0.2432, Avg Dice: 0.8458\n",
            "Epoch [20/50], Step [45/50], Avg Loss: 0.2422, Avg Dice: 0.8455\n",
            "Epoch [20/50], Step [50/50], Avg Loss: 0.2424, Avg Dice: 0.8455\n",
            "End of epoch 20: Avg Loss: 0.2424, Avg Dice: 0.8455\n",
            "Epoch [21/50], Step [5/50], Avg Loss: 0.2481, Avg Dice: 0.8475\n",
            "Epoch [21/50], Step [10/50], Avg Loss: 0.2406, Avg Dice: 0.8487\n",
            "Epoch [21/50], Step [15/50], Avg Loss: 0.2401, Avg Dice: 0.8480\n",
            "Epoch [21/50], Step [20/50], Avg Loss: 0.2375, Avg Dice: 0.8479\n",
            "Epoch [21/50], Step [25/50], Avg Loss: 0.2387, Avg Dice: 0.8474\n",
            "Epoch [21/50], Step [30/50], Avg Loss: 0.2394, Avg Dice: 0.8474\n",
            "Epoch [21/50], Step [35/50], Avg Loss: 0.2397, Avg Dice: 0.8470\n",
            "Epoch [21/50], Step [40/50], Avg Loss: 0.2392, Avg Dice: 0.8470\n",
            "Epoch [21/50], Step [45/50], Avg Loss: 0.2397, Avg Dice: 0.8474\n",
            "Epoch [21/50], Step [50/50], Avg Loss: 0.2380, Avg Dice: 0.8475\n",
            "End of epoch 21: Avg Loss: 0.2380, Avg Dice: 0.8475\n",
            "Epoch [22/50], Step [5/50], Avg Loss: 0.2283, Avg Dice: 0.8481\n",
            "Epoch [22/50], Step [10/50], Avg Loss: 0.2296, Avg Dice: 0.8475\n",
            "Epoch [22/50], Step [15/50], Avg Loss: 0.2269, Avg Dice: 0.8471\n",
            "Epoch [22/50], Step [20/50], Avg Loss: 0.2279, Avg Dice: 0.8485\n",
            "Epoch [22/50], Step [25/50], Avg Loss: 0.2306, Avg Dice: 0.8482\n",
            "Epoch [22/50], Step [30/50], Avg Loss: 0.2323, Avg Dice: 0.8484\n",
            "Epoch [22/50], Step [35/50], Avg Loss: 0.2345, Avg Dice: 0.8475\n",
            "Epoch [22/50], Step [40/50], Avg Loss: 0.2334, Avg Dice: 0.8474\n",
            "Epoch [22/50], Step [45/50], Avg Loss: 0.2344, Avg Dice: 0.8472\n",
            "Epoch [22/50], Step [50/50], Avg Loss: 0.2346, Avg Dice: 0.8479\n",
            "End of epoch 22: Avg Loss: 0.2346, Avg Dice: 0.8479\n",
            "Epoch [23/50], Step [5/50], Avg Loss: 0.2162, Avg Dice: 0.8548\n",
            "Epoch [23/50], Step [10/50], Avg Loss: 0.2247, Avg Dice: 0.8534\n",
            "Epoch [23/50], Step [15/50], Avg Loss: 0.2299, Avg Dice: 0.8504\n",
            "Epoch [23/50], Step [20/50], Avg Loss: 0.2284, Avg Dice: 0.8495\n",
            "Epoch [23/50], Step [25/50], Avg Loss: 0.2311, Avg Dice: 0.8500\n",
            "Epoch [23/50], Step [30/50], Avg Loss: 0.2312, Avg Dice: 0.8501\n",
            "Epoch [23/50], Step [35/50], Avg Loss: 0.2304, Avg Dice: 0.8503\n",
            "Epoch [23/50], Step [40/50], Avg Loss: 0.2317, Avg Dice: 0.8500\n",
            "Epoch [23/50], Step [45/50], Avg Loss: 0.2308, Avg Dice: 0.8499\n",
            "Epoch [23/50], Step [50/50], Avg Loss: 0.2300, Avg Dice: 0.8496\n",
            "End of epoch 23: Avg Loss: 0.2300, Avg Dice: 0.8496\n",
            "Epoch [24/50], Step [5/50], Avg Loss: 0.2319, Avg Dice: 0.8485\n",
            "Epoch [24/50], Step [10/50], Avg Loss: 0.2300, Avg Dice: 0.8509\n",
            "Epoch [24/50], Step [15/50], Avg Loss: 0.2273, Avg Dice: 0.8510\n",
            "Epoch [24/50], Step [20/50], Avg Loss: 0.2275, Avg Dice: 0.8509\n",
            "Epoch [24/50], Step [25/50], Avg Loss: 0.2281, Avg Dice: 0.8509\n",
            "Epoch [24/50], Step [30/50], Avg Loss: 0.2264, Avg Dice: 0.8511\n",
            "Epoch [24/50], Step [35/50], Avg Loss: 0.2281, Avg Dice: 0.8507\n",
            "Epoch [24/50], Step [40/50], Avg Loss: 0.2277, Avg Dice: 0.8504\n",
            "Epoch [24/50], Step [45/50], Avg Loss: 0.2274, Avg Dice: 0.8507\n",
            "Epoch [24/50], Step [50/50], Avg Loss: 0.2263, Avg Dice: 0.8503\n",
            "End of epoch 24: Avg Loss: 0.2263, Avg Dice: 0.8503\n",
            "Epoch [25/50], Step [5/50], Avg Loss: 0.2278, Avg Dice: 0.8503\n",
            "Epoch [25/50], Step [10/50], Avg Loss: 0.2232, Avg Dice: 0.8515\n",
            "Epoch [25/50], Step [15/50], Avg Loss: 0.2234, Avg Dice: 0.8523\n",
            "Epoch [25/50], Step [20/50], Avg Loss: 0.2222, Avg Dice: 0.8515\n",
            "Epoch [25/50], Step [25/50], Avg Loss: 0.2233, Avg Dice: 0.8508\n",
            "Epoch [25/50], Step [30/50], Avg Loss: 0.2222, Avg Dice: 0.8510\n",
            "Epoch [25/50], Step [35/50], Avg Loss: 0.2212, Avg Dice: 0.8510\n",
            "Epoch [25/50], Step [40/50], Avg Loss: 0.2217, Avg Dice: 0.8512\n",
            "Epoch [25/50], Step [45/50], Avg Loss: 0.2224, Avg Dice: 0.8515\n",
            "Epoch [25/50], Step [50/50], Avg Loss: 0.2225, Avg Dice: 0.8518\n",
            "End of epoch 25: Avg Loss: 0.2225, Avg Dice: 0.8518\n",
            "Epoch [26/50], Step [5/50], Avg Loss: 0.2298, Avg Dice: 0.8502\n",
            "Epoch [26/50], Step [10/50], Avg Loss: 0.2261, Avg Dice: 0.8523\n",
            "Epoch [26/50], Step [15/50], Avg Loss: 0.2264, Avg Dice: 0.8531\n",
            "Epoch [26/50], Step [20/50], Avg Loss: 0.2277, Avg Dice: 0.8519\n",
            "Epoch [26/50], Step [25/50], Avg Loss: 0.2245, Avg Dice: 0.8514\n",
            "Epoch [26/50], Step [30/50], Avg Loss: 0.2244, Avg Dice: 0.8518\n",
            "Epoch [26/50], Step [35/50], Avg Loss: 0.2244, Avg Dice: 0.8520\n",
            "Epoch [26/50], Step [40/50], Avg Loss: 0.2235, Avg Dice: 0.8520\n",
            "Epoch [26/50], Step [45/50], Avg Loss: 0.2230, Avg Dice: 0.8513\n",
            "Epoch [26/50], Step [50/50], Avg Loss: 0.2225, Avg Dice: 0.8516\n",
            "End of epoch 26: Avg Loss: 0.2225, Avg Dice: 0.8516\n",
            "Epoch [27/50], Step [5/50], Avg Loss: 0.2153, Avg Dice: 0.8574\n",
            "Epoch [27/50], Step [10/50], Avg Loss: 0.2257, Avg Dice: 0.8568\n",
            "Epoch [27/50], Step [15/50], Avg Loss: 0.2227, Avg Dice: 0.8574\n",
            "Epoch [27/50], Step [20/50], Avg Loss: 0.2223, Avg Dice: 0.8561\n",
            "Epoch [27/50], Step [25/50], Avg Loss: 0.2200, Avg Dice: 0.8562\n",
            "Epoch [27/50], Step [30/50], Avg Loss: 0.2198, Avg Dice: 0.8557\n",
            "Epoch [27/50], Step [35/50], Avg Loss: 0.2180, Avg Dice: 0.8549\n",
            "Epoch [27/50], Step [40/50], Avg Loss: 0.2173, Avg Dice: 0.8540\n",
            "Epoch [27/50], Step [45/50], Avg Loss: 0.2179, Avg Dice: 0.8536\n",
            "Epoch [27/50], Step [50/50], Avg Loss: 0.2174, Avg Dice: 0.8534\n",
            "End of epoch 27: Avg Loss: 0.2174, Avg Dice: 0.8534\n",
            "Epoch [28/50], Step [5/50], Avg Loss: 0.2074, Avg Dice: 0.8500\n",
            "Epoch [28/50], Step [10/50], Avg Loss: 0.2100, Avg Dice: 0.8537\n",
            "Epoch [28/50], Step [15/50], Avg Loss: 0.2103, Avg Dice: 0.8540\n",
            "Epoch [28/50], Step [20/50], Avg Loss: 0.2118, Avg Dice: 0.8540\n",
            "Epoch [28/50], Step [25/50], Avg Loss: 0.2120, Avg Dice: 0.8546\n",
            "Epoch [28/50], Step [30/50], Avg Loss: 0.2122, Avg Dice: 0.8553\n",
            "Epoch [28/50], Step [35/50], Avg Loss: 0.2120, Avg Dice: 0.8551\n",
            "Epoch [28/50], Step [40/50], Avg Loss: 0.2130, Avg Dice: 0.8550\n",
            "Epoch [28/50], Step [45/50], Avg Loss: 0.2139, Avg Dice: 0.8542\n",
            "Epoch [28/50], Step [50/50], Avg Loss: 0.2144, Avg Dice: 0.8541\n",
            "End of epoch 28: Avg Loss: 0.2144, Avg Dice: 0.8541\n",
            "Epoch [29/50], Step [5/50], Avg Loss: 0.2164, Avg Dice: 0.8562\n",
            "Epoch [29/50], Step [10/50], Avg Loss: 0.2138, Avg Dice: 0.8574\n",
            "Epoch [29/50], Step [15/50], Avg Loss: 0.2128, Avg Dice: 0.8564\n",
            "Epoch [29/50], Step [20/50], Avg Loss: 0.2104, Avg Dice: 0.8553\n",
            "Epoch [29/50], Step [25/50], Avg Loss: 0.2109, Avg Dice: 0.8548\n",
            "Epoch [29/50], Step [30/50], Avg Loss: 0.2100, Avg Dice: 0.8545\n",
            "Epoch [29/50], Step [35/50], Avg Loss: 0.2106, Avg Dice: 0.8548\n",
            "Epoch [29/50], Step [40/50], Avg Loss: 0.2089, Avg Dice: 0.8557\n",
            "Epoch [29/50], Step [45/50], Avg Loss: 0.2105, Avg Dice: 0.8554\n",
            "Epoch [29/50], Step [50/50], Avg Loss: 0.2112, Avg Dice: 0.8552\n",
            "End of epoch 29: Avg Loss: 0.2112, Avg Dice: 0.8552\n",
            "Epoch [30/50], Step [5/50], Avg Loss: 0.2053, Avg Dice: 0.8587\n",
            "Epoch [30/50], Step [10/50], Avg Loss: 0.2093, Avg Dice: 0.8571\n",
            "Epoch [30/50], Step [15/50], Avg Loss: 0.2099, Avg Dice: 0.8559\n",
            "Epoch [30/50], Step [20/50], Avg Loss: 0.2094, Avg Dice: 0.8562\n",
            "Epoch [30/50], Step [25/50], Avg Loss: 0.2081, Avg Dice: 0.8557\n",
            "Epoch [30/50], Step [30/50], Avg Loss: 0.2102, Avg Dice: 0.8558\n",
            "Epoch [30/50], Step [35/50], Avg Loss: 0.2091, Avg Dice: 0.8556\n",
            "Epoch [30/50], Step [40/50], Avg Loss: 0.2101, Avg Dice: 0.8560\n",
            "Epoch [30/50], Step [45/50], Avg Loss: 0.2100, Avg Dice: 0.8563\n",
            "Epoch [30/50], Step [50/50], Avg Loss: 0.2092, Avg Dice: 0.8564\n",
            "End of epoch 30: Avg Loss: 0.2092, Avg Dice: 0.8564\n",
            "Epoch [31/50], Step [5/50], Avg Loss: 0.2036, Avg Dice: 0.8567\n",
            "Epoch [31/50], Step [10/50], Avg Loss: 0.2020, Avg Dice: 0.8567\n",
            "Epoch [31/50], Step [15/50], Avg Loss: 0.2050, Avg Dice: 0.8572\n",
            "Epoch [31/50], Step [20/50], Avg Loss: 0.2070, Avg Dice: 0.8571\n",
            "Epoch [31/50], Step [25/50], Avg Loss: 0.2083, Avg Dice: 0.8571\n",
            "Epoch [31/50], Step [30/50], Avg Loss: 0.2053, Avg Dice: 0.8578\n",
            "Epoch [31/50], Step [35/50], Avg Loss: 0.2041, Avg Dice: 0.8572\n",
            "Epoch [31/50], Step [40/50], Avg Loss: 0.2051, Avg Dice: 0.8567\n",
            "Epoch [31/50], Step [45/50], Avg Loss: 0.2044, Avg Dice: 0.8575\n",
            "Epoch [31/50], Step [50/50], Avg Loss: 0.2057, Avg Dice: 0.8572\n",
            "End of epoch 31: Avg Loss: 0.2057, Avg Dice: 0.8572\n",
            "Epoch [32/50], Step [5/50], Avg Loss: 0.1980, Avg Dice: 0.8602\n",
            "Epoch [32/50], Step [10/50], Avg Loss: 0.1930, Avg Dice: 0.8595\n",
            "Epoch [32/50], Step [15/50], Avg Loss: 0.1955, Avg Dice: 0.8592\n",
            "Epoch [32/50], Step [20/50], Avg Loss: 0.1977, Avg Dice: 0.8584\n",
            "Epoch [32/50], Step [25/50], Avg Loss: 0.1986, Avg Dice: 0.8579\n",
            "Epoch [32/50], Step [30/50], Avg Loss: 0.2012, Avg Dice: 0.8577\n",
            "Epoch [32/50], Step [40/50], Avg Loss: 0.2021, Avg Dice: 0.8584\n",
            "Epoch [32/50], Step [45/50], Avg Loss: 0.2039, Avg Dice: 0.8580\n",
            "Epoch [32/50], Step [50/50], Avg Loss: 0.2038, Avg Dice: 0.8581\n",
            "End of epoch 32: Avg Loss: 0.2038, Avg Dice: 0.8581\n",
            "Epoch [33/50], Step [5/50], Avg Loss: 0.2067, Avg Dice: 0.8602\n",
            "Epoch [33/50], Step [10/50], Avg Loss: 0.2086, Avg Dice: 0.8575\n",
            "Epoch [33/50], Step [15/50], Avg Loss: 0.2051, Avg Dice: 0.8589\n",
            "Epoch [33/50], Step [20/50], Avg Loss: 0.2026, Avg Dice: 0.8592\n",
            "Epoch [33/50], Step [25/50], Avg Loss: 0.2006, Avg Dice: 0.8586\n",
            "Epoch [33/50], Step [30/50], Avg Loss: 0.2006, Avg Dice: 0.8592\n",
            "Epoch [33/50], Step [35/50], Avg Loss: 0.2005, Avg Dice: 0.8594\n",
            "Epoch [33/50], Step [40/50], Avg Loss: 0.2004, Avg Dice: 0.8587\n",
            "Epoch [33/50], Step [45/50], Avg Loss: 0.2009, Avg Dice: 0.8586\n",
            "Epoch [33/50], Step [50/50], Avg Loss: 0.2020, Avg Dice: 0.8585\n",
            "End of epoch 33: Avg Loss: 0.2020, Avg Dice: 0.8585\n",
            "Epoch [34/50], Step [5/50], Avg Loss: 0.2142, Avg Dice: 0.8586\n",
            "Epoch [34/50], Step [10/50], Avg Loss: 0.2056, Avg Dice: 0.8570\n",
            "Epoch [34/50], Step [15/50], Avg Loss: 0.2051, Avg Dice: 0.8580\n",
            "Epoch [34/50], Step [20/50], Avg Loss: 0.2004, Avg Dice: 0.8571\n",
            "Epoch [34/50], Step [25/50], Avg Loss: 0.2010, Avg Dice: 0.8569\n",
            "Epoch [34/50], Step [30/50], Avg Loss: 0.2006, Avg Dice: 0.8571\n",
            "Epoch [34/50], Step [35/50], Avg Loss: 0.1998, Avg Dice: 0.8580\n",
            "Epoch [34/50], Step [40/50], Avg Loss: 0.2001, Avg Dice: 0.8586\n",
            "Epoch [34/50], Step [45/50], Avg Loss: 0.2006, Avg Dice: 0.8587\n",
            "Epoch [34/50], Step [50/50], Avg Loss: 0.2009, Avg Dice: 0.8587\n",
            "End of epoch 34: Avg Loss: 0.2009, Avg Dice: 0.8587\n",
            "Epoch [35/50], Step [5/50], Avg Loss: 0.1984, Avg Dice: 0.8566\n",
            "Epoch [35/50], Step [10/50], Avg Loss: 0.1980, Avg Dice: 0.8601\n",
            "Epoch [35/50], Step [15/50], Avg Loss: 0.2015, Avg Dice: 0.8606\n",
            "Epoch [35/50], Step [20/50], Avg Loss: 0.2027, Avg Dice: 0.8604\n",
            "Epoch [35/50], Step [25/50], Avg Loss: 0.2004, Avg Dice: 0.8599\n",
            "Epoch [35/50], Step [30/50], Avg Loss: 0.2013, Avg Dice: 0.8595\n",
            "Epoch [35/50], Step [35/50], Avg Loss: 0.1999, Avg Dice: 0.8594\n",
            "Epoch [35/50], Step [40/50], Avg Loss: 0.1994, Avg Dice: 0.8594\n",
            "Epoch [35/50], Step [45/50], Avg Loss: 0.1996, Avg Dice: 0.8597\n",
            "Epoch [35/50], Step [50/50], Avg Loss: 0.1993, Avg Dice: 0.8592\n",
            "End of epoch 35: Avg Loss: 0.1993, Avg Dice: 0.8592\n",
            "Epoch [36/50], Step [5/50], Avg Loss: 0.1952, Avg Dice: 0.8626\n",
            "Epoch [36/50], Step [10/50], Avg Loss: 0.1942, Avg Dice: 0.8609\n",
            "Epoch [36/50], Step [15/50], Avg Loss: 0.1928, Avg Dice: 0.8614\n",
            "Epoch [36/50], Step [20/50], Avg Loss: 0.1922, Avg Dice: 0.8610\n",
            "Epoch [36/50], Step [25/50], Avg Loss: 0.1957, Avg Dice: 0.8604\n",
            "Epoch [36/50], Step [30/50], Avg Loss: 0.1966, Avg Dice: 0.8596\n",
            "Epoch [36/50], Step [35/50], Avg Loss: 0.1960, Avg Dice: 0.8598\n",
            "Epoch [36/50], Step [40/50], Avg Loss: 0.1967, Avg Dice: 0.8598\n",
            "Epoch [36/50], Step [45/50], Avg Loss: 0.1965, Avg Dice: 0.8600\n",
            "Epoch [36/50], Step [50/50], Avg Loss: 0.1971, Avg Dice: 0.8600\n",
            "End of epoch 36: Avg Loss: 0.1971, Avg Dice: 0.8600\n",
            "Epoch [37/50], Step [5/50], Avg Loss: 0.1839, Avg Dice: 0.8635\n",
            "Epoch [37/50], Step [10/50], Avg Loss: 0.1896, Avg Dice: 0.8615\n",
            "Epoch [37/50], Step [15/50], Avg Loss: 0.1905, Avg Dice: 0.8618\n",
            "Epoch [37/50], Step [20/50], Avg Loss: 0.1911, Avg Dice: 0.8616\n",
            "Epoch [37/50], Step [25/50], Avg Loss: 0.1933, Avg Dice: 0.8609\n",
            "Epoch [37/50], Step [30/50], Avg Loss: 0.1933, Avg Dice: 0.8610\n",
            "Epoch [37/50], Step [35/50], Avg Loss: 0.1950, Avg Dice: 0.8613\n",
            "Epoch [37/50], Step [40/50], Avg Loss: 0.1945, Avg Dice: 0.8613\n",
            "Epoch [37/50], Step [45/50], Avg Loss: 0.1948, Avg Dice: 0.8612\n",
            "Epoch [37/50], Step [50/50], Avg Loss: 0.1946, Avg Dice: 0.8610\n",
            "End of epoch 37: Avg Loss: 0.1946, Avg Dice: 0.8610\n",
            "Epoch [38/50], Step [5/50], Avg Loss: 0.2035, Avg Dice: 0.8594\n",
            "Epoch [38/50], Step [10/50], Avg Loss: 0.1983, Avg Dice: 0.8588\n",
            "Epoch [38/50], Step [15/50], Avg Loss: 0.1977, Avg Dice: 0.8597\n",
            "Epoch [38/50], Step [20/50], Avg Loss: 0.1954, Avg Dice: 0.8605\n",
            "Epoch [38/50], Step [25/50], Avg Loss: 0.1941, Avg Dice: 0.8613\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-83a9c2fe0206>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;31m# Train the model with Dice score monitoring and prediction plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_loss_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training completed!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-83a9c2fe0206>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, device, num_epochs, aux_loss_weight, num_classes, plot_freq)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mseg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseg_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maux_loss_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maux_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, device, num_classes, n_samples_to_plot=3):\n",
        "    model.eval()\n",
        "    total_dice = 0.0\n",
        "    count = 0\n",
        "    plotted = False  # flag to plot only once per evaluation run\n",
        "    with torch.no_grad():\n",
        "        for images, masks in dataloader:\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)  # [B, H, W]\n",
        "            seg_logits, _ = model(images)\n",
        "            preds = torch.argmax(seg_logits, dim=1)  # [B, H, W]\n",
        "            batch_dice = dice_score(preds, masks, num_classes)\n",
        "            total_dice += batch_dice.item() if isinstance(batch_dice, torch.Tensor) else batch_dice\n",
        "            count += 1\n",
        "\n",
        "            # Optionally plot predictions from one batch during evaluation\n",
        "            if not plotted:\n",
        "                plot_prediction_and_mask(images, masks, preds, class_colors = class_colors)\n",
        "                plotted = True\n",
        "\n",
        "    avg_dice = total_dice / count\n",
        "    print(f\"Average Dice score on Validation: {avg_dice:.4f}\")\n",
        "    return avg_dice\n"
      ],
      "metadata": {
        "id": "0jVDfMPkQnsb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, val_loader, device, num_classes, n_samples_to_plot=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "J2IQvFWUTBo8",
        "outputId": "0c29b549-c951-4d09-b7ff-c1a9aafcf520"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-b4c2e9a82ace>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples_to_plot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-acd30eb12e8f>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, dataloader, device, num_classes, n_samples_to_plot)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m# Optionally plot predictions from one batch during evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mplotted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0mplot_prediction_and_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_colors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_colors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0mplotted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-f73a6221d35b>\u001b[0m in \u001b[0;36mplot_prediction_and_mask\u001b[0;34m(image, pred_mask, true_mask, class_colors)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;31m# Create color masks for the predicted and true masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m     \u001b[0mpred_color_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolorize_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_colors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     \u001b[0mtrue_color_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolorize_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_colors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-f73a6221d35b>\u001b[0m in \u001b[0;36mcolorize_mask\u001b[0;34m(mask, class_colors)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \"\"\"\n\u001b[1;32m    230\u001b[0m     \u001b[0;31m# Create an empty array with an extra channel for color (RGB)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0mcolor_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def find_unique_classes_from_masks(mask_files):\n",
        "    \"\"\"\n",
        "    Given a list of mask file paths, compute the union of unique pixel values\n",
        "    from each mask, and return a sorted list of unique classes.\n",
        "    \"\"\"\n",
        "    unique_classes = set()\n",
        "\n",
        "    for mask_path in mask_files:\n",
        "        # Open the mask image and convert it to a numpy array\n",
        "        mask = Image.open(mask_path)\n",
        "        mask_array = np.array(mask)\n",
        "\n",
        "        # Update the unique classes set with the values found in this mask\n",
        "        unique_values = np.unique(mask_array)\n",
        "        unique_classes.update(unique_values)\n",
        "\n",
        "    # Convert the set to a sorted list before returning\n",
        "    return sorted(unique_classes)\n",
        "\n",
        "# Example usage:\n",
        "# if __name__ == \"__main__\":\n",
        "    # Replace this with the path to your mask folder\n",
        "    # mask_folder = \"path/to/your/mask_folder\"\n",
        "    # Get a list of all mask file paths (assuming PNG or JPG images)\n",
        "mask_files = mask_paths\n",
        "\n",
        "unique_classes = find_unique_classes_from_masks(mask_files)\n",
        "num_classes = len(unique_classes)\n",
        "\n",
        "print(\"Found unique classes:\", unique_classes)\n",
        "print(\"Number of classes:\", num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHtlB0BoTEC4",
        "outputId": "aa02979f-642b-42fd-eeba-25c1d9416f9a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found unique classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 255]\n",
            "Number of classes: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sq5OfQg-aH5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BD100K"
      ],
      "metadata": {
        "id": "70cvu_1QbWd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "solesensei_solesensei_bdd100k_path = kagglehub.dataset_download('solesensei/solesensei_bdd100k')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRBqzjBqbXrC",
        "outputId": "ee2d25eb-8e6d-410a-d4f3-cc3eddcb9838"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.7).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/solesensei/solesensei_bdd100k?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7.61G/7.61G [06:17<00:00, 21.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n",
            "Num GPUs Available:  1\n",
            "0 data points loaded in total!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(solesensei_solesensei_bdd100k_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMUjR0ogf9aB",
        "outputId": "76132b85-f832-439d-9537-fce24bb08b4e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cache/kagglehub/datasets/solesensei/solesensei_bdd100k/versions/2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "from sklearn import utils as sk_utils\n",
        "\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "# define image size\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 192\n",
        "IMG_CHANNELS = 3\n",
        "\n",
        "\n",
        "TRAIN_PATH = '/root/.cache/kagglehub/datasets/solesensei/solesensei_bdd100k/versions/2/bdd100k_seg/bdd100k/seg/images/train/*.jpg'\n",
        "MASK_TRAIN = '/root/.cache/kagglehub/datasets/solesensei/solesensei_bdd100k/versions/2/bdd100k_seg/bdd100k/seg/labels/train/*.png'\n",
        "\n",
        "def load_image(file_path, is_x=False):\n",
        "    image = tf.io.read_file(file_path)\n",
        "    image = tf.image.decode_image(image)\n",
        "\n",
        "    if is_x:\n",
        "        image = tf.image.resize(image, (IMG_HEIGHT,IMG_WIDTH), method=tf.image.ResizeMethod.LANCZOS3)\n",
        "        image = image / 255.0  # Normalize the image\n",
        "    else:\n",
        "        image = tf.image.resize(image, (IMG_HEIGHT,IMG_WIDTH), method='nearest', antialias=True)\n",
        "    return image\n",
        "\n",
        "\n",
        "image_paths = sorted(glob.glob(TRAIN_PATH))\n",
        "mask_paths = sorted(glob.glob(MASK_TRAIN))\n",
        "image_paths, mask_paths = sk_utils.shuffle(image_paths, mask_paths, random_state=42)\n",
        "\n",
        "# X_train = []\n",
        "# Y_train = []\n",
        "\n",
        "# for x, y in zip(image_paths, mask_paths):\n",
        "#     X_train.append(load_image(x, True))\n",
        "#     Y_train.append(load_image(y))\n",
        "#     if len(X_train) % 500 == 0:\n",
        "#         print(len(X_train), 'data points loaded!')\n",
        "# else:\n",
        "#     print(len(X_train), 'data points loaded in total!')\n",
        "\n",
        "\n",
        "# # Convert the lists to NumPy arrays\n",
        "# X_train = np.array(X_train)\n",
        "# Y_train = np.array(Y_train)\n",
        "# # 255 is representing unknown objects\n",
        "# Y_train[Y_train == 255] = 19\n",
        "\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# color_dict = {\n",
        "#     0: (0.7, 0.7, 0.7),     # road - gray\n",
        "#     1:  (0.9, 0.9, 0.2),     # sidewalk - light yellow\n",
        "#     2: (1.0, 0.4980392156862745, 0.054901960784313725),\n",
        "#     3: (1.0, 0.7333333333333333, 0.47058823529411764),\n",
        "#     4: (0.8, 0.5, 0.1),  # Fence - rust orange\n",
        "#     5: (0.596078431372549, 0.8745098039215686, 0.5411764705882353),\n",
        "#     6: (0.325, 0.196, 0.361),\n",
        "#     7: (1.0, 0.596078431372549, 0.5882352941176471),\n",
        "#     8:  (0.2, 0.6, 0.2),     # vegetation - green\n",
        "#     9: (0.7725490196078432, 0.6901960784313725, 0.8352941176470589),\n",
        "#     10: (0.5, 0.7, 1.0),     # sky - light blue\n",
        "#     11: (1.0, 0.0, 0.0), # person - red\n",
        "#     12: (0.8901960784313725, 0.4666666666666667, 0.7607843137254902),\n",
        "#     13: (0.0, 0.0, 1.0),  # Car - blue\n",
        "#     14: (0.0, 0.0, 1.0),  # Track - blue\n",
        "#     15: (0.0, 0.0, 1.0),  # Bus - blue\n",
        "#     16: (0.7372549019607844, 0.7411764705882353, 0.13333333333333333),\n",
        "#     17: (0.8588235294117647, 0.8588235294117647, 0.5529411764705883),\n",
        "#     18: (0.09019607843137255, 0.7450980392156863, 0.8117647058823529),\n",
        "#     19: (0, 0, 0) # unknown - black\n",
        "# }\n",
        "\n",
        "# def colorize_image(image, color_dict):\n",
        "#     # remove the extra dimension\n",
        "#     image = np.squeeze(image)\n",
        "#     # Generate the colored image using the color dictionary\n",
        "#     colored_image = np.zeros((image.shape[0], image.shape[1], 3))\n",
        "\n",
        "#     for pixel_value, color in color_dict.items():\n",
        "#         colored_image[image == pixel_value] = color\n",
        "\n",
        "#     # Convert the image to 8-bit unsigned integer\n",
        "#     colored_image = (colored_image * 255).astype(np.uint8)\n",
        "\n",
        "#     return colored_image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ltogz4QAf5-D",
        "outputId": "ea19ef41-b483-454e-f112-a0f8bc620ce4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /root/.cache/kagglehub/datasets/solesensei/solesensei_bdd100k/versions/2/bdd100k_seg/bdd100k/seg/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMRrxCWwgU-J",
        "outputId": "c81e2755-7468-4aed-fb48-40c64b9de336"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "color_labels  images  labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(Image.open(mask_paths[100]).convert(\"L\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugUR-r4igPoX",
        "outputId": "856bc29d-ffe6-4990-942a-9616956b044b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   1,   2,   5,   6,   7,   8,   9,  10,  13,  14,  15, 255],\n",
              "      dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Define your Dataset class\n",
        "# -----------------------------\n",
        "class LyftSegmentationDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for segmentation that loads images and masks from disk.\n",
        "    Assumes images are in RGB and masks are single-channel with integer labels.\n",
        "    \"\"\"\n",
        "    def __init__(self, image_list, mask_list, transform_image=None, transform_mask=None):\n",
        "        assert len(image_list) == len(mask_list), \"Image and mask lists must be equal length.\"\n",
        "        self.image_list = image_list\n",
        "        self.mask_list = mask_list\n",
        "        self.transform_image = transform_image\n",
        "        self.transform_mask = transform_mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_list[idx]).convert(\"RGB\")\n",
        "        mask = Image.open(self.mask_list[idx]).convert(\"L\")  # Convert to single channel\n",
        "\n",
        "        if self.transform_image:\n",
        "            image = self.transform_image(image)\n",
        "        if self.transform_mask:\n",
        "            mask = self.transform_mask(mask)\n",
        "        else:\n",
        "            mask = torch.from_numpy(np.array(mask, dtype=np.int64))\n",
        "        mask[mask == 255] = 19  # or map to another appropriate class index if needed\n",
        "        return image, mask\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Define image and mask transformations\n",
        "# -----------------------------\n",
        "img_size = 224  # Defined image size\n",
        "transform_image = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),  # [0, 1] float tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transform_mask = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size), interpolation=Image.NEAREST),\n",
        "    transforms.Lambda(lambda x: torch.from_numpy(np.array(x, dtype=np.int64)))\n",
        "])\n",
        "\n",
        "# -----------------------------\n",
        "# 3. File lists for images and masks\n",
        "# -----------------------------\n",
        "# image_path = '/kaggle/input/lyft-udacity-challenge/dataa/dataA/CameraRGB/'\n",
        "# mask_path = '/kaggle/input/lyft-udacity-challenge/dataa/dataA/CameraSeg/'\n",
        "\n",
        "# image_list = sorted([os.path.join(image_path, i) for i in os.listdir(image_path)])\n",
        "# mask_list = sorted([os.path.join(mask_path, i) for i in os.listdir(mask_path)])\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Define the Switch Transformer Segmentation Model and components\n",
        "# -----------------------------\n",
        "class PatchEmbedding(nn.Module):\n",
        "    def __init__(self, img_size=224, patch_size=16, in_channels=3, embed_dim=768):\n",
        "        super().__init__()\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = (img_size // patch_size) ** 2\n",
        "        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, self.num_patches, embed_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, in_channels, H, W]\n",
        "        x = self.proj(x)                    # [B, embed_dim, H/patch_size, W/patch_size]\n",
        "        x = x.flatten(2)                    # [B, embed_dim, num_patches]\n",
        "        x = x.transpose(1, 2)               # [B, num_patches, embed_dim]\n",
        "        x += self.pos_embedding             # Add position embedding\n",
        "        return x\n",
        "\n",
        "class ExpertFFN(nn.Module):\n",
        "    def __init__(self, embed_dim, expansion=4):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(embed_dim, embed_dim * expansion)\n",
        "        self.fc2 = nn.Linear(embed_dim * expansion, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.gelu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class SwitchFFN(nn.Module):\n",
        "    def __init__(self, embed_dim, num_experts=4, expansion=4):\n",
        "        super().__init__()\n",
        "        self.num_experts = num_experts\n",
        "        self.experts = nn.ModuleList([ExpertFFN(embed_dim, expansion) for _ in range(num_experts)])\n",
        "        self.gate = nn.Linear(embed_dim, num_experts)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, D = x.shape\n",
        "        logits = self.gate(x)               # [B, N, num_experts]\n",
        "        indices = logits.argmax(dim=-1)     # [B, N] - select expert index with highest score\n",
        "        output = torch.zeros_like(x)\n",
        "        expert_counts = torch.zeros(B, self.num_experts, device=x.device)\n",
        "        for expert_id in range(self.num_experts):\n",
        "            mask = (indices == expert_id)   # Boolean mask [B, N]\n",
        "            if mask.sum() == 0:\n",
        "                continue\n",
        "            selected_tokens = x[mask]       # [num_selected, D]\n",
        "            expert_output = self.experts[expert_id](selected_tokens)\n",
        "            output[mask] = expert_output\n",
        "            expert_counts[:, expert_id] += mask.float().sum(dim=1) if mask.dim() == 2 else mask.float().sum(dim=0)\n",
        "        return output, expert_counts\n",
        "\n",
        "class SwitchTransformerLayer(nn.Module):\n",
        "    def __init__(self, embed_dim, num_experts=4, expansion=4, num_heads=8, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.switch_ffn = SwitchFFN(embed_dim, num_experts=num_experts, expansion=expansion)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_out, _ = self.self_attn(x, x, x)\n",
        "        x = x + self.dropout(attn_out)\n",
        "        x = self.norm1(x)\n",
        "        ffn_out, expert_counts = self.switch_ffn(x)\n",
        "        x = x + self.dropout(ffn_out)\n",
        "        x = self.norm2(x)\n",
        "        return x, expert_counts\n",
        "\n",
        "class SwitchTransformerEncoder(nn.Module):\n",
        "    def __init__(self, depth, embed_dim, num_experts=4, expansion=4, num_heads=8, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            SwitchTransformerLayer(embed_dim, num_experts, expansion, num_heads, dropout)\n",
        "            for _ in range(depth)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        aux_loss = 0.0\n",
        "        for layer in self.layers:\n",
        "            x, expert_counts = layer(x)\n",
        "            # Optionally, incorporate an auxiliary loss for load balancing here if desired.\n",
        "        return x, aux_loss\n",
        "\n",
        "class SegmentationDecoder(nn.Module):\n",
        "    def __init__(self, embed_dim, img_size=224, patch_size=16, num_classes=21):\n",
        "        super().__init__()\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches_side = img_size // patch_size\n",
        "        self.conv1 = nn.Conv2d(embed_dim, embed_dim // 2, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(embed_dim // 2)\n",
        "        self.conv2 = nn.Conv2d(embed_dim // 2, num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, D = x.shape\n",
        "        H = W = self.num_patches_side\n",
        "        x = x.transpose(1, 2).reshape(B, D, H, W)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.interpolate(x, size=(self.img_size, self.img_size), mode='bilinear', align_corners=False)\n",
        "        logits = self.conv2(x)\n",
        "        return logits\n",
        "\n",
        "class SwitchTransformerSegmentationModel(nn.Module):\n",
        "    def __init__(self, img_size=224, patch_size=16, in_channels=3, embed_dim=768, depth=6,\n",
        "                 num_experts=4, expansion=4, num_heads=8, dropout=0.1, num_classes=21):\n",
        "        super().__init__()\n",
        "        self.patch_embedding = PatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n",
        "        self.encoder = SwitchTransformerEncoder(depth, embed_dim, num_experts, expansion, num_heads, dropout)\n",
        "        self.decoder = SegmentationDecoder(embed_dim, img_size, patch_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_embedding(x)\n",
        "        x, aux_loss = self.encoder(x)\n",
        "        segmentation_logits = self.decoder(x)\n",
        "        return segmentation_logits, aux_loss\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Define Dice Score Function\n",
        "# -----------------------------\n",
        "def dice_score(pred, target, num_classes, epsilon=1e-6):\n",
        "    \"\"\"\n",
        "    Computes the Dice score per class and returns the average score.\n",
        "    pred: tensor of shape [B, H, W] with predicted classes.\n",
        "    target: tensor of shape [B, H, W] with ground truth classes.\n",
        "    \"\"\"\n",
        "    dice = 0.0\n",
        "    for cls in range(num_classes):\n",
        "        pred_cls = (pred == cls).float()\n",
        "        target_cls = (target == cls).float()\n",
        "        intersection = (pred_cls * target_cls).sum()\n",
        "        union = pred_cls.sum() + target_cls.sum()\n",
        "        dice += (2 * intersection + epsilon) / (union + epsilon)\n",
        "    return dice / num_classes\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define your class colors (adjust the number of classes/colors as needed)\n",
        "class_colors = {\n",
        "    0: (1, 0, 0),   # red  (often used for background, or class 0)\n",
        "    1: (0, 1, 0),   # green (class 1)\n",
        "    2: (0, 0, 1),   # blue  (class 2)\n",
        "    3: (1, 0, 1)    # magenta (class 3)\n",
        "}\n",
        "\n",
        "\n",
        "def colorize_mask(mask, class_colors):\n",
        "    \"\"\"\n",
        "    Colorize a segmentation mask given a mapping from class labels to colors.\n",
        "\n",
        "    Parameters:\n",
        "        mask (np.ndarray): 2D array (height, width) of class indices.\n",
        "        class_colors (dict): dictionary mapping class indices to RGB tuples.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: colorized mask of shape (height, width, 3) for visualization.\n",
        "    \"\"\"\n",
        "    # Create an empty array with an extra channel for color (RGB)\n",
        "    h, w = mask.shape\n",
        "    color_mask = np.zeros((h, w, 3), dtype=np.float32)\n",
        "\n",
        "    # Assign colors for each class present in the mask\n",
        "    for class_id, color in class_colors.items():\n",
        "        color_mask[mask == class_id] = color\n",
        "\n",
        "    return color_mask\n",
        "\n",
        "# -----------------------------\n",
        "# 6. Helper function to plot predictions\n",
        "# -----------------------------\n",
        "def plot_prediction_and_mask(image, pred_mask, true_mask, class_colors):\n",
        "    \"\"\"\n",
        "    Plot the original image, prediction mask, and ground truth mask.\n",
        "\n",
        "    Parameters:\n",
        "        image (np.ndarray): the input image of shape (height, width, 3).\n",
        "        pred_mask (np.ndarray): predicted segmentation mask (class indices).\n",
        "        true_mask (np.ndarray): ground truth segmentation mask (class indices).\n",
        "        class_colors (dict): mapping from class labels to colors.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create color masks for the predicted and true masks\n",
        "    pred_color_mask = colorize_mask(pred_mask, class_colors)\n",
        "    true_color_mask = colorize_mask(true_mask, class_colors)\n",
        "\n",
        "    # Plotting using matplotlib\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "    # Show original image\n",
        "    axes[0].imshow(image)\n",
        "    axes[0].set_title(\"Original Image\")\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Show predicted mask\n",
        "    axes[1].imshow(pred_color_mask)\n",
        "    axes[1].set_title(\"Predicted Mask\")\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # Show ground truth mask\n",
        "    axes[2].imshow(true_color_mask)\n",
        "    axes[2].set_title(\"Ground Truth Mask\")\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 7. Training loop with Dice score and prediction plotting\n",
        "# -----------------------------\n",
        "def train(model, dataloader, optimizer, device, num_epochs=5, aux_loss_weight=0.01, num_classes=21, plot_freq=10):\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()  # segmentation cross-entropy loss\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        running_dice = 0.0\n",
        "        for i, (images, masks) in enumerate(dataloader):\n",
        "            images = images.to(device)      # [B, 3, H, W]\n",
        "            masks = masks.to(device)        # [B, H, W]\n",
        "            masks = masks.long()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            seg_logits, aux_loss = model(images)\n",
        "            # assert outputs.shape[1] == num_classes, \"The number of output channels must equal the number of classes.\"\n",
        "\n",
        "            # seg_logits shape: [B, num_classes, H, W]\n",
        "            seg_loss = criterion(seg_logits, masks)\n",
        "            loss = seg_loss + aux_loss_weight * aux_loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Calculate Dice score on training mini-batch:\n",
        "            preds = torch.argmax(seg_logits, dim=1)  # shape: [B, H, W]\n",
        "            batch_dice = dice_score(preds, masks, num_classes)\n",
        "            running_dice += batch_dice.item() if isinstance(batch_dice, torch.Tensor) else batch_dice\n",
        "\n",
        "            # Every plot_freq iterations, plot a few example predictions from the current batch.\n",
        "            # if (i + 1) % plot_freq == 0:\n",
        "            #     print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n",
        "            #     # Plot first few images. Adjust n_samples as desired.\n",
        "            #     plot_predictions(images, masks, preds, n_samples=3, title_prefix=\"Train\")\n",
        "\n",
        "            if (i + 1) % 5 == 0:\n",
        "                avg_loss = running_loss / (i+1)\n",
        "                avg_dice = running_dice / (i+1)\n",
        "                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Avg Loss: {avg_loss:.4f}, Avg Dice: {avg_dice:.4f}\")\n",
        "        print(f\"End of epoch {epoch+1}: Avg Loss: {running_loss/len(dataloader):.4f}, Avg Dice: {running_dice/len(dataloader):.4f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 8. Evaluation loop with prediction plotting\n",
        "# -----------------------------\n",
        "def evaluate(model, dataloader, device, num_classes, n_samples_to_plot=3):\n",
        "    model.eval()\n",
        "    total_dice = 0.0\n",
        "    count = 0\n",
        "    plotted = False  # flag to plot only once per evaluation run\n",
        "    with torch.no_grad():\n",
        "        for images, masks in dataloader:\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)  # [B, H, W]\n",
        "            seg_logits, _ = model(images)\n",
        "            preds = torch.argmax(seg_logits, dim=1)  # [B, H, W]\n",
        "            batch_dice = dice_score(preds, masks, num_classes)\n",
        "            total_dice += batch_dice.item() if isinstance(batch_dice, torch.Tensor) else batch_dice\n",
        "            count += 1\n",
        "\n",
        "            # Optionally plot predictions from one batch during evaluation\n",
        "            if not plotted:\n",
        "                plot_prediction_and_mask(images, masks, preds, n_samples=n_samples_to_plot, title_prefix=\"Eval\")\n",
        "                plotted = True\n",
        "\n",
        "    avg_dice = total_dice / count\n",
        "    print(f\"Average Dice score on Validation: {avg_dice:.4f}\")\n",
        "    return avg_dice\n",
        "\n",
        "# -----------------------------\n",
        "# 9. Main: Dataset setup, model instantiation, training, and evaluation\n",
        "# -----------------------------\n",
        "# def main():\n",
        "    # Hyperparameters\n",
        "# ... (Your previous code for model and dataset)\n",
        "\n",
        "# Hyperparameters\n",
        "num_epochs = 50\n",
        "batch_size = 16\n",
        "learning_rate = 1e-4\n",
        "num_classes = 21  # Change this to reflect the number of classes in the BDD100K dataset\n",
        "\n",
        "# ... (Rest of your code for model loading and training)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create full dataset\n",
        "full_dataset = LyftSegmentationDataset(\n",
        "    image_list=image_paths,\n",
        "    mask_list=mask_paths,\n",
        "    transform_image=transform_image,\n",
        "    transform_mask=transform_mask\n",
        ")\n",
        "\n",
        "# Split the dataset into training and validation sets (80-20 split)\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Instantiate model\n",
        "model = SwitchTransformerSegmentationModel(\n",
        "    img_size=img_size,\n",
        "    patch_size=16,\n",
        "    in_channels=3,\n",
        "    embed_dim=256,    # Reduced embed_dim to speed testing; adjust as needed\n",
        "    depth=3,          # Adjust depth as required\n",
        "    num_experts=4,\n",
        "    expansion=4,\n",
        "    num_heads=4,\n",
        "    dropout=0.1,\n",
        "    num_classes=num_classes\n",
        ")\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model with Dice score monitoring and prediction plotting\n",
        "print(\"Starting training...\")\n",
        "train(model, train_loader, optimizer, device, num_epochs=num_epochs, aux_loss_weight=0.01, num_classes=num_classes, plot_freq=10)\n",
        "print(\"Training completed!\")\n",
        "\n",
        "# Evaluate the model using Dice score and plot predictions from the validation set\n",
        "print(\"Evaluating model performance...\")\n",
        "evaluate(model, val_loader, device, num_classes, n_samples_to_plot=3)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1BYINV7c-4D",
        "outputId": "58cb19bb-aab9-4212-fde0-7a3f8cbed5f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Epoch [1/50], Step [5/350], Avg Loss: 3.0115, Avg Dice: 0.0392\n",
            "Epoch [1/50], Step [10/350], Avg Loss: 2.8190, Avg Dice: 0.0641\n",
            "Epoch [1/50], Step [15/350], Avg Loss: 2.6982, Avg Dice: 0.0879\n",
            "Epoch [1/50], Step [20/350], Avg Loss: 2.5907, Avg Dice: 0.1077\n",
            "Epoch [1/50], Step [25/350], Avg Loss: 2.5059, Avg Dice: 0.1292\n",
            "Epoch [1/50], Step [30/350], Avg Loss: 2.4433, Avg Dice: 0.1441\n",
            "Epoch [1/50], Step [35/350], Avg Loss: 2.3851, Avg Dice: 0.1549\n",
            "Epoch [1/50], Step [40/350], Avg Loss: 2.3198, Avg Dice: 0.1624\n",
            "Epoch [1/50], Step [45/350], Avg Loss: 2.2674, Avg Dice: 0.1754\n",
            "Epoch [1/50], Step [50/350], Avg Loss: 2.2314, Avg Dice: 0.1901\n",
            "Epoch [1/50], Step [55/350], Avg Loss: 2.1911, Avg Dice: 0.1999\n",
            "Epoch [1/50], Step [60/350], Avg Loss: 2.1644, Avg Dice: 0.2055\n",
            "Epoch [1/50], Step [65/350], Avg Loss: 2.1286, Avg Dice: 0.2143\n",
            "Epoch [1/50], Step [70/350], Avg Loss: 2.1023, Avg Dice: 0.2226\n",
            "Epoch [1/50], Step [75/350], Avg Loss: 2.0814, Avg Dice: 0.2301\n",
            "Epoch [1/50], Step [80/350], Avg Loss: 2.0595, Avg Dice: 0.2369\n",
            "Epoch [1/50], Step [85/350], Avg Loss: 2.0329, Avg Dice: 0.2394\n",
            "Epoch [1/50], Step [90/350], Avg Loss: 2.0134, Avg Dice: 0.2421\n",
            "Epoch [1/50], Step [95/350], Avg Loss: 1.9872, Avg Dice: 0.2490\n",
            "Epoch [1/50], Step [100/350], Avg Loss: 1.9712, Avg Dice: 0.2512\n",
            "Epoch [1/50], Step [105/350], Avg Loss: 1.9513, Avg Dice: 0.2545\n",
            "Epoch [1/50], Step [110/350], Avg Loss: 1.9386, Avg Dice: 0.2564\n",
            "Epoch [1/50], Step [115/350], Avg Loss: 1.9216, Avg Dice: 0.2609\n",
            "Epoch [1/50], Step [120/350], Avg Loss: 1.9076, Avg Dice: 0.2648\n",
            "Epoch [1/50], Step [125/350], Avg Loss: 1.8980, Avg Dice: 0.2671\n",
            "Epoch [1/50], Step [130/350], Avg Loss: 1.8828, Avg Dice: 0.2689\n",
            "Epoch [1/50], Step [135/350], Avg Loss: 1.8680, Avg Dice: 0.2705\n",
            "Epoch [1/50], Step [140/350], Avg Loss: 1.8558, Avg Dice: 0.2724\n",
            "Epoch [1/50], Step [145/350], Avg Loss: 1.8429, Avg Dice: 0.2741\n",
            "Epoch [1/50], Step [150/350], Avg Loss: 1.8280, Avg Dice: 0.2746\n",
            "Epoch [1/50], Step [155/350], Avg Loss: 1.8162, Avg Dice: 0.2755\n",
            "Epoch [1/50], Step [160/350], Avg Loss: 1.8015, Avg Dice: 0.2761\n",
            "Epoch [1/50], Step [165/350], Avg Loss: 1.7931, Avg Dice: 0.2766\n",
            "Epoch [1/50], Step [170/350], Avg Loss: 1.7825, Avg Dice: 0.2779\n",
            "Epoch [1/50], Step [175/350], Avg Loss: 1.7734, Avg Dice: 0.2792\n",
            "Epoch [1/50], Step [180/350], Avg Loss: 1.7620, Avg Dice: 0.2817\n",
            "Epoch [1/50], Step [185/350], Avg Loss: 1.7528, Avg Dice: 0.2828\n",
            "Epoch [1/50], Step [190/350], Avg Loss: 1.7439, Avg Dice: 0.2839\n",
            "Epoch [1/50], Step [195/350], Avg Loss: 1.7354, Avg Dice: 0.2846\n",
            "Epoch [1/50], Step [200/350], Avg Loss: 1.7271, Avg Dice: 0.2851\n",
            "Epoch [1/50], Step [205/350], Avg Loss: 1.7204, Avg Dice: 0.2860\n",
            "Epoch [1/50], Step [210/350], Avg Loss: 1.7104, Avg Dice: 0.2868\n",
            "Epoch [1/50], Step [215/350], Avg Loss: 1.7021, Avg Dice: 0.2883\n",
            "Epoch [1/50], Step [220/350], Avg Loss: 1.6936, Avg Dice: 0.2895\n",
            "Epoch [1/50], Step [225/350], Avg Loss: 1.6859, Avg Dice: 0.2900\n",
            "Epoch [1/50], Step [230/350], Avg Loss: 1.6789, Avg Dice: 0.2911\n",
            "Epoch [1/50], Step [235/350], Avg Loss: 1.6723, Avg Dice: 0.2918\n",
            "Epoch [1/50], Step [240/350], Avg Loss: 1.6645, Avg Dice: 0.2929\n",
            "Epoch [1/50], Step [245/350], Avg Loss: 1.6576, Avg Dice: 0.2937\n",
            "Epoch [1/50], Step [250/350], Avg Loss: 1.6529, Avg Dice: 0.2944\n",
            "Epoch [1/50], Step [255/350], Avg Loss: 1.6455, Avg Dice: 0.2952\n",
            "Epoch [1/50], Step [260/350], Avg Loss: 1.6393, Avg Dice: 0.2952\n",
            "Epoch [1/50], Step [265/350], Avg Loss: 1.6345, Avg Dice: 0.2959\n",
            "Epoch [1/50], Step [270/350], Avg Loss: 1.6271, Avg Dice: 0.2976\n",
            "Epoch [1/50], Step [275/350], Avg Loss: 1.6213, Avg Dice: 0.2983\n",
            "Epoch [1/50], Step [280/350], Avg Loss: 1.6151, Avg Dice: 0.2987\n",
            "Epoch [1/50], Step [285/350], Avg Loss: 1.6103, Avg Dice: 0.2991\n",
            "Epoch [1/50], Step [290/350], Avg Loss: 1.6057, Avg Dice: 0.2994\n",
            "Epoch [1/50], Step [295/350], Avg Loss: 1.6004, Avg Dice: 0.3001\n",
            "Epoch [1/50], Step [300/350], Avg Loss: 1.5944, Avg Dice: 0.3003\n",
            "Epoch [1/50], Step [305/350], Avg Loss: 1.5901, Avg Dice: 0.3007\n",
            "Epoch [1/50], Step [310/350], Avg Loss: 1.5856, Avg Dice: 0.3015\n",
            "Epoch [1/50], Step [315/350], Avg Loss: 1.5815, Avg Dice: 0.3023\n",
            "Epoch [1/50], Step [320/350], Avg Loss: 1.5773, Avg Dice: 0.3031\n",
            "Epoch [1/50], Step [325/350], Avg Loss: 1.5727, Avg Dice: 0.3036\n",
            "Epoch [1/50], Step [330/350], Avg Loss: 1.5691, Avg Dice: 0.3036\n",
            "Epoch [1/50], Step [335/350], Avg Loss: 1.5633, Avg Dice: 0.3044\n",
            "Epoch [1/50], Step [340/350], Avg Loss: 1.5589, Avg Dice: 0.3050\n",
            "Epoch [1/50], Step [345/350], Avg Loss: 1.5551, Avg Dice: 0.3052\n",
            "Epoch [1/50], Step [350/350], Avg Loss: 1.5497, Avg Dice: 0.3055\n",
            "End of epoch 1: Avg Loss: 1.5497, Avg Dice: 0.3055\n",
            "Epoch [2/50], Step [5/350], Avg Loss: 1.3231, Avg Dice: 0.3541\n",
            "Epoch [2/50], Step [10/350], Avg Loss: 1.2839, Avg Dice: 0.3361\n",
            "Epoch [2/50], Step [15/350], Avg Loss: 1.2620, Avg Dice: 0.3437\n",
            "Epoch [2/50], Step [20/350], Avg Loss: 1.2483, Avg Dice: 0.3450\n",
            "Epoch [2/50], Step [25/350], Avg Loss: 1.2438, Avg Dice: 0.3457\n",
            "Epoch [2/50], Step [30/350], Avg Loss: 1.2437, Avg Dice: 0.3405\n",
            "Epoch [2/50], Step [35/350], Avg Loss: 1.2337, Avg Dice: 0.3464\n",
            "Epoch [2/50], Step [40/350], Avg Loss: 1.2249, Avg Dice: 0.3495\n",
            "Epoch [2/50], Step [45/350], Avg Loss: 1.2200, Avg Dice: 0.3476\n",
            "Epoch [2/50], Step [50/350], Avg Loss: 1.2247, Avg Dice: 0.3468\n",
            "Epoch [2/50], Step [55/350], Avg Loss: 1.2155, Avg Dice: 0.3500\n",
            "Epoch [2/50], Step [60/350], Avg Loss: 1.2192, Avg Dice: 0.3474\n",
            "Epoch [2/50], Step [65/350], Avg Loss: 1.2159, Avg Dice: 0.3488\n",
            "Epoch [2/50], Step [70/350], Avg Loss: 1.2194, Avg Dice: 0.3465\n",
            "Epoch [2/50], Step [75/350], Avg Loss: 1.2136, Avg Dice: 0.3481\n",
            "Epoch [2/50], Step [80/350], Avg Loss: 1.2089, Avg Dice: 0.3478\n",
            "Epoch [2/50], Step [85/350], Avg Loss: 1.2065, Avg Dice: 0.3487\n",
            "Epoch [2/50], Step [90/350], Avg Loss: 1.2011, Avg Dice: 0.3466\n",
            "Epoch [2/50], Step [95/350], Avg Loss: 1.2055, Avg Dice: 0.3445\n",
            "Epoch [2/50], Step [100/350], Avg Loss: 1.2081, Avg Dice: 0.3442\n",
            "Epoch [2/50], Step [105/350], Avg Loss: 1.2074, Avg Dice: 0.3432\n",
            "Epoch [2/50], Step [110/350], Avg Loss: 1.2059, Avg Dice: 0.3445\n",
            "Epoch [2/50], Step [115/350], Avg Loss: 1.2015, Avg Dice: 0.3458\n",
            "Epoch [2/50], Step [120/350], Avg Loss: 1.2003, Avg Dice: 0.3465\n",
            "Epoch [2/50], Step [125/350], Avg Loss: 1.1996, Avg Dice: 0.3466\n",
            "Epoch [2/50], Step [130/350], Avg Loss: 1.1960, Avg Dice: 0.3472\n",
            "Epoch [2/50], Step [135/350], Avg Loss: 1.1955, Avg Dice: 0.3483\n",
            "Epoch [2/50], Step [140/350], Avg Loss: 1.1964, Avg Dice: 0.3491\n",
            "Epoch [2/50], Step [145/350], Avg Loss: 1.1955, Avg Dice: 0.3478\n",
            "Epoch [2/50], Step [150/350], Avg Loss: 1.1950, Avg Dice: 0.3485\n",
            "Epoch [2/50], Step [155/350], Avg Loss: 1.1968, Avg Dice: 0.3472\n",
            "Epoch [2/50], Step [160/350], Avg Loss: 1.1970, Avg Dice: 0.3470\n",
            "Epoch [2/50], Step [165/350], Avg Loss: 1.1975, Avg Dice: 0.3468\n",
            "Epoch [2/50], Step [170/350], Avg Loss: 1.1960, Avg Dice: 0.3468\n",
            "Epoch [2/50], Step [175/350], Avg Loss: 1.1961, Avg Dice: 0.3475\n",
            "Epoch [2/50], Step [180/350], Avg Loss: 1.1951, Avg Dice: 0.3479\n",
            "Epoch [2/50], Step [185/350], Avg Loss: 1.1931, Avg Dice: 0.3484\n",
            "Epoch [2/50], Step [190/350], Avg Loss: 1.1939, Avg Dice: 0.3492\n",
            "Epoch [2/50], Step [195/350], Avg Loss: 1.1929, Avg Dice: 0.3492\n",
            "Epoch [2/50], Step [200/350], Avg Loss: 1.1919, Avg Dice: 0.3481\n",
            "Epoch [2/50], Step [205/350], Avg Loss: 1.1892, Avg Dice: 0.3472\n",
            "Epoch [2/50], Step [210/350], Avg Loss: 1.1879, Avg Dice: 0.3460\n",
            "Epoch [2/50], Step [215/350], Avg Loss: 1.1886, Avg Dice: 0.3460\n",
            "Epoch [2/50], Step [220/350], Avg Loss: 1.1884, Avg Dice: 0.3455\n",
            "Epoch [2/50], Step [225/350], Avg Loss: 1.1864, Avg Dice: 0.3451\n",
            "Epoch [2/50], Step [230/350], Avg Loss: 1.1880, Avg Dice: 0.3453\n",
            "Epoch [2/50], Step [235/350], Avg Loss: 1.1858, Avg Dice: 0.3451\n",
            "Epoch [2/50], Step [240/350], Avg Loss: 1.1853, Avg Dice: 0.3443\n",
            "Epoch [2/50], Step [245/350], Avg Loss: 1.1834, Avg Dice: 0.3442\n",
            "Epoch [2/50], Step [250/350], Avg Loss: 1.1835, Avg Dice: 0.3443\n",
            "Epoch [2/50], Step [255/350], Avg Loss: 1.1828, Avg Dice: 0.3444\n",
            "Epoch [2/50], Step [260/350], Avg Loss: 1.1815, Avg Dice: 0.3447\n",
            "Epoch [2/50], Step [265/350], Avg Loss: 1.1797, Avg Dice: 0.3450\n",
            "Epoch [2/50], Step [270/350], Avg Loss: 1.1782, Avg Dice: 0.3455\n",
            "Epoch [2/50], Step [275/350], Avg Loss: 1.1769, Avg Dice: 0.3461\n",
            "Epoch [2/50], Step [280/350], Avg Loss: 1.1746, Avg Dice: 0.3460\n",
            "Epoch [2/50], Step [285/350], Avg Loss: 1.1727, Avg Dice: 0.3454\n",
            "Epoch [2/50], Step [290/350], Avg Loss: 1.1710, Avg Dice: 0.3459\n",
            "Epoch [2/50], Step [295/350], Avg Loss: 1.1698, Avg Dice: 0.3457\n",
            "Epoch [2/50], Step [300/350], Avg Loss: 1.1674, Avg Dice: 0.3457\n",
            "Epoch [2/50], Step [305/350], Avg Loss: 1.1659, Avg Dice: 0.3455\n",
            "Epoch [2/50], Step [310/350], Avg Loss: 1.1646, Avg Dice: 0.3455\n",
            "Epoch [2/50], Step [315/350], Avg Loss: 1.1621, Avg Dice: 0.3451\n",
            "Epoch [2/50], Step [320/350], Avg Loss: 1.1592, Avg Dice: 0.3461\n",
            "Epoch [2/50], Step [325/350], Avg Loss: 1.1591, Avg Dice: 0.3458\n",
            "Epoch [2/50], Step [330/350], Avg Loss: 1.1590, Avg Dice: 0.3461\n",
            "Epoch [2/50], Step [335/350], Avg Loss: 1.1590, Avg Dice: 0.3464\n",
            "Epoch [2/50], Step [340/350], Avg Loss: 1.1592, Avg Dice: 0.3458\n",
            "Epoch [2/50], Step [345/350], Avg Loss: 1.1593, Avg Dice: 0.3461\n",
            "Epoch [2/50], Step [350/350], Avg Loss: 1.1590, Avg Dice: 0.3459\n",
            "End of epoch 2: Avg Loss: 1.1590, Avg Dice: 0.3459\n",
            "Epoch [3/50], Step [5/350], Avg Loss: 1.1347, Avg Dice: 0.3084\n",
            "Epoch [3/50], Step [10/350], Avg Loss: 1.1239, Avg Dice: 0.3370\n",
            "Epoch [3/50], Step [15/350], Avg Loss: 1.1070, Avg Dice: 0.3495\n",
            "Epoch [3/50], Step [20/350], Avg Loss: 1.0919, Avg Dice: 0.3482\n",
            "Epoch [3/50], Step [25/350], Avg Loss: 1.0966, Avg Dice: 0.3534\n",
            "Epoch [3/50], Step [30/350], Avg Loss: 1.0902, Avg Dice: 0.3598\n",
            "Epoch [3/50], Step [35/350], Avg Loss: 1.0763, Avg Dice: 0.3626\n",
            "Epoch [3/50], Step [40/350], Avg Loss: 1.0825, Avg Dice: 0.3581\n",
            "Epoch [3/50], Step [45/350], Avg Loss: 1.0731, Avg Dice: 0.3567\n",
            "Epoch [3/50], Step [50/350], Avg Loss: 1.0729, Avg Dice: 0.3566\n",
            "Epoch [3/50], Step [55/350], Avg Loss: 1.0675, Avg Dice: 0.3551\n",
            "Epoch [3/50], Step [60/350], Avg Loss: 1.0732, Avg Dice: 0.3577\n",
            "Epoch [3/50], Step [65/350], Avg Loss: 1.0769, Avg Dice: 0.3564\n",
            "Epoch [3/50], Step [70/350], Avg Loss: 1.0799, Avg Dice: 0.3565\n",
            "Epoch [3/50], Step [75/350], Avg Loss: 1.0727, Avg Dice: 0.3586\n",
            "Epoch [3/50], Step [80/350], Avg Loss: 1.0723, Avg Dice: 0.3577\n",
            "Epoch [3/50], Step [85/350], Avg Loss: 1.0788, Avg Dice: 0.3600\n",
            "Epoch [3/50], Step [90/350], Avg Loss: 1.0813, Avg Dice: 0.3619\n",
            "Epoch [3/50], Step [95/350], Avg Loss: 1.0841, Avg Dice: 0.3616\n",
            "Epoch [3/50], Step [100/350], Avg Loss: 1.0837, Avg Dice: 0.3621\n",
            "Epoch [3/50], Step [105/350], Avg Loss: 1.0873, Avg Dice: 0.3612\n",
            "Epoch [3/50], Step [110/350], Avg Loss: 1.0894, Avg Dice: 0.3602\n",
            "Epoch [3/50], Step [115/350], Avg Loss: 1.0893, Avg Dice: 0.3617\n",
            "Epoch [3/50], Step [120/350], Avg Loss: 1.0898, Avg Dice: 0.3626\n",
            "Epoch [3/50], Step [125/350], Avg Loss: 1.0901, Avg Dice: 0.3607\n",
            "Epoch [3/50], Step [130/350], Avg Loss: 1.0888, Avg Dice: 0.3595\n",
            "Epoch [3/50], Step [135/350], Avg Loss: 1.0888, Avg Dice: 0.3578\n",
            "Epoch [3/50], Step [140/350], Avg Loss: 1.0890, Avg Dice: 0.3576\n",
            "Epoch [3/50], Step [145/350], Avg Loss: 1.0879, Avg Dice: 0.3574\n",
            "Epoch [3/50], Step [150/350], Avg Loss: 1.0872, Avg Dice: 0.3568\n",
            "Epoch [3/50], Step [155/350], Avg Loss: 1.0889, Avg Dice: 0.3565\n",
            "Epoch [3/50], Step [160/350], Avg Loss: 1.0869, Avg Dice: 0.3557\n",
            "Epoch [3/50], Step [165/350], Avg Loss: 1.0879, Avg Dice: 0.3552\n",
            "Epoch [3/50], Step [170/350], Avg Loss: 1.0872, Avg Dice: 0.3547\n",
            "Epoch [3/50], Step [175/350], Avg Loss: 1.0863, Avg Dice: 0.3555\n",
            "Epoch [3/50], Step [180/350], Avg Loss: 1.0865, Avg Dice: 0.3556\n",
            "Epoch [3/50], Step [185/350], Avg Loss: 1.0865, Avg Dice: 0.3552\n",
            "Epoch [3/50], Step [190/350], Avg Loss: 1.0857, Avg Dice: 0.3554\n",
            "Epoch [3/50], Step [195/350], Avg Loss: 1.0846, Avg Dice: 0.3566\n",
            "Epoch [3/50], Step [200/350], Avg Loss: 1.0858, Avg Dice: 0.3569\n",
            "Epoch [3/50], Step [205/350], Avg Loss: 1.0857, Avg Dice: 0.3576\n",
            "Epoch [3/50], Step [210/350], Avg Loss: 1.0861, Avg Dice: 0.3571\n",
            "Epoch [3/50], Step [215/350], Avg Loss: 1.0848, Avg Dice: 0.3572\n",
            "Epoch [3/50], Step [220/350], Avg Loss: 1.0824, Avg Dice: 0.3580\n",
            "Epoch [3/50], Step [225/350], Avg Loss: 1.0821, Avg Dice: 0.3575\n",
            "Epoch [3/50], Step [230/350], Avg Loss: 1.0822, Avg Dice: 0.3579\n",
            "Epoch [3/50], Step [235/350], Avg Loss: 1.0808, Avg Dice: 0.3582\n",
            "Epoch [3/50], Step [240/350], Avg Loss: 1.0789, Avg Dice: 0.3586\n",
            "Epoch [3/50], Step [245/350], Avg Loss: 1.0804, Avg Dice: 0.3592\n",
            "Epoch [3/50], Step [250/350], Avg Loss: 1.0802, Avg Dice: 0.3592\n",
            "Epoch [3/50], Step [255/350], Avg Loss: 1.0790, Avg Dice: 0.3593\n",
            "Epoch [3/50], Step [260/350], Avg Loss: 1.0786, Avg Dice: 0.3592\n",
            "Epoch [3/50], Step [265/350], Avg Loss: 1.0774, Avg Dice: 0.3591\n",
            "Epoch [3/50], Step [270/350], Avg Loss: 1.0781, Avg Dice: 0.3589\n",
            "Epoch [3/50], Step [275/350], Avg Loss: 1.0762, Avg Dice: 0.3591\n",
            "Epoch [3/50], Step [280/350], Avg Loss: 1.0765, Avg Dice: 0.3589\n",
            "Epoch [3/50], Step [285/350], Avg Loss: 1.0765, Avg Dice: 0.3583\n",
            "Epoch [3/50], Step [290/350], Avg Loss: 1.0762, Avg Dice: 0.3583\n",
            "Epoch [3/50], Step [295/350], Avg Loss: 1.0757, Avg Dice: 0.3577\n",
            "Epoch [3/50], Step [300/350], Avg Loss: 1.0753, Avg Dice: 0.3583\n",
            "Epoch [3/50], Step [305/350], Avg Loss: 1.0744, Avg Dice: 0.3588\n",
            "Epoch [3/50], Step [310/350], Avg Loss: 1.0743, Avg Dice: 0.3583\n",
            "Epoch [3/50], Step [315/350], Avg Loss: 1.0734, Avg Dice: 0.3579\n",
            "Epoch [3/50], Step [320/350], Avg Loss: 1.0727, Avg Dice: 0.3581\n",
            "Epoch [3/50], Step [325/350], Avg Loss: 1.0723, Avg Dice: 0.3585\n",
            "Epoch [3/50], Step [330/350], Avg Loss: 1.0713, Avg Dice: 0.3587\n",
            "Epoch [3/50], Step [335/350], Avg Loss: 1.0708, Avg Dice: 0.3594\n",
            "Epoch [3/50], Step [340/350], Avg Loss: 1.0691, Avg Dice: 0.3590\n",
            "Epoch [3/50], Step [345/350], Avg Loss: 1.0682, Avg Dice: 0.3589\n",
            "Epoch [3/50], Step [350/350], Avg Loss: 1.0682, Avg Dice: 0.3583\n",
            "End of epoch 3: Avg Loss: 1.0682, Avg Dice: 0.3583\n",
            "Epoch [4/50], Step [5/350], Avg Loss: 0.9808, Avg Dice: 0.3544\n",
            "Epoch [4/50], Step [10/350], Avg Loss: 1.0146, Avg Dice: 0.3599\n",
            "Epoch [4/50], Step [15/350], Avg Loss: 0.9902, Avg Dice: 0.3629\n",
            "Epoch [4/50], Step [20/350], Avg Loss: 1.0088, Avg Dice: 0.3582\n",
            "Epoch [4/50], Step [25/350], Avg Loss: 1.0015, Avg Dice: 0.3670\n",
            "Epoch [4/50], Step [30/350], Avg Loss: 1.0061, Avg Dice: 0.3603\n",
            "Epoch [4/50], Step [35/350], Avg Loss: 1.0051, Avg Dice: 0.3651\n",
            "Epoch [4/50], Step [40/350], Avg Loss: 1.0057, Avg Dice: 0.3656\n",
            "Epoch [4/50], Step [45/350], Avg Loss: 1.0044, Avg Dice: 0.3626\n",
            "Epoch [4/50], Step [50/350], Avg Loss: 1.0006, Avg Dice: 0.3614\n",
            "Epoch [4/50], Step [55/350], Avg Loss: 1.0031, Avg Dice: 0.3640\n",
            "Epoch [4/50], Step [60/350], Avg Loss: 1.0026, Avg Dice: 0.3609\n",
            "Epoch [4/50], Step [65/350], Avg Loss: 1.0060, Avg Dice: 0.3625\n",
            "Epoch [4/50], Step [70/350], Avg Loss: 1.0075, Avg Dice: 0.3615\n",
            "Epoch [4/50], Step [75/350], Avg Loss: 1.0067, Avg Dice: 0.3650\n",
            "Epoch [4/50], Step [80/350], Avg Loss: 1.0060, Avg Dice: 0.3673\n",
            "Epoch [4/50], Step [85/350], Avg Loss: 1.0080, Avg Dice: 0.3687\n",
            "Epoch [4/50], Step [90/350], Avg Loss: 1.0150, Avg Dice: 0.3661\n",
            "Epoch [4/50], Step [95/350], Avg Loss: 1.0124, Avg Dice: 0.3658\n",
            "Epoch [4/50], Step [100/350], Avg Loss: 1.0124, Avg Dice: 0.3642\n",
            "Epoch [4/50], Step [105/350], Avg Loss: 1.0129, Avg Dice: 0.3620\n",
            "Epoch [4/50], Step [110/350], Avg Loss: 1.0144, Avg Dice: 0.3611\n",
            "Epoch [4/50], Step [115/350], Avg Loss: 1.0107, Avg Dice: 0.3607\n",
            "Epoch [4/50], Step [120/350], Avg Loss: 1.0130, Avg Dice: 0.3603\n",
            "Epoch [4/50], Step [125/350], Avg Loss: 1.0158, Avg Dice: 0.3607\n",
            "Epoch [4/50], Step [130/350], Avg Loss: 1.0171, Avg Dice: 0.3620\n",
            "Epoch [4/50], Step [135/350], Avg Loss: 1.0153, Avg Dice: 0.3636\n",
            "Epoch [4/50], Step [140/350], Avg Loss: 1.0155, Avg Dice: 0.3644\n",
            "Epoch [4/50], Step [145/350], Avg Loss: 1.0173, Avg Dice: 0.3646\n",
            "Epoch [4/50], Step [150/350], Avg Loss: 1.0196, Avg Dice: 0.3636\n",
            "Epoch [4/50], Step [155/350], Avg Loss: 1.0178, Avg Dice: 0.3634\n",
            "Epoch [4/50], Step [160/350], Avg Loss: 1.0165, Avg Dice: 0.3642\n",
            "Epoch [4/50], Step [165/350], Avg Loss: 1.0151, Avg Dice: 0.3648\n",
            "Epoch [4/50], Step [170/350], Avg Loss: 1.0143, Avg Dice: 0.3647\n",
            "Epoch [4/50], Step [175/350], Avg Loss: 1.0142, Avg Dice: 0.3650\n",
            "Epoch [4/50], Step [180/350], Avg Loss: 1.0118, Avg Dice: 0.3658\n",
            "Epoch [4/50], Step [185/350], Avg Loss: 1.0114, Avg Dice: 0.3658\n",
            "Epoch [4/50], Step [190/350], Avg Loss: 1.0133, Avg Dice: 0.3668\n",
            "Epoch [4/50], Step [195/350], Avg Loss: 1.0140, Avg Dice: 0.3668\n",
            "Epoch [4/50], Step [200/350], Avg Loss: 1.0163, Avg Dice: 0.3669\n",
            "Epoch [4/50], Step [205/350], Avg Loss: 1.0155, Avg Dice: 0.3674\n",
            "Epoch [4/50], Step [210/350], Avg Loss: 1.0149, Avg Dice: 0.3668\n",
            "Epoch [4/50], Step [215/350], Avg Loss: 1.0158, Avg Dice: 0.3669\n",
            "Epoch [4/50], Step [220/350], Avg Loss: 1.0171, Avg Dice: 0.3676\n",
            "Epoch [4/50], Step [225/350], Avg Loss: 1.0183, Avg Dice: 0.3676\n",
            "Epoch [4/50], Step [230/350], Avg Loss: 1.0201, Avg Dice: 0.3677\n",
            "Epoch [4/50], Step [235/350], Avg Loss: 1.0200, Avg Dice: 0.3682\n",
            "Epoch [4/50], Step [240/350], Avg Loss: 1.0215, Avg Dice: 0.3685\n",
            "Epoch [4/50], Step [245/350], Avg Loss: 1.0197, Avg Dice: 0.3689\n",
            "Epoch [4/50], Step [250/350], Avg Loss: 1.0173, Avg Dice: 0.3694\n",
            "Epoch [4/50], Step [255/350], Avg Loss: 1.0164, Avg Dice: 0.3689\n",
            "Epoch [4/50], Step [260/350], Avg Loss: 1.0151, Avg Dice: 0.3687\n",
            "Epoch [4/50], Step [265/350], Avg Loss: 1.0132, Avg Dice: 0.3680\n",
            "Epoch [4/50], Step [270/350], Avg Loss: 1.0129, Avg Dice: 0.3681\n",
            "Epoch [4/50], Step [275/350], Avg Loss: 1.0139, Avg Dice: 0.3678\n",
            "Epoch [4/50], Step [280/350], Avg Loss: 1.0139, Avg Dice: 0.3682\n",
            "Epoch [4/50], Step [285/350], Avg Loss: 1.0157, Avg Dice: 0.3683\n",
            "Epoch [4/50], Step [290/350], Avg Loss: 1.0175, Avg Dice: 0.3680\n",
            "Epoch [4/50], Step [295/350], Avg Loss: 1.0173, Avg Dice: 0.3680\n",
            "Epoch [4/50], Step [300/350], Avg Loss: 1.0167, Avg Dice: 0.3678\n",
            "Epoch [4/50], Step [305/350], Avg Loss: 1.0168, Avg Dice: 0.3673\n",
            "Epoch [4/50], Step [310/350], Avg Loss: 1.0183, Avg Dice: 0.3675\n",
            "Epoch [4/50], Step [315/350], Avg Loss: 1.0185, Avg Dice: 0.3678\n",
            "Epoch [4/50], Step [320/350], Avg Loss: 1.0186, Avg Dice: 0.3686\n",
            "Epoch [4/50], Step [325/350], Avg Loss: 1.0189, Avg Dice: 0.3679\n",
            "Epoch [4/50], Step [330/350], Avg Loss: 1.0194, Avg Dice: 0.3685\n",
            "Epoch [4/50], Step [335/350], Avg Loss: 1.0197, Avg Dice: 0.3683\n",
            "Epoch [4/50], Step [340/350], Avg Loss: 1.0191, Avg Dice: 0.3681\n",
            "Epoch [4/50], Step [345/350], Avg Loss: 1.0195, Avg Dice: 0.3677\n",
            "Epoch [4/50], Step [350/350], Avg Loss: 1.0191, Avg Dice: 0.3675\n",
            "End of epoch 4: Avg Loss: 1.0191, Avg Dice: 0.3675\n",
            "Epoch [5/50], Step [5/350], Avg Loss: 0.9188, Avg Dice: 0.3183\n",
            "Epoch [5/50], Step [10/350], Avg Loss: 0.9442, Avg Dice: 0.3550\n",
            "Epoch [5/50], Step [15/350], Avg Loss: 0.9622, Avg Dice: 0.3611\n",
            "Epoch [5/50], Step [20/350], Avg Loss: 0.9618, Avg Dice: 0.3644\n",
            "Epoch [5/50], Step [25/350], Avg Loss: 0.9598, Avg Dice: 0.3714\n",
            "Epoch [5/50], Step [30/350], Avg Loss: 0.9736, Avg Dice: 0.3746\n",
            "Epoch [5/50], Step [35/350], Avg Loss: 0.9842, Avg Dice: 0.3761\n",
            "Epoch [5/50], Step [40/350], Avg Loss: 0.9770, Avg Dice: 0.3806\n",
            "Epoch [5/50], Step [45/350], Avg Loss: 0.9886, Avg Dice: 0.3782\n",
            "Epoch [5/50], Step [50/350], Avg Loss: 0.9919, Avg Dice: 0.3748\n",
            "Epoch [5/50], Step [55/350], Avg Loss: 0.9847, Avg Dice: 0.3792\n",
            "Epoch [5/50], Step [60/350], Avg Loss: 0.9820, Avg Dice: 0.3803\n",
            "Epoch [5/50], Step [65/350], Avg Loss: 0.9883, Avg Dice: 0.3767\n",
            "Epoch [5/50], Step [70/350], Avg Loss: 0.9870, Avg Dice: 0.3784\n",
            "Epoch [5/50], Step [75/350], Avg Loss: 0.9947, Avg Dice: 0.3758\n",
            "Epoch [5/50], Step [80/350], Avg Loss: 0.9871, Avg Dice: 0.3781\n",
            "Epoch [5/50], Step [85/350], Avg Loss: 0.9921, Avg Dice: 0.3773\n",
            "Epoch [5/50], Step [90/350], Avg Loss: 1.0003, Avg Dice: 0.3747\n",
            "Epoch [5/50], Step [95/350], Avg Loss: 0.9986, Avg Dice: 0.3739\n",
            "Epoch [5/50], Step [100/350], Avg Loss: 0.9949, Avg Dice: 0.3764\n",
            "Epoch [5/50], Step [105/350], Avg Loss: 0.9985, Avg Dice: 0.3755\n",
            "Epoch [5/50], Step [110/350], Avg Loss: 0.9970, Avg Dice: 0.3746\n",
            "Epoch [5/50], Step [115/350], Avg Loss: 0.9962, Avg Dice: 0.3776\n",
            "Epoch [5/50], Step [120/350], Avg Loss: 0.9955, Avg Dice: 0.3777\n",
            "Epoch [5/50], Step [125/350], Avg Loss: 0.9949, Avg Dice: 0.3782\n",
            "Epoch [5/50], Step [130/350], Avg Loss: 0.9935, Avg Dice: 0.3785\n",
            "Epoch [5/50], Step [135/350], Avg Loss: 0.9906, Avg Dice: 0.3781\n",
            "Epoch [5/50], Step [140/350], Avg Loss: 0.9926, Avg Dice: 0.3776\n",
            "Epoch [5/50], Step [145/350], Avg Loss: 0.9922, Avg Dice: 0.3779\n",
            "Epoch [5/50], Step [150/350], Avg Loss: 0.9921, Avg Dice: 0.3760\n",
            "Epoch [5/50], Step [155/350], Avg Loss: 0.9943, Avg Dice: 0.3768\n",
            "Epoch [5/50], Step [160/350], Avg Loss: 0.9952, Avg Dice: 0.3767\n",
            "Epoch [5/50], Step [165/350], Avg Loss: 0.9948, Avg Dice: 0.3771\n",
            "Epoch [5/50], Step [170/350], Avg Loss: 0.9921, Avg Dice: 0.3772\n",
            "Epoch [5/50], Step [175/350], Avg Loss: 0.9917, Avg Dice: 0.3775\n",
            "Epoch [5/50], Step [180/350], Avg Loss: 0.9896, Avg Dice: 0.3782\n",
            "Epoch [5/50], Step [185/350], Avg Loss: 0.9888, Avg Dice: 0.3782\n",
            "Epoch [5/50], Step [190/350], Avg Loss: 0.9894, Avg Dice: 0.3779\n",
            "Epoch [5/50], Step [195/350], Avg Loss: 0.9913, Avg Dice: 0.3768\n",
            "Epoch [5/50], Step [200/350], Avg Loss: 0.9908, Avg Dice: 0.3766\n",
            "Epoch [5/50], Step [205/350], Avg Loss: 0.9904, Avg Dice: 0.3773\n",
            "Epoch [5/50], Step [210/350], Avg Loss: 0.9918, Avg Dice: 0.3767\n",
            "Epoch [5/50], Step [215/350], Avg Loss: 0.9902, Avg Dice: 0.3785\n",
            "Epoch [5/50], Step [220/350], Avg Loss: 0.9926, Avg Dice: 0.3769\n",
            "Epoch [5/50], Step [225/350], Avg Loss: 0.9923, Avg Dice: 0.3767\n",
            "Epoch [5/50], Step [230/350], Avg Loss: 0.9914, Avg Dice: 0.3770\n",
            "Epoch [5/50], Step [235/350], Avg Loss: 0.9915, Avg Dice: 0.3771\n",
            "Epoch [5/50], Step [240/350], Avg Loss: 0.9892, Avg Dice: 0.3775\n",
            "Epoch [5/50], Step [245/350], Avg Loss: 0.9885, Avg Dice: 0.3777\n",
            "Epoch [5/50], Step [250/350], Avg Loss: 0.9870, Avg Dice: 0.3767\n",
            "Epoch [5/50], Step [255/350], Avg Loss: 0.9864, Avg Dice: 0.3759\n",
            "Epoch [5/50], Step [260/350], Avg Loss: 0.9877, Avg Dice: 0.3756\n",
            "Epoch [5/50], Step [265/350], Avg Loss: 0.9884, Avg Dice: 0.3754\n",
            "Epoch [5/50], Step [270/350], Avg Loss: 0.9875, Avg Dice: 0.3760\n",
            "Epoch [5/50], Step [275/350], Avg Loss: 0.9874, Avg Dice: 0.3762\n",
            "Epoch [5/50], Step [280/350], Avg Loss: 0.9874, Avg Dice: 0.3758\n",
            "Epoch [5/50], Step [285/350], Avg Loss: 0.9874, Avg Dice: 0.3758\n",
            "Epoch [5/50], Step [290/350], Avg Loss: 0.9859, Avg Dice: 0.3758\n",
            "Epoch [5/50], Step [295/350], Avg Loss: 0.9853, Avg Dice: 0.3756\n",
            "Epoch [5/50], Step [300/350], Avg Loss: 0.9855, Avg Dice: 0.3755\n",
            "Epoch [5/50], Step [305/350], Avg Loss: 0.9857, Avg Dice: 0.3757\n",
            "Epoch [5/50], Step [310/350], Avg Loss: 0.9850, Avg Dice: 0.3757\n",
            "Epoch [5/50], Step [315/350], Avg Loss: 0.9865, Avg Dice: 0.3751\n",
            "Epoch [5/50], Step [320/350], Avg Loss: 0.9861, Avg Dice: 0.3744\n",
            "Epoch [5/50], Step [325/350], Avg Loss: 0.9855, Avg Dice: 0.3741\n",
            "Epoch [5/50], Step [330/350], Avg Loss: 0.9863, Avg Dice: 0.3739\n",
            "Epoch [5/50], Step [335/350], Avg Loss: 0.9860, Avg Dice: 0.3741\n",
            "Epoch [5/50], Step [340/350], Avg Loss: 0.9864, Avg Dice: 0.3738\n",
            "Epoch [5/50], Step [345/350], Avg Loss: 0.9857, Avg Dice: 0.3742\n",
            "Epoch [5/50], Step [350/350], Avg Loss: 0.9851, Avg Dice: 0.3745\n",
            "End of epoch 5: Avg Loss: 0.9851, Avg Dice: 0.3745\n",
            "Epoch [6/50], Step [5/350], Avg Loss: 0.8973, Avg Dice: 0.3779\n",
            "Epoch [6/50], Step [10/350], Avg Loss: 0.9150, Avg Dice: 0.3684\n",
            "Epoch [6/50], Step [15/350], Avg Loss: 0.9406, Avg Dice: 0.3651\n",
            "Epoch [6/50], Step [20/350], Avg Loss: 0.9540, Avg Dice: 0.3658\n",
            "Epoch [6/50], Step [25/350], Avg Loss: 0.9514, Avg Dice: 0.3761\n",
            "Epoch [6/50], Step [30/350], Avg Loss: 0.9612, Avg Dice: 0.3752\n",
            "Epoch [6/50], Step [35/350], Avg Loss: 0.9624, Avg Dice: 0.3741\n",
            "Epoch [6/50], Step [40/350], Avg Loss: 0.9598, Avg Dice: 0.3738\n",
            "Epoch [6/50], Step [45/350], Avg Loss: 0.9605, Avg Dice: 0.3727\n",
            "Epoch [6/50], Step [50/350], Avg Loss: 0.9496, Avg Dice: 0.3764\n",
            "Epoch [6/50], Step [55/350], Avg Loss: 0.9491, Avg Dice: 0.3759\n",
            "Epoch [6/50], Step [60/350], Avg Loss: 0.9524, Avg Dice: 0.3765\n",
            "Epoch [6/50], Step [65/350], Avg Loss: 0.9527, Avg Dice: 0.3788\n",
            "Epoch [6/50], Step [70/350], Avg Loss: 0.9581, Avg Dice: 0.3773\n",
            "Epoch [6/50], Step [75/350], Avg Loss: 0.9593, Avg Dice: 0.3763\n",
            "Epoch [6/50], Step [80/350], Avg Loss: 0.9556, Avg Dice: 0.3783\n",
            "Epoch [6/50], Step [85/350], Avg Loss: 0.9533, Avg Dice: 0.3821\n",
            "Epoch [6/50], Step [90/350], Avg Loss: 0.9608, Avg Dice: 0.3821\n",
            "Epoch [6/50], Step [95/350], Avg Loss: 0.9604, Avg Dice: 0.3817\n",
            "Epoch [6/50], Step [100/350], Avg Loss: 0.9598, Avg Dice: 0.3831\n",
            "Epoch [6/50], Step [105/350], Avg Loss: 0.9637, Avg Dice: 0.3823\n",
            "Epoch [6/50], Step [110/350], Avg Loss: 0.9666, Avg Dice: 0.3806\n",
            "Epoch [6/50], Step [115/350], Avg Loss: 0.9687, Avg Dice: 0.3799\n",
            "Epoch [6/50], Step [120/350], Avg Loss: 0.9703, Avg Dice: 0.3808\n",
            "Epoch [6/50], Step [125/350], Avg Loss: 0.9709, Avg Dice: 0.3794\n",
            "Epoch [6/50], Step [130/350], Avg Loss: 0.9721, Avg Dice: 0.3803\n",
            "Epoch [6/50], Step [135/350], Avg Loss: 0.9702, Avg Dice: 0.3795\n",
            "Epoch [6/50], Step [140/350], Avg Loss: 0.9681, Avg Dice: 0.3794\n",
            "Epoch [6/50], Step [145/350], Avg Loss: 0.9708, Avg Dice: 0.3787\n",
            "Epoch [6/50], Step [150/350], Avg Loss: 0.9687, Avg Dice: 0.3783\n",
            "Epoch [6/50], Step [155/350], Avg Loss: 0.9665, Avg Dice: 0.3784\n",
            "Epoch [6/50], Step [160/350], Avg Loss: 0.9689, Avg Dice: 0.3788\n",
            "Epoch [6/50], Step [165/350], Avg Loss: 0.9677, Avg Dice: 0.3781\n",
            "Epoch [6/50], Step [170/350], Avg Loss: 0.9683, Avg Dice: 0.3792\n",
            "Epoch [6/50], Step [175/350], Avg Loss: 0.9689, Avg Dice: 0.3798\n",
            "Epoch [6/50], Step [180/350], Avg Loss: 0.9683, Avg Dice: 0.3808\n",
            "Epoch [6/50], Step [185/350], Avg Loss: 0.9686, Avg Dice: 0.3806\n",
            "Epoch [6/50], Step [190/350], Avg Loss: 0.9668, Avg Dice: 0.3817\n",
            "Epoch [6/50], Step [195/350], Avg Loss: 0.9655, Avg Dice: 0.3820\n",
            "Epoch [6/50], Step [200/350], Avg Loss: 0.9664, Avg Dice: 0.3812\n",
            "Epoch [6/50], Step [205/350], Avg Loss: 0.9661, Avg Dice: 0.3816\n",
            "Epoch [6/50], Step [210/350], Avg Loss: 0.9639, Avg Dice: 0.3809\n",
            "Epoch [6/50], Step [215/350], Avg Loss: 0.9653, Avg Dice: 0.3817\n",
            "Epoch [6/50], Step [220/350], Avg Loss: 0.9630, Avg Dice: 0.3823\n",
            "Epoch [6/50], Step [225/350], Avg Loss: 0.9621, Avg Dice: 0.3825\n",
            "Epoch [6/50], Step [230/350], Avg Loss: 0.9610, Avg Dice: 0.3830\n",
            "Epoch [6/50], Step [235/350], Avg Loss: 0.9599, Avg Dice: 0.3836\n",
            "Epoch [6/50], Step [240/350], Avg Loss: 0.9593, Avg Dice: 0.3833\n",
            "Epoch [6/50], Step [245/350], Avg Loss: 0.9574, Avg Dice: 0.3824\n",
            "Epoch [6/50], Step [250/350], Avg Loss: 0.9573, Avg Dice: 0.3819\n",
            "Epoch [6/50], Step [255/350], Avg Loss: 0.9578, Avg Dice: 0.3816\n",
            "Epoch [6/50], Step [260/350], Avg Loss: 0.9576, Avg Dice: 0.3813\n",
            "Epoch [6/50], Step [265/350], Avg Loss: 0.9563, Avg Dice: 0.3814\n",
            "Epoch [6/50], Step [270/350], Avg Loss: 0.9581, Avg Dice: 0.3808\n",
            "Epoch [6/50], Step [275/350], Avg Loss: 0.9571, Avg Dice: 0.3812\n",
            "Epoch [6/50], Step [280/350], Avg Loss: 0.9572, Avg Dice: 0.3810\n",
            "Epoch [6/50], Step [285/350], Avg Loss: 0.9579, Avg Dice: 0.3808\n",
            "Epoch [6/50], Step [290/350], Avg Loss: 0.9580, Avg Dice: 0.3810\n",
            "Epoch [6/50], Step [295/350], Avg Loss: 0.9585, Avg Dice: 0.3808\n",
            "Epoch [6/50], Step [300/350], Avg Loss: 0.9576, Avg Dice: 0.3807\n",
            "Epoch [6/50], Step [305/350], Avg Loss: 0.9579, Avg Dice: 0.3811\n",
            "Epoch [6/50], Step [310/350], Avg Loss: 0.9580, Avg Dice: 0.3811\n",
            "Epoch [6/50], Step [315/350], Avg Loss: 0.9576, Avg Dice: 0.3808\n",
            "Epoch [6/50], Step [320/350], Avg Loss: 0.9582, Avg Dice: 0.3809\n",
            "Epoch [6/50], Step [325/350], Avg Loss: 0.9577, Avg Dice: 0.3811\n",
            "Epoch [6/50], Step [330/350], Avg Loss: 0.9569, Avg Dice: 0.3813\n",
            "Epoch [6/50], Step [335/350], Avg Loss: 0.9581, Avg Dice: 0.3814\n",
            "Epoch [6/50], Step [340/350], Avg Loss: 0.9572, Avg Dice: 0.3820\n",
            "Epoch [6/50], Step [345/350], Avg Loss: 0.9566, Avg Dice: 0.3827\n",
            "Epoch [6/50], Step [350/350], Avg Loss: 0.9577, Avg Dice: 0.3830\n",
            "End of epoch 6: Avg Loss: 0.9577, Avg Dice: 0.3830\n",
            "Epoch [7/50], Step [5/350], Avg Loss: 0.9315, Avg Dice: 0.3812\n",
            "Epoch [7/50], Step [10/350], Avg Loss: 0.9492, Avg Dice: 0.3789\n",
            "Epoch [7/50], Step [15/350], Avg Loss: 0.9525, Avg Dice: 0.3791\n",
            "Epoch [7/50], Step [20/350], Avg Loss: 0.9208, Avg Dice: 0.3890\n",
            "Epoch [7/50], Step [25/350], Avg Loss: 0.9337, Avg Dice: 0.3831\n",
            "Epoch [7/50], Step [30/350], Avg Loss: 0.9336, Avg Dice: 0.3835\n",
            "Epoch [7/50], Step [35/350], Avg Loss: 0.9290, Avg Dice: 0.3869\n",
            "Epoch [7/50], Step [40/350], Avg Loss: 0.9163, Avg Dice: 0.3897\n",
            "Epoch [7/50], Step [45/350], Avg Loss: 0.9126, Avg Dice: 0.3901\n",
            "Epoch [7/50], Step [50/350], Avg Loss: 0.9249, Avg Dice: 0.3905\n",
            "Epoch [7/50], Step [55/350], Avg Loss: 0.9285, Avg Dice: 0.3844\n",
            "Epoch [7/50], Step [60/350], Avg Loss: 0.9369, Avg Dice: 0.3820\n",
            "Epoch [7/50], Step [65/350], Avg Loss: 0.9406, Avg Dice: 0.3829\n",
            "Epoch [7/50], Step [70/350], Avg Loss: 0.9431, Avg Dice: 0.3838\n",
            "Epoch [7/50], Step [75/350], Avg Loss: 0.9442, Avg Dice: 0.3825\n",
            "Epoch [7/50], Step [80/350], Avg Loss: 0.9416, Avg Dice: 0.3826\n",
            "Epoch [7/50], Step [85/350], Avg Loss: 0.9404, Avg Dice: 0.3848\n",
            "Epoch [7/50], Step [90/350], Avg Loss: 0.9414, Avg Dice: 0.3844\n",
            "Epoch [7/50], Step [95/350], Avg Loss: 0.9394, Avg Dice: 0.3851\n",
            "Epoch [7/50], Step [100/350], Avg Loss: 0.9389, Avg Dice: 0.3844\n",
            "Epoch [7/50], Step [105/350], Avg Loss: 0.9400, Avg Dice: 0.3841\n",
            "Epoch [7/50], Step [110/350], Avg Loss: 0.9372, Avg Dice: 0.3855\n",
            "Epoch [7/50], Step [115/350], Avg Loss: 0.9383, Avg Dice: 0.3851\n",
            "Epoch [7/50], Step [120/350], Avg Loss: 0.9329, Avg Dice: 0.3848\n",
            "Epoch [7/50], Step [125/350], Avg Loss: 0.9300, Avg Dice: 0.3849\n",
            "Epoch [7/50], Step [130/350], Avg Loss: 0.9308, Avg Dice: 0.3850\n",
            "Epoch [7/50], Step [135/350], Avg Loss: 0.9316, Avg Dice: 0.3860\n",
            "Epoch [7/50], Step [140/350], Avg Loss: 0.9321, Avg Dice: 0.3880\n",
            "Epoch [7/50], Step [145/350], Avg Loss: 0.9300, Avg Dice: 0.3877\n",
            "Epoch [7/50], Step [150/350], Avg Loss: 0.9328, Avg Dice: 0.3875\n",
            "Epoch [7/50], Step [155/350], Avg Loss: 0.9310, Avg Dice: 0.3864\n",
            "Epoch [7/50], Step [160/350], Avg Loss: 0.9332, Avg Dice: 0.3857\n",
            "Epoch [7/50], Step [165/350], Avg Loss: 0.9321, Avg Dice: 0.3874\n",
            "Epoch [7/50], Step [170/350], Avg Loss: 0.9328, Avg Dice: 0.3879\n",
            "Epoch [7/50], Step [175/350], Avg Loss: 0.9329, Avg Dice: 0.3882\n",
            "Epoch [7/50], Step [180/350], Avg Loss: 0.9323, Avg Dice: 0.3890\n",
            "Epoch [7/50], Step [185/350], Avg Loss: 0.9302, Avg Dice: 0.3889\n",
            "Epoch [7/50], Step [190/350], Avg Loss: 0.9286, Avg Dice: 0.3887\n",
            "Epoch [7/50], Step [195/350], Avg Loss: 0.9277, Avg Dice: 0.3876\n",
            "Epoch [7/50], Step [200/350], Avg Loss: 0.9289, Avg Dice: 0.3872\n",
            "Epoch [7/50], Step [205/350], Avg Loss: 0.9277, Avg Dice: 0.3876\n",
            "Epoch [7/50], Step [210/350], Avg Loss: 0.9273, Avg Dice: 0.3874\n",
            "Epoch [7/50], Step [215/350], Avg Loss: 0.9262, Avg Dice: 0.3883\n",
            "Epoch [7/50], Step [220/350], Avg Loss: 0.9277, Avg Dice: 0.3876\n",
            "Epoch [7/50], Step [225/350], Avg Loss: 0.9272, Avg Dice: 0.3880\n",
            "Epoch [7/50], Step [230/350], Avg Loss: 0.9280, Avg Dice: 0.3883\n",
            "Epoch [7/50], Step [235/350], Avg Loss: 0.9280, Avg Dice: 0.3889\n",
            "Epoch [7/50], Step [240/350], Avg Loss: 0.9290, Avg Dice: 0.3886\n",
            "Epoch [7/50], Step [245/350], Avg Loss: 0.9296, Avg Dice: 0.3874\n",
            "Epoch [7/50], Step [250/350], Avg Loss: 0.9304, Avg Dice: 0.3870\n",
            "Epoch [7/50], Step [255/350], Avg Loss: 0.9322, Avg Dice: 0.3856\n",
            "Epoch [7/50], Step [260/350], Avg Loss: 0.9319, Avg Dice: 0.3862\n",
            "Epoch [7/50], Step [265/350], Avg Loss: 0.9317, Avg Dice: 0.3856\n",
            "Epoch [7/50], Step [270/350], Avg Loss: 0.9323, Avg Dice: 0.3856\n",
            "Epoch [7/50], Step [275/350], Avg Loss: 0.9323, Avg Dice: 0.3856\n",
            "Epoch [7/50], Step [280/350], Avg Loss: 0.9323, Avg Dice: 0.3860\n",
            "Epoch [7/50], Step [285/350], Avg Loss: 0.9318, Avg Dice: 0.3859\n",
            "Epoch [7/50], Step [290/350], Avg Loss: 0.9322, Avg Dice: 0.3865\n",
            "Epoch [7/50], Step [295/350], Avg Loss: 0.9322, Avg Dice: 0.3870\n",
            "Epoch [7/50], Step [300/350], Avg Loss: 0.9322, Avg Dice: 0.3869\n",
            "Epoch [7/50], Step [305/350], Avg Loss: 0.9322, Avg Dice: 0.3879\n",
            "Epoch [7/50], Step [310/350], Avg Loss: 0.9323, Avg Dice: 0.3875\n",
            "Epoch [7/50], Step [315/350], Avg Loss: 0.9317, Avg Dice: 0.3872\n",
            "Epoch [7/50], Step [320/350], Avg Loss: 0.9315, Avg Dice: 0.3877\n",
            "Epoch [7/50], Step [325/350], Avg Loss: 0.9323, Avg Dice: 0.3873\n",
            "Epoch [7/50], Step [330/350], Avg Loss: 0.9319, Avg Dice: 0.3880\n",
            "Epoch [7/50], Step [335/350], Avg Loss: 0.9308, Avg Dice: 0.3886\n",
            "Epoch [7/50], Step [340/350], Avg Loss: 0.9303, Avg Dice: 0.3889\n",
            "Epoch [7/50], Step [345/350], Avg Loss: 0.9309, Avg Dice: 0.3882\n",
            "Epoch [7/50], Step [350/350], Avg Loss: 0.9310, Avg Dice: 0.3887\n",
            "End of epoch 7: Avg Loss: 0.9310, Avg Dice: 0.3887\n",
            "Epoch [8/50], Step [5/350], Avg Loss: 0.8308, Avg Dice: 0.4186\n",
            "Epoch [8/50], Step [10/350], Avg Loss: 0.9071, Avg Dice: 0.3940\n",
            "Epoch [8/50], Step [15/350], Avg Loss: 0.9314, Avg Dice: 0.3864\n",
            "Epoch [8/50], Step [20/350], Avg Loss: 0.9156, Avg Dice: 0.3789\n",
            "Epoch [8/50], Step [25/350], Avg Loss: 0.9291, Avg Dice: 0.3754\n",
            "Epoch [8/50], Step [30/350], Avg Loss: 0.9140, Avg Dice: 0.3691\n",
            "Epoch [8/50], Step [35/350], Avg Loss: 0.9116, Avg Dice: 0.3769\n",
            "Epoch [8/50], Step [40/350], Avg Loss: 0.9108, Avg Dice: 0.3766\n",
            "Epoch [8/50], Step [45/350], Avg Loss: 0.9103, Avg Dice: 0.3780\n",
            "Epoch [8/50], Step [50/350], Avg Loss: 0.9013, Avg Dice: 0.3739\n",
            "Epoch [8/50], Step [55/350], Avg Loss: 0.8998, Avg Dice: 0.3818\n",
            "Epoch [8/50], Step [60/350], Avg Loss: 0.9001, Avg Dice: 0.3815\n",
            "Epoch [8/50], Step [65/350], Avg Loss: 0.8964, Avg Dice: 0.3822\n",
            "Epoch [8/50], Step [70/350], Avg Loss: 0.9037, Avg Dice: 0.3831\n",
            "Epoch [8/50], Step [75/350], Avg Loss: 0.9068, Avg Dice: 0.3846\n",
            "Epoch [8/50], Step [80/350], Avg Loss: 0.9109, Avg Dice: 0.3848\n",
            "Epoch [8/50], Step [85/350], Avg Loss: 0.9135, Avg Dice: 0.3837\n",
            "Epoch [8/50], Step [90/350], Avg Loss: 0.9087, Avg Dice: 0.3842\n",
            "Epoch [8/50], Step [95/350], Avg Loss: 0.9132, Avg Dice: 0.3849\n",
            "Epoch [8/50], Step [100/350], Avg Loss: 0.9123, Avg Dice: 0.3842\n",
            "Epoch [8/50], Step [105/350], Avg Loss: 0.9140, Avg Dice: 0.3856\n",
            "Epoch [8/50], Step [110/350], Avg Loss: 0.9107, Avg Dice: 0.3874\n",
            "Epoch [8/50], Step [115/350], Avg Loss: 0.9078, Avg Dice: 0.3887\n",
            "Epoch [8/50], Step [120/350], Avg Loss: 0.9036, Avg Dice: 0.3889\n",
            "Epoch [8/50], Step [125/350], Avg Loss: 0.9025, Avg Dice: 0.3880\n",
            "Epoch [8/50], Step [130/350], Avg Loss: 0.9030, Avg Dice: 0.3886\n",
            "Epoch [8/50], Step [135/350], Avg Loss: 0.9023, Avg Dice: 0.3883\n",
            "Epoch [8/50], Step [140/350], Avg Loss: 0.9015, Avg Dice: 0.3878\n",
            "Epoch [8/50], Step [145/350], Avg Loss: 0.9026, Avg Dice: 0.3877\n",
            "Epoch [8/50], Step [150/350], Avg Loss: 0.9063, Avg Dice: 0.3875\n",
            "Epoch [8/50], Step [155/350], Avg Loss: 0.9071, Avg Dice: 0.3883\n",
            "Epoch [8/50], Step [160/350], Avg Loss: 0.9058, Avg Dice: 0.3894\n",
            "Epoch [8/50], Step [165/350], Avg Loss: 0.9049, Avg Dice: 0.3891\n",
            "Epoch [8/50], Step [170/350], Avg Loss: 0.9047, Avg Dice: 0.3895\n",
            "Epoch [8/50], Step [175/350], Avg Loss: 0.9042, Avg Dice: 0.3896\n",
            "Epoch [8/50], Step [180/350], Avg Loss: 0.9043, Avg Dice: 0.3901\n",
            "Epoch [8/50], Step [185/350], Avg Loss: 0.9041, Avg Dice: 0.3911\n",
            "Epoch [8/50], Step [190/350], Avg Loss: 0.9063, Avg Dice: 0.3898\n",
            "Epoch [8/50], Step [195/350], Avg Loss: 0.9075, Avg Dice: 0.3893\n",
            "Epoch [8/50], Step [200/350], Avg Loss: 0.9084, Avg Dice: 0.3885\n",
            "Epoch [8/50], Step [205/350], Avg Loss: 0.9077, Avg Dice: 0.3894\n",
            "Epoch [8/50], Step [210/350], Avg Loss: 0.9077, Avg Dice: 0.3898\n",
            "Epoch [8/50], Step [215/350], Avg Loss: 0.9075, Avg Dice: 0.3904\n",
            "Epoch [8/50], Step [220/350], Avg Loss: 0.9075, Avg Dice: 0.3901\n",
            "Epoch [8/50], Step [225/350], Avg Loss: 0.9069, Avg Dice: 0.3899\n",
            "Epoch [8/50], Step [230/350], Avg Loss: 0.9079, Avg Dice: 0.3895\n",
            "Epoch [8/50], Step [235/350], Avg Loss: 0.9061, Avg Dice: 0.3909\n",
            "Epoch [8/50], Step [240/350], Avg Loss: 0.9078, Avg Dice: 0.3905\n",
            "Epoch [8/50], Step [245/350], Avg Loss: 0.9085, Avg Dice: 0.3908\n",
            "Epoch [8/50], Step [250/350], Avg Loss: 0.9103, Avg Dice: 0.3907\n",
            "Epoch [8/50], Step [255/350], Avg Loss: 0.9096, Avg Dice: 0.3909\n",
            "Epoch [8/50], Step [260/350], Avg Loss: 0.9106, Avg Dice: 0.3903\n",
            "Epoch [8/50], Step [265/350], Avg Loss: 0.9099, Avg Dice: 0.3909\n",
            "Epoch [8/50], Step [270/350], Avg Loss: 0.9106, Avg Dice: 0.3905\n",
            "Epoch [8/50], Step [275/350], Avg Loss: 0.9111, Avg Dice: 0.3904\n",
            "Epoch [8/50], Step [280/350], Avg Loss: 0.9107, Avg Dice: 0.3902\n",
            "Epoch [8/50], Step [285/350], Avg Loss: 0.9106, Avg Dice: 0.3910\n",
            "Epoch [8/50], Step [290/350], Avg Loss: 0.9109, Avg Dice: 0.3904\n",
            "Epoch [8/50], Step [295/350], Avg Loss: 0.9110, Avg Dice: 0.3910\n",
            "Epoch [8/50], Step [300/350], Avg Loss: 0.9115, Avg Dice: 0.3912\n",
            "Epoch [8/50], Step [305/350], Avg Loss: 0.9114, Avg Dice: 0.3921\n",
            "Epoch [8/50], Step [310/350], Avg Loss: 0.9120, Avg Dice: 0.3918\n",
            "Epoch [8/50], Step [315/350], Avg Loss: 0.9109, Avg Dice: 0.3917\n",
            "Epoch [8/50], Step [320/350], Avg Loss: 0.9118, Avg Dice: 0.3918\n",
            "Epoch [8/50], Step [325/350], Avg Loss: 0.9118, Avg Dice: 0.3919\n",
            "Epoch [8/50], Step [330/350], Avg Loss: 0.9107, Avg Dice: 0.3917\n",
            "Epoch [8/50], Step [335/350], Avg Loss: 0.9104, Avg Dice: 0.3916\n",
            "Epoch [8/50], Step [340/350], Avg Loss: 0.9112, Avg Dice: 0.3913\n",
            "Epoch [8/50], Step [345/350], Avg Loss: 0.9113, Avg Dice: 0.3907\n",
            "Epoch [8/50], Step [350/350], Avg Loss: 0.9109, Avg Dice: 0.3913\n",
            "End of epoch 8: Avg Loss: 0.9109, Avg Dice: 0.3913\n",
            "Epoch [9/50], Step [5/350], Avg Loss: 0.8716, Avg Dice: 0.3874\n",
            "Epoch [9/50], Step [10/350], Avg Loss: 0.8648, Avg Dice: 0.3830\n",
            "Epoch [9/50], Step [15/350], Avg Loss: 0.8644, Avg Dice: 0.3894\n",
            "Epoch [9/50], Step [20/350], Avg Loss: 0.8819, Avg Dice: 0.3821\n",
            "Epoch [9/50], Step [25/350], Avg Loss: 0.8809, Avg Dice: 0.3777\n",
            "Epoch [9/50], Step [30/350], Avg Loss: 0.8699, Avg Dice: 0.3804\n",
            "Epoch [9/50], Step [35/350], Avg Loss: 0.8596, Avg Dice: 0.3803\n",
            "Epoch [9/50], Step [40/350], Avg Loss: 0.8652, Avg Dice: 0.3847\n",
            "Epoch [9/50], Step [45/350], Avg Loss: 0.8701, Avg Dice: 0.3879\n",
            "Epoch [9/50], Step [50/350], Avg Loss: 0.8724, Avg Dice: 0.3830\n",
            "Epoch [9/50], Step [55/350], Avg Loss: 0.8734, Avg Dice: 0.3872\n",
            "Epoch [9/50], Step [60/350], Avg Loss: 0.8743, Avg Dice: 0.3871\n",
            "Epoch [9/50], Step [65/350], Avg Loss: 0.8766, Avg Dice: 0.3863\n",
            "Epoch [9/50], Step [70/350], Avg Loss: 0.8794, Avg Dice: 0.3876\n",
            "Epoch [9/50], Step [75/350], Avg Loss: 0.8809, Avg Dice: 0.3908\n",
            "Epoch [9/50], Step [80/350], Avg Loss: 0.8812, Avg Dice: 0.3878\n",
            "Epoch [9/50], Step [85/350], Avg Loss: 0.8830, Avg Dice: 0.3915\n",
            "Epoch [9/50], Step [90/350], Avg Loss: 0.8805, Avg Dice: 0.3907\n",
            "Epoch [9/50], Step [95/350], Avg Loss: 0.8814, Avg Dice: 0.3897\n",
            "Epoch [9/50], Step [100/350], Avg Loss: 0.8805, Avg Dice: 0.3898\n",
            "Epoch [9/50], Step [105/350], Avg Loss: 0.8799, Avg Dice: 0.3902\n",
            "Epoch [9/50], Step [110/350], Avg Loss: 0.8802, Avg Dice: 0.3925\n",
            "Epoch [9/50], Step [115/350], Avg Loss: 0.8764, Avg Dice: 0.3925\n",
            "Epoch [9/50], Step [120/350], Avg Loss: 0.8768, Avg Dice: 0.3929\n",
            "Epoch [9/50], Step [125/350], Avg Loss: 0.8812, Avg Dice: 0.3928\n",
            "Epoch [9/50], Step [130/350], Avg Loss: 0.8838, Avg Dice: 0.3915\n",
            "Epoch [9/50], Step [135/350], Avg Loss: 0.8840, Avg Dice: 0.3926\n",
            "Epoch [9/50], Step [140/350], Avg Loss: 0.8866, Avg Dice: 0.3928\n",
            "Epoch [9/50], Step [145/350], Avg Loss: 0.8897, Avg Dice: 0.3916\n",
            "Epoch [9/50], Step [150/350], Avg Loss: 0.8893, Avg Dice: 0.3931\n",
            "Epoch [9/50], Step [155/350], Avg Loss: 0.8904, Avg Dice: 0.3924\n",
            "Epoch [9/50], Step [160/350], Avg Loss: 0.8893, Avg Dice: 0.3930\n",
            "Epoch [9/50], Step [165/350], Avg Loss: 0.8865, Avg Dice: 0.3948\n",
            "Epoch [9/50], Step [170/350], Avg Loss: 0.8869, Avg Dice: 0.3954\n",
            "Epoch [9/50], Step [175/350], Avg Loss: 0.8871, Avg Dice: 0.3952\n",
            "Epoch [9/50], Step [180/350], Avg Loss: 0.8869, Avg Dice: 0.3962\n",
            "Epoch [9/50], Step [185/350], Avg Loss: 0.8878, Avg Dice: 0.3957\n",
            "Epoch [9/50], Step [190/350], Avg Loss: 0.8894, Avg Dice: 0.3952\n",
            "Epoch [9/50], Step [195/350], Avg Loss: 0.8888, Avg Dice: 0.3957\n",
            "Epoch [9/50], Step [200/350], Avg Loss: 0.8892, Avg Dice: 0.3953\n",
            "Epoch [9/50], Step [205/350], Avg Loss: 0.8889, Avg Dice: 0.3950\n",
            "Epoch [9/50], Step [210/350], Avg Loss: 0.8888, Avg Dice: 0.3945\n",
            "Epoch [9/50], Step [215/350], Avg Loss: 0.8898, Avg Dice: 0.3946\n",
            "Epoch [9/50], Step [220/350], Avg Loss: 0.8895, Avg Dice: 0.3942\n",
            "Epoch [9/50], Step [225/350], Avg Loss: 0.8881, Avg Dice: 0.3950\n",
            "Epoch [9/50], Step [230/350], Avg Loss: 0.8865, Avg Dice: 0.3948\n",
            "Epoch [9/50], Step [235/350], Avg Loss: 0.8876, Avg Dice: 0.3945\n",
            "Epoch [9/50], Step [240/350], Avg Loss: 0.8879, Avg Dice: 0.3943\n",
            "Epoch [9/50], Step [245/350], Avg Loss: 0.8877, Avg Dice: 0.3943\n",
            "Epoch [9/50], Step [250/350], Avg Loss: 0.8880, Avg Dice: 0.3944\n",
            "Epoch [9/50], Step [255/350], Avg Loss: 0.8880, Avg Dice: 0.3947\n",
            "Epoch [9/50], Step [260/350], Avg Loss: 0.8866, Avg Dice: 0.3949\n",
            "Epoch [9/50], Step [265/350], Avg Loss: 0.8850, Avg Dice: 0.3949\n",
            "Epoch [9/50], Step [270/350], Avg Loss: 0.8846, Avg Dice: 0.3948\n",
            "Epoch [9/50], Step [275/350], Avg Loss: 0.8841, Avg Dice: 0.3942\n",
            "Epoch [9/50], Step [280/350], Avg Loss: 0.8846, Avg Dice: 0.3942\n",
            "Epoch [9/50], Step [285/350], Avg Loss: 0.8857, Avg Dice: 0.3937\n",
            "Epoch [9/50], Step [290/350], Avg Loss: 0.8856, Avg Dice: 0.3933\n",
            "Epoch [9/50], Step [295/350], Avg Loss: 0.8848, Avg Dice: 0.3934\n",
            "Epoch [9/50], Step [300/350], Avg Loss: 0.8858, Avg Dice: 0.3937\n",
            "Epoch [9/50], Step [305/350], Avg Loss: 0.8858, Avg Dice: 0.3928\n",
            "Epoch [9/50], Step [310/350], Avg Loss: 0.8871, Avg Dice: 0.3926\n",
            "Epoch [9/50], Step [315/350], Avg Loss: 0.8866, Avg Dice: 0.3928\n",
            "Epoch [9/50], Step [320/350], Avg Loss: 0.8873, Avg Dice: 0.3927\n",
            "Epoch [9/50], Step [325/350], Avg Loss: 0.8875, Avg Dice: 0.3928\n",
            "Epoch [9/50], Step [330/350], Avg Loss: 0.8882, Avg Dice: 0.3924\n",
            "Epoch [9/50], Step [335/350], Avg Loss: 0.8879, Avg Dice: 0.3921\n",
            "Epoch [9/50], Step [340/350], Avg Loss: 0.8878, Avg Dice: 0.3924\n",
            "Epoch [9/50], Step [345/350], Avg Loss: 0.8883, Avg Dice: 0.3917\n",
            "Epoch [9/50], Step [350/350], Avg Loss: 0.8887, Avg Dice: 0.3916\n",
            "End of epoch 9: Avg Loss: 0.8887, Avg Dice: 0.3916\n",
            "Epoch [10/50], Step [5/350], Avg Loss: 0.9294, Avg Dice: 0.4083\n",
            "Epoch [10/50], Step [10/350], Avg Loss: 0.9226, Avg Dice: 0.4065\n",
            "Epoch [10/50], Step [15/350], Avg Loss: 0.9152, Avg Dice: 0.4149\n",
            "Epoch [10/50], Step [20/350], Avg Loss: 0.8881, Avg Dice: 0.4163\n",
            "Epoch [10/50], Step [25/350], Avg Loss: 0.8823, Avg Dice: 0.4153\n",
            "Epoch [10/50], Step [30/350], Avg Loss: 0.8692, Avg Dice: 0.4101\n",
            "Epoch [10/50], Step [35/350], Avg Loss: 0.8699, Avg Dice: 0.4112\n",
            "Epoch [10/50], Step [40/350], Avg Loss: 0.8750, Avg Dice: 0.4133\n",
            "Epoch [10/50], Step [45/350], Avg Loss: 0.8627, Avg Dice: 0.4195\n",
            "Epoch [10/50], Step [50/350], Avg Loss: 0.8585, Avg Dice: 0.4155\n",
            "Epoch [10/50], Step [55/350], Avg Loss: 0.8532, Avg Dice: 0.4182\n",
            "Epoch [10/50], Step [60/350], Avg Loss: 0.8609, Avg Dice: 0.4133\n",
            "Epoch [10/50], Step [65/350], Avg Loss: 0.8535, Avg Dice: 0.4109\n",
            "Epoch [10/50], Step [70/350], Avg Loss: 0.8502, Avg Dice: 0.4108\n",
            "Epoch [10/50], Step [75/350], Avg Loss: 0.8501, Avg Dice: 0.4065\n",
            "Epoch [10/50], Step [80/350], Avg Loss: 0.8486, Avg Dice: 0.4041\n",
            "Epoch [10/50], Step [85/350], Avg Loss: 0.8473, Avg Dice: 0.4038\n",
            "Epoch [10/50], Step [90/350], Avg Loss: 0.8476, Avg Dice: 0.4036\n",
            "Epoch [10/50], Step [95/350], Avg Loss: 0.8485, Avg Dice: 0.4038\n",
            "Epoch [10/50], Step [100/350], Avg Loss: 0.8500, Avg Dice: 0.4033\n",
            "Epoch [10/50], Step [105/350], Avg Loss: 0.8490, Avg Dice: 0.4027\n",
            "Epoch [10/50], Step [110/350], Avg Loss: 0.8555, Avg Dice: 0.4001\n",
            "Epoch [10/50], Step [115/350], Avg Loss: 0.8566, Avg Dice: 0.4007\n",
            "Epoch [10/50], Step [120/350], Avg Loss: 0.8578, Avg Dice: 0.4009\n",
            "Epoch [10/50], Step [125/350], Avg Loss: 0.8612, Avg Dice: 0.4003\n",
            "Epoch [10/50], Step [130/350], Avg Loss: 0.8626, Avg Dice: 0.3996\n",
            "Epoch [10/50], Step [135/350], Avg Loss: 0.8635, Avg Dice: 0.3994\n",
            "Epoch [10/50], Step [140/350], Avg Loss: 0.8621, Avg Dice: 0.3998\n",
            "Epoch [10/50], Step [145/350], Avg Loss: 0.8637, Avg Dice: 0.3999\n",
            "Epoch [10/50], Step [150/350], Avg Loss: 0.8625, Avg Dice: 0.3993\n",
            "Epoch [10/50], Step [155/350], Avg Loss: 0.8621, Avg Dice: 0.3997\n",
            "Epoch [10/50], Step [160/350], Avg Loss: 0.8638, Avg Dice: 0.3994\n",
            "Epoch [10/50], Step [165/350], Avg Loss: 0.8650, Avg Dice: 0.3988\n",
            "Epoch [10/50], Step [170/350], Avg Loss: 0.8657, Avg Dice: 0.3984\n",
            "Epoch [10/50], Step [175/350], Avg Loss: 0.8648, Avg Dice: 0.3987\n",
            "Epoch [10/50], Step [180/350], Avg Loss: 0.8659, Avg Dice: 0.3989\n",
            "Epoch [10/50], Step [185/350], Avg Loss: 0.8672, Avg Dice: 0.3987\n",
            "Epoch [10/50], Step [190/350], Avg Loss: 0.8687, Avg Dice: 0.3985\n",
            "Epoch [10/50], Step [195/350], Avg Loss: 0.8686, Avg Dice: 0.3984\n",
            "Epoch [10/50], Step [200/350], Avg Loss: 0.8696, Avg Dice: 0.3980\n",
            "Epoch [10/50], Step [205/350], Avg Loss: 0.8689, Avg Dice: 0.3990\n",
            "Epoch [10/50], Step [210/350], Avg Loss: 0.8687, Avg Dice: 0.3996\n",
            "Epoch [10/50], Step [215/350], Avg Loss: 0.8678, Avg Dice: 0.3993\n",
            "Epoch [10/50], Step [220/350], Avg Loss: 0.8684, Avg Dice: 0.3996\n",
            "Epoch [10/50], Step [225/350], Avg Loss: 0.8695, Avg Dice: 0.3994\n",
            "Epoch [10/50], Step [230/350], Avg Loss: 0.8689, Avg Dice: 0.3992\n",
            "Epoch [10/50], Step [235/350], Avg Loss: 0.8691, Avg Dice: 0.3992\n",
            "Epoch [10/50], Step [240/350], Avg Loss: 0.8688, Avg Dice: 0.3989\n",
            "Epoch [10/50], Step [245/350], Avg Loss: 0.8694, Avg Dice: 0.3983\n",
            "Epoch [10/50], Step [250/350], Avg Loss: 0.8709, Avg Dice: 0.3985\n",
            "Epoch [10/50], Step [255/350], Avg Loss: 0.8710, Avg Dice: 0.3977\n",
            "Epoch [10/50], Step [260/350], Avg Loss: 0.8697, Avg Dice: 0.3975\n",
            "Epoch [10/50], Step [265/350], Avg Loss: 0.8682, Avg Dice: 0.3976\n",
            "Epoch [10/50], Step [270/350], Avg Loss: 0.8686, Avg Dice: 0.3972\n",
            "Epoch [10/50], Step [275/350], Avg Loss: 0.8683, Avg Dice: 0.3971\n",
            "Epoch [10/50], Step [280/350], Avg Loss: 0.8678, Avg Dice: 0.3968\n",
            "Epoch [10/50], Step [285/350], Avg Loss: 0.8687, Avg Dice: 0.3968\n",
            "Epoch [10/50], Step [290/350], Avg Loss: 0.8691, Avg Dice: 0.3966\n",
            "Epoch [10/50], Step [295/350], Avg Loss: 0.8690, Avg Dice: 0.3969\n",
            "Epoch [10/50], Step [300/350], Avg Loss: 0.8681, Avg Dice: 0.3971\n",
            "Epoch [10/50], Step [305/350], Avg Loss: 0.8682, Avg Dice: 0.3970\n",
            "Epoch [10/50], Step [310/350], Avg Loss: 0.8689, Avg Dice: 0.3974\n",
            "Epoch [10/50], Step [315/350], Avg Loss: 0.8688, Avg Dice: 0.3975\n",
            "Epoch [10/50], Step [320/350], Avg Loss: 0.8686, Avg Dice: 0.3974\n",
            "Epoch [10/50], Step [325/350], Avg Loss: 0.8682, Avg Dice: 0.3983\n",
            "Epoch [10/50], Step [330/350], Avg Loss: 0.8684, Avg Dice: 0.3986\n",
            "Epoch [10/50], Step [335/350], Avg Loss: 0.8668, Avg Dice: 0.3986\n",
            "Epoch [10/50], Step [340/350], Avg Loss: 0.8677, Avg Dice: 0.3982\n",
            "Epoch [10/50], Step [345/350], Avg Loss: 0.8683, Avg Dice: 0.3979\n",
            "Epoch [10/50], Step [350/350], Avg Loss: 0.8686, Avg Dice: 0.3980\n",
            "End of epoch 10: Avg Loss: 0.8686, Avg Dice: 0.3980\n",
            "Epoch [11/50], Step [5/350], Avg Loss: 0.8416, Avg Dice: 0.3936\n",
            "Epoch [11/50], Step [10/350], Avg Loss: 0.8516, Avg Dice: 0.3923\n",
            "Epoch [11/50], Step [15/350], Avg Loss: 0.8320, Avg Dice: 0.4006\n",
            "Epoch [11/50], Step [20/350], Avg Loss: 0.8242, Avg Dice: 0.4153\n",
            "Epoch [11/50], Step [25/350], Avg Loss: 0.8279, Avg Dice: 0.4196\n",
            "Epoch [11/50], Step [30/350], Avg Loss: 0.8134, Avg Dice: 0.4150\n",
            "Epoch [11/50], Step [35/350], Avg Loss: 0.8181, Avg Dice: 0.4188\n",
            "Epoch [11/50], Step [40/350], Avg Loss: 0.8204, Avg Dice: 0.4129\n",
            "Epoch [11/50], Step [45/350], Avg Loss: 0.8313, Avg Dice: 0.4110\n",
            "Epoch [11/50], Step [50/350], Avg Loss: 0.8326, Avg Dice: 0.4117\n",
            "Epoch [11/50], Step [55/350], Avg Loss: 0.8318, Avg Dice: 0.4124\n",
            "Epoch [11/50], Step [60/350], Avg Loss: 0.8345, Avg Dice: 0.4117\n",
            "Epoch [11/50], Step [65/350], Avg Loss: 0.8346, Avg Dice: 0.4115\n",
            "Epoch [11/50], Step [70/350], Avg Loss: 0.8345, Avg Dice: 0.4079\n",
            "Epoch [11/50], Step [75/350], Avg Loss: 0.8337, Avg Dice: 0.4071\n",
            "Epoch [11/50], Step [80/350], Avg Loss: 0.8330, Avg Dice: 0.4057\n",
            "Epoch [11/50], Step [85/350], Avg Loss: 0.8284, Avg Dice: 0.4095\n",
            "Epoch [11/50], Step [90/350], Avg Loss: 0.8321, Avg Dice: 0.4075\n",
            "Epoch [11/50], Step [95/350], Avg Loss: 0.8310, Avg Dice: 0.4071\n",
            "Epoch [11/50], Step [100/350], Avg Loss: 0.8302, Avg Dice: 0.4086\n",
            "Epoch [11/50], Step [105/350], Avg Loss: 0.8315, Avg Dice: 0.4066\n",
            "Epoch [11/50], Step [110/350], Avg Loss: 0.8306, Avg Dice: 0.4041\n",
            "Epoch [11/50], Step [115/350], Avg Loss: 0.8292, Avg Dice: 0.4044\n",
            "Epoch [11/50], Step [120/350], Avg Loss: 0.8313, Avg Dice: 0.4032\n",
            "Epoch [11/50], Step [125/350], Avg Loss: 0.8326, Avg Dice: 0.4025\n",
            "Epoch [11/50], Step [130/350], Avg Loss: 0.8358, Avg Dice: 0.4029\n",
            "Epoch [11/50], Step [135/350], Avg Loss: 0.8358, Avg Dice: 0.4028\n",
            "Epoch [11/50], Step [140/350], Avg Loss: 0.8378, Avg Dice: 0.4033\n",
            "Epoch [11/50], Step [145/350], Avg Loss: 0.8380, Avg Dice: 0.4031\n",
            "Epoch [11/50], Step [150/350], Avg Loss: 0.8384, Avg Dice: 0.4022\n",
            "Epoch [11/50], Step [155/350], Avg Loss: 0.8376, Avg Dice: 0.4036\n",
            "Epoch [11/50], Step [160/350], Avg Loss: 0.8377, Avg Dice: 0.4046\n",
            "Epoch [11/50], Step [165/350], Avg Loss: 0.8374, Avg Dice: 0.4050\n",
            "Epoch [11/50], Step [170/350], Avg Loss: 0.8398, Avg Dice: 0.4044\n",
            "Epoch [11/50], Step [175/350], Avg Loss: 0.8408, Avg Dice: 0.4045\n",
            "Epoch [11/50], Step [180/350], Avg Loss: 0.8422, Avg Dice: 0.4043\n",
            "Epoch [11/50], Step [185/350], Avg Loss: 0.8423, Avg Dice: 0.4030\n",
            "Epoch [11/50], Step [190/350], Avg Loss: 0.8435, Avg Dice: 0.4020\n",
            "Epoch [11/50], Step [195/350], Avg Loss: 0.8430, Avg Dice: 0.4018\n",
            "Epoch [11/50], Step [200/350], Avg Loss: 0.8452, Avg Dice: 0.4020\n",
            "Epoch [11/50], Step [205/350], Avg Loss: 0.8469, Avg Dice: 0.4008\n",
            "Epoch [11/50], Step [210/350], Avg Loss: 0.8468, Avg Dice: 0.4004\n",
            "Epoch [11/50], Step [215/350], Avg Loss: 0.8483, Avg Dice: 0.3997\n",
            "Epoch [11/50], Step [220/350], Avg Loss: 0.8491, Avg Dice: 0.4001\n",
            "Epoch [11/50], Step [225/350], Avg Loss: 0.8473, Avg Dice: 0.4007\n",
            "Epoch [11/50], Step [230/350], Avg Loss: 0.8476, Avg Dice: 0.3998\n",
            "Epoch [11/50], Step [235/350], Avg Loss: 0.8479, Avg Dice: 0.3994\n",
            "Epoch [11/50], Step [240/350], Avg Loss: 0.8478, Avg Dice: 0.4001\n",
            "Epoch [11/50], Step [245/350], Avg Loss: 0.8478, Avg Dice: 0.3995\n",
            "Epoch [11/50], Step [250/350], Avg Loss: 0.8462, Avg Dice: 0.3997\n",
            "Epoch [11/50], Step [255/350], Avg Loss: 0.8452, Avg Dice: 0.3994\n",
            "Epoch [11/50], Step [260/350], Avg Loss: 0.8465, Avg Dice: 0.3994\n",
            "Epoch [11/50], Step [265/350], Avg Loss: 0.8479, Avg Dice: 0.3991\n",
            "Epoch [11/50], Step [270/350], Avg Loss: 0.8468, Avg Dice: 0.3992\n",
            "Epoch [11/50], Step [275/350], Avg Loss: 0.8481, Avg Dice: 0.3994\n",
            "Epoch [11/50], Step [280/350], Avg Loss: 0.8505, Avg Dice: 0.3988\n",
            "Epoch [11/50], Step [285/350], Avg Loss: 0.8512, Avg Dice: 0.3984\n",
            "Epoch [11/50], Step [290/350], Avg Loss: 0.8532, Avg Dice: 0.3977\n",
            "Epoch [11/50], Step [295/350], Avg Loss: 0.8535, Avg Dice: 0.3981\n",
            "Epoch [11/50], Step [300/350], Avg Loss: 0.8556, Avg Dice: 0.3976\n",
            "Epoch [11/50], Step [305/350], Avg Loss: 0.8558, Avg Dice: 0.3975\n",
            "Epoch [11/50], Step [310/350], Avg Loss: 0.8549, Avg Dice: 0.3978\n",
            "Epoch [11/50], Step [315/350], Avg Loss: 0.8536, Avg Dice: 0.3978\n",
            "Epoch [11/50], Step [320/350], Avg Loss: 0.8526, Avg Dice: 0.3977\n",
            "Epoch [11/50], Step [325/350], Avg Loss: 0.8528, Avg Dice: 0.3973\n",
            "Epoch [11/50], Step [330/350], Avg Loss: 0.8512, Avg Dice: 0.3981\n",
            "Epoch [11/50], Step [335/350], Avg Loss: 0.8513, Avg Dice: 0.3981\n",
            "Epoch [11/50], Step [340/350], Avg Loss: 0.8524, Avg Dice: 0.3980\n",
            "Epoch [11/50], Step [345/350], Avg Loss: 0.8531, Avg Dice: 0.3972\n",
            "Epoch [11/50], Step [350/350], Avg Loss: 0.8528, Avg Dice: 0.3972\n",
            "End of epoch 11: Avg Loss: 0.8528, Avg Dice: 0.3972\n",
            "Epoch [12/50], Step [5/350], Avg Loss: 0.8635, Avg Dice: 0.4324\n",
            "Epoch [12/50], Step [10/350], Avg Loss: 0.8214, Avg Dice: 0.4418\n",
            "Epoch [12/50], Step [15/350], Avg Loss: 0.8194, Avg Dice: 0.4286\n",
            "Epoch [12/50], Step [20/350], Avg Loss: 0.8197, Avg Dice: 0.4159\n",
            "Epoch [12/50], Step [25/350], Avg Loss: 0.8125, Avg Dice: 0.4170\n",
            "Epoch [12/50], Step [30/350], Avg Loss: 0.8195, Avg Dice: 0.4177\n",
            "Epoch [12/50], Step [35/350], Avg Loss: 0.8189, Avg Dice: 0.4154\n",
            "Epoch [12/50], Step [40/350], Avg Loss: 0.8175, Avg Dice: 0.4101\n",
            "Epoch [12/50], Step [45/350], Avg Loss: 0.8105, Avg Dice: 0.4040\n",
            "Epoch [12/50], Step [50/350], Avg Loss: 0.8146, Avg Dice: 0.4085\n",
            "Epoch [12/50], Step [55/350], Avg Loss: 0.8148, Avg Dice: 0.4061\n",
            "Epoch [12/50], Step [60/350], Avg Loss: 0.8077, Avg Dice: 0.4098\n",
            "Epoch [12/50], Step [65/350], Avg Loss: 0.8033, Avg Dice: 0.4115\n",
            "Epoch [12/50], Step [70/350], Avg Loss: 0.8041, Avg Dice: 0.4120\n",
            "Epoch [12/50], Step [75/350], Avg Loss: 0.8112, Avg Dice: 0.4130\n",
            "Epoch [12/50], Step [80/350], Avg Loss: 0.8151, Avg Dice: 0.4109\n",
            "Epoch [12/50], Step [85/350], Avg Loss: 0.8173, Avg Dice: 0.4092\n",
            "Epoch [12/50], Step [90/350], Avg Loss: 0.8153, Avg Dice: 0.4101\n",
            "Epoch [12/50], Step [95/350], Avg Loss: 0.8135, Avg Dice: 0.4111\n",
            "Epoch [12/50], Step [100/350], Avg Loss: 0.8142, Avg Dice: 0.4127\n",
            "Epoch [12/50], Step [105/350], Avg Loss: 0.8146, Avg Dice: 0.4123\n",
            "Epoch [12/50], Step [110/350], Avg Loss: 0.8184, Avg Dice: 0.4110\n",
            "Epoch [12/50], Step [115/350], Avg Loss: 0.8184, Avg Dice: 0.4107\n",
            "Epoch [12/50], Step [120/350], Avg Loss: 0.8190, Avg Dice: 0.4113\n",
            "Epoch [12/50], Step [125/350], Avg Loss: 0.8204, Avg Dice: 0.4116\n",
            "Epoch [12/50], Step [130/350], Avg Loss: 0.8192, Avg Dice: 0.4134\n",
            "Epoch [12/50], Step [135/350], Avg Loss: 0.8196, Avg Dice: 0.4137\n",
            "Epoch [12/50], Step [140/350], Avg Loss: 0.8214, Avg Dice: 0.4143\n",
            "Epoch [12/50], Step [145/350], Avg Loss: 0.8231, Avg Dice: 0.4149\n",
            "Epoch [12/50], Step [150/350], Avg Loss: 0.8246, Avg Dice: 0.4157\n",
            "Epoch [12/50], Step [155/350], Avg Loss: 0.8235, Avg Dice: 0.4151\n",
            "Epoch [12/50], Step [160/350], Avg Loss: 0.8225, Avg Dice: 0.4150\n",
            "Epoch [12/50], Step [165/350], Avg Loss: 0.8212, Avg Dice: 0.4150\n",
            "Epoch [12/50], Step [170/350], Avg Loss: 0.8217, Avg Dice: 0.4162\n",
            "Epoch [12/50], Step [175/350], Avg Loss: 0.8233, Avg Dice: 0.4163\n",
            "Epoch [12/50], Step [180/350], Avg Loss: 0.8217, Avg Dice: 0.4148\n",
            "Epoch [12/50], Step [185/350], Avg Loss: 0.8216, Avg Dice: 0.4137\n",
            "Epoch [12/50], Step [190/350], Avg Loss: 0.8214, Avg Dice: 0.4141\n",
            "Epoch [12/50], Step [195/350], Avg Loss: 0.8225, Avg Dice: 0.4137\n",
            "Epoch [12/50], Step [200/350], Avg Loss: 0.8227, Avg Dice: 0.4133\n",
            "Epoch [12/50], Step [205/350], Avg Loss: 0.8207, Avg Dice: 0.4132\n",
            "Epoch [12/50], Step [210/350], Avg Loss: 0.8208, Avg Dice: 0.4119\n",
            "Epoch [12/50], Step [215/350], Avg Loss: 0.8203, Avg Dice: 0.4127\n",
            "Epoch [12/50], Step [220/350], Avg Loss: 0.8212, Avg Dice: 0.4114\n",
            "Epoch [12/50], Step [225/350], Avg Loss: 0.8205, Avg Dice: 0.4120\n",
            "Epoch [12/50], Step [230/350], Avg Loss: 0.8206, Avg Dice: 0.4112\n",
            "Epoch [12/50], Step [235/350], Avg Loss: 0.8211, Avg Dice: 0.4115\n",
            "Epoch [12/50], Step [240/350], Avg Loss: 0.8226, Avg Dice: 0.4115\n",
            "Epoch [12/50], Step [245/350], Avg Loss: 0.8248, Avg Dice: 0.4112\n",
            "Epoch [12/50], Step [250/350], Avg Loss: 0.8251, Avg Dice: 0.4103\n",
            "Epoch [12/50], Step [255/350], Avg Loss: 0.8252, Avg Dice: 0.4097\n",
            "Epoch [12/50], Step [260/350], Avg Loss: 0.8264, Avg Dice: 0.4092\n",
            "Epoch [12/50], Step [265/350], Avg Loss: 0.8274, Avg Dice: 0.4092\n",
            "Epoch [12/50], Step [270/350], Avg Loss: 0.8293, Avg Dice: 0.4093\n",
            "Epoch [12/50], Step [275/350], Avg Loss: 0.8298, Avg Dice: 0.4091\n",
            "Epoch [12/50], Step [280/350], Avg Loss: 0.8305, Avg Dice: 0.4085\n",
            "Epoch [12/50], Step [285/350], Avg Loss: 0.8315, Avg Dice: 0.4082\n",
            "Epoch [12/50], Step [290/350], Avg Loss: 0.8315, Avg Dice: 0.4075\n",
            "Epoch [12/50], Step [295/350], Avg Loss: 0.8307, Avg Dice: 0.4082\n",
            "Epoch [12/50], Step [300/350], Avg Loss: 0.8313, Avg Dice: 0.4088\n",
            "Epoch [12/50], Step [305/350], Avg Loss: 0.8319, Avg Dice: 0.4082\n",
            "Epoch [12/50], Step [310/350], Avg Loss: 0.8315, Avg Dice: 0.4077\n",
            "Epoch [12/50], Step [315/350], Avg Loss: 0.8307, Avg Dice: 0.4071\n",
            "Epoch [12/50], Step [320/350], Avg Loss: 0.8311, Avg Dice: 0.4068\n",
            "Epoch [12/50], Step [325/350], Avg Loss: 0.8319, Avg Dice: 0.4060\n",
            "Epoch [12/50], Step [330/350], Avg Loss: 0.8323, Avg Dice: 0.4049\n",
            "Epoch [12/50], Step [335/350], Avg Loss: 0.8329, Avg Dice: 0.4052\n",
            "Epoch [12/50], Step [340/350], Avg Loss: 0.8332, Avg Dice: 0.4052\n",
            "Epoch [12/50], Step [345/350], Avg Loss: 0.8327, Avg Dice: 0.4056\n",
            "Epoch [12/50], Step [350/350], Avg Loss: 0.8332, Avg Dice: 0.4055\n",
            "End of epoch 12: Avg Loss: 0.8332, Avg Dice: 0.4055\n",
            "Epoch [13/50], Step [5/350], Avg Loss: 0.7805, Avg Dice: 0.3821\n",
            "Epoch [13/50], Step [10/350], Avg Loss: 0.8078, Avg Dice: 0.4171\n",
            "Epoch [13/50], Step [15/350], Avg Loss: 0.8136, Avg Dice: 0.4176\n",
            "Epoch [13/50], Step [20/350], Avg Loss: 0.8110, Avg Dice: 0.4250\n",
            "Epoch [13/50], Step [25/350], Avg Loss: 0.8170, Avg Dice: 0.4302\n",
            "Epoch [13/50], Step [30/350], Avg Loss: 0.8272, Avg Dice: 0.4278\n",
            "Epoch [13/50], Step [35/350], Avg Loss: 0.8274, Avg Dice: 0.4247\n",
            "Epoch [13/50], Step [40/350], Avg Loss: 0.8263, Avg Dice: 0.4153\n",
            "Epoch [13/50], Step [45/350], Avg Loss: 0.8260, Avg Dice: 0.4111\n",
            "Epoch [13/50], Step [50/350], Avg Loss: 0.8189, Avg Dice: 0.4127\n",
            "Epoch [13/50], Step [55/350], Avg Loss: 0.8173, Avg Dice: 0.4107\n",
            "Epoch [13/50], Step [60/350], Avg Loss: 0.8118, Avg Dice: 0.4084\n",
            "Epoch [13/50], Step [65/350], Avg Loss: 0.8073, Avg Dice: 0.4087\n",
            "Epoch [13/50], Step [70/350], Avg Loss: 0.8069, Avg Dice: 0.4078\n",
            "Epoch [13/50], Step [75/350], Avg Loss: 0.8079, Avg Dice: 0.4076\n",
            "Epoch [13/50], Step [80/350], Avg Loss: 0.8042, Avg Dice: 0.4092\n",
            "Epoch [13/50], Step [85/350], Avg Loss: 0.8048, Avg Dice: 0.4087\n",
            "Epoch [13/50], Step [90/350], Avg Loss: 0.8047, Avg Dice: 0.4101\n",
            "Epoch [13/50], Step [95/350], Avg Loss: 0.8058, Avg Dice: 0.4123\n",
            "Epoch [13/50], Step [100/350], Avg Loss: 0.8038, Avg Dice: 0.4111\n",
            "Epoch [13/50], Step [105/350], Avg Loss: 0.8030, Avg Dice: 0.4106\n",
            "Epoch [13/50], Step [110/350], Avg Loss: 0.8005, Avg Dice: 0.4121\n",
            "Epoch [13/50], Step [115/350], Avg Loss: 0.7978, Avg Dice: 0.4121\n",
            "Epoch [13/50], Step [120/350], Avg Loss: 0.7995, Avg Dice: 0.4124\n",
            "Epoch [13/50], Step [125/350], Avg Loss: 0.7983, Avg Dice: 0.4148\n",
            "Epoch [13/50], Step [130/350], Avg Loss: 0.7980, Avg Dice: 0.4158\n",
            "Epoch [13/50], Step [135/350], Avg Loss: 0.7989, Avg Dice: 0.4145\n",
            "Epoch [13/50], Step [140/350], Avg Loss: 0.8001, Avg Dice: 0.4158\n",
            "Epoch [13/50], Step [145/350], Avg Loss: 0.8047, Avg Dice: 0.4152\n",
            "Epoch [13/50], Step [150/350], Avg Loss: 0.8045, Avg Dice: 0.4153\n",
            "Epoch [13/50], Step [155/350], Avg Loss: 0.8057, Avg Dice: 0.4151\n",
            "Epoch [13/50], Step [160/350], Avg Loss: 0.8085, Avg Dice: 0.4147\n",
            "Epoch [13/50], Step [165/350], Avg Loss: 0.8095, Avg Dice: 0.4144\n",
            "Epoch [13/50], Step [170/350], Avg Loss: 0.8108, Avg Dice: 0.4142\n",
            "Epoch [13/50], Step [175/350], Avg Loss: 0.8130, Avg Dice: 0.4149\n",
            "Epoch [13/50], Step [180/350], Avg Loss: 0.8158, Avg Dice: 0.4140\n",
            "Epoch [13/50], Step [185/350], Avg Loss: 0.8151, Avg Dice: 0.4142\n",
            "Epoch [13/50], Step [190/350], Avg Loss: 0.8158, Avg Dice: 0.4144\n",
            "Epoch [13/50], Step [195/350], Avg Loss: 0.8143, Avg Dice: 0.4137\n",
            "Epoch [13/50], Step [200/350], Avg Loss: 0.8134, Avg Dice: 0.4132\n",
            "Epoch [13/50], Step [205/350], Avg Loss: 0.8136, Avg Dice: 0.4136\n",
            "Epoch [13/50], Step [210/350], Avg Loss: 0.8125, Avg Dice: 0.4134\n",
            "Epoch [13/50], Step [215/350], Avg Loss: 0.8130, Avg Dice: 0.4136\n",
            "Epoch [13/50], Step [220/350], Avg Loss: 0.8114, Avg Dice: 0.4134\n",
            "Epoch [13/50], Step [225/350], Avg Loss: 0.8110, Avg Dice: 0.4132\n",
            "Epoch [13/50], Step [230/350], Avg Loss: 0.8114, Avg Dice: 0.4127\n",
            "Epoch [13/50], Step [235/350], Avg Loss: 0.8120, Avg Dice: 0.4127\n",
            "Epoch [13/50], Step [240/350], Avg Loss: 0.8123, Avg Dice: 0.4120\n",
            "Epoch [13/50], Step [245/350], Avg Loss: 0.8113, Avg Dice: 0.4128\n",
            "Epoch [13/50], Step [250/350], Avg Loss: 0.8124, Avg Dice: 0.4121\n",
            "Epoch [13/50], Step [255/350], Avg Loss: 0.8126, Avg Dice: 0.4120\n",
            "Epoch [13/50], Step [260/350], Avg Loss: 0.8122, Avg Dice: 0.4110\n",
            "Epoch [13/50], Step [265/350], Avg Loss: 0.8115, Avg Dice: 0.4114\n",
            "Epoch [13/50], Step [270/350], Avg Loss: 0.8114, Avg Dice: 0.4107\n",
            "Epoch [13/50], Step [275/350], Avg Loss: 0.8119, Avg Dice: 0.4111\n",
            "Epoch [13/50], Step [280/350], Avg Loss: 0.8116, Avg Dice: 0.4115\n",
            "Epoch [13/50], Step [285/350], Avg Loss: 0.8115, Avg Dice: 0.4116\n",
            "Epoch [13/50], Step [290/350], Avg Loss: 0.8118, Avg Dice: 0.4111\n",
            "Epoch [13/50], Step [295/350], Avg Loss: 0.8136, Avg Dice: 0.4103\n",
            "Epoch [13/50], Step [300/350], Avg Loss: 0.8134, Avg Dice: 0.4108\n",
            "Epoch [13/50], Step [305/350], Avg Loss: 0.8125, Avg Dice: 0.4107\n",
            "Epoch [13/50], Step [310/350], Avg Loss: 0.8124, Avg Dice: 0.4103\n",
            "Epoch [13/50], Step [315/350], Avg Loss: 0.8117, Avg Dice: 0.4099\n",
            "Epoch [13/50], Step [320/350], Avg Loss: 0.8112, Avg Dice: 0.4092\n",
            "Epoch [13/50], Step [325/350], Avg Loss: 0.8117, Avg Dice: 0.4091\n",
            "Epoch [13/50], Step [330/350], Avg Loss: 0.8122, Avg Dice: 0.4092\n",
            "Epoch [13/50], Step [335/350], Avg Loss: 0.8120, Avg Dice: 0.4087\n",
            "Epoch [13/50], Step [340/350], Avg Loss: 0.8117, Avg Dice: 0.4090\n",
            "Epoch [13/50], Step [345/350], Avg Loss: 0.8116, Avg Dice: 0.4085\n",
            "Epoch [13/50], Step [350/350], Avg Loss: 0.8129, Avg Dice: 0.4080\n",
            "End of epoch 13: Avg Loss: 0.8129, Avg Dice: 0.4080\n",
            "Epoch [14/50], Step [5/350], Avg Loss: 0.7393, Avg Dice: 0.4198\n",
            "Epoch [14/50], Step [10/350], Avg Loss: 0.7346, Avg Dice: 0.4344\n",
            "Epoch [14/50], Step [15/350], Avg Loss: 0.7568, Avg Dice: 0.4361\n",
            "Epoch [14/50], Step [20/350], Avg Loss: 0.7558, Avg Dice: 0.4333\n",
            "Epoch [14/50], Step [25/350], Avg Loss: 0.7605, Avg Dice: 0.4267\n",
            "Epoch [14/50], Step [30/350], Avg Loss: 0.7649, Avg Dice: 0.4208\n",
            "Epoch [14/50], Step [35/350], Avg Loss: 0.7695, Avg Dice: 0.4198\n",
            "Epoch [14/50], Step [40/350], Avg Loss: 0.7768, Avg Dice: 0.4153\n",
            "Epoch [14/50], Step [45/350], Avg Loss: 0.7833, Avg Dice: 0.4129\n",
            "Epoch [14/50], Step [50/350], Avg Loss: 0.7910, Avg Dice: 0.4085\n",
            "Epoch [14/50], Step [55/350], Avg Loss: 0.7909, Avg Dice: 0.4076\n",
            "Epoch [14/50], Step [60/350], Avg Loss: 0.7910, Avg Dice: 0.4059\n",
            "Epoch [14/50], Step [65/350], Avg Loss: 0.7916, Avg Dice: 0.4034\n",
            "Epoch [14/50], Step [70/350], Avg Loss: 0.7893, Avg Dice: 0.4024\n",
            "Epoch [14/50], Step [75/350], Avg Loss: 0.7960, Avg Dice: 0.4056\n",
            "Epoch [14/50], Step [80/350], Avg Loss: 0.7963, Avg Dice: 0.4051\n",
            "Epoch [14/50], Step [85/350], Avg Loss: 0.7980, Avg Dice: 0.4088\n",
            "Epoch [14/50], Step [90/350], Avg Loss: 0.7966, Avg Dice: 0.4097\n",
            "Epoch [14/50], Step [95/350], Avg Loss: 0.7956, Avg Dice: 0.4110\n",
            "Epoch [14/50], Step [100/350], Avg Loss: 0.7964, Avg Dice: 0.4108\n",
            "Epoch [14/50], Step [105/350], Avg Loss: 0.7944, Avg Dice: 0.4113\n",
            "Epoch [14/50], Step [110/350], Avg Loss: 0.7915, Avg Dice: 0.4119\n",
            "Epoch [14/50], Step [115/350], Avg Loss: 0.7924, Avg Dice: 0.4104\n",
            "Epoch [14/50], Step [120/350], Avg Loss: 0.7917, Avg Dice: 0.4106\n",
            "Epoch [14/50], Step [125/350], Avg Loss: 0.7896, Avg Dice: 0.4107\n",
            "Epoch [14/50], Step [130/350], Avg Loss: 0.7916, Avg Dice: 0.4101\n",
            "Epoch [14/50], Step [135/350], Avg Loss: 0.7900, Avg Dice: 0.4089\n",
            "Epoch [14/50], Step [140/350], Avg Loss: 0.7899, Avg Dice: 0.4098\n",
            "Epoch [14/50], Step [145/350], Avg Loss: 0.7902, Avg Dice: 0.4094\n",
            "Epoch [14/50], Step [150/350], Avg Loss: 0.7905, Avg Dice: 0.4100\n",
            "Epoch [14/50], Step [155/350], Avg Loss: 0.7890, Avg Dice: 0.4101\n",
            "Epoch [14/50], Step [160/350], Avg Loss: 0.7875, Avg Dice: 0.4108\n",
            "Epoch [14/50], Step [165/350], Avg Loss: 0.7880, Avg Dice: 0.4100\n",
            "Epoch [14/50], Step [170/350], Avg Loss: 0.7885, Avg Dice: 0.4102\n",
            "Epoch [14/50], Step [175/350], Avg Loss: 0.7871, Avg Dice: 0.4108\n",
            "Epoch [14/50], Step [180/350], Avg Loss: 0.7849, Avg Dice: 0.4116\n",
            "Epoch [14/50], Step [185/350], Avg Loss: 0.7857, Avg Dice: 0.4116\n",
            "Epoch [14/50], Step [190/350], Avg Loss: 0.7862, Avg Dice: 0.4113\n",
            "Epoch [14/50], Step [195/350], Avg Loss: 0.7847, Avg Dice: 0.4118\n",
            "Epoch [14/50], Step [200/350], Avg Loss: 0.7855, Avg Dice: 0.4120\n",
            "Epoch [14/50], Step [205/350], Avg Loss: 0.7861, Avg Dice: 0.4122\n",
            "Epoch [14/50], Step [210/350], Avg Loss: 0.7871, Avg Dice: 0.4121\n",
            "Epoch [14/50], Step [215/350], Avg Loss: 0.7893, Avg Dice: 0.4123\n",
            "Epoch [14/50], Step [220/350], Avg Loss: 0.7898, Avg Dice: 0.4125\n",
            "Epoch [14/50], Step [225/350], Avg Loss: 0.7900, Avg Dice: 0.4124\n",
            "Epoch [14/50], Step [230/350], Avg Loss: 0.7902, Avg Dice: 0.4123\n",
            "Epoch [14/50], Step [235/350], Avg Loss: 0.7897, Avg Dice: 0.4118\n",
            "Epoch [14/50], Step [240/350], Avg Loss: 0.7896, Avg Dice: 0.4120\n",
            "Epoch [14/50], Step [245/350], Avg Loss: 0.7904, Avg Dice: 0.4119\n",
            "Epoch [14/50], Step [250/350], Avg Loss: 0.7896, Avg Dice: 0.4115\n",
            "Epoch [14/50], Step [255/350], Avg Loss: 0.7896, Avg Dice: 0.4119\n",
            "Epoch [14/50], Step [260/350], Avg Loss: 0.7911, Avg Dice: 0.4122\n",
            "Epoch [14/50], Step [265/350], Avg Loss: 0.7912, Avg Dice: 0.4120\n",
            "Epoch [14/50], Step [270/350], Avg Loss: 0.7918, Avg Dice: 0.4122\n",
            "Epoch [14/50], Step [275/350], Avg Loss: 0.7915, Avg Dice: 0.4117\n",
            "Epoch [14/50], Step [280/350], Avg Loss: 0.7911, Avg Dice: 0.4116\n",
            "Epoch [14/50], Step [285/350], Avg Loss: 0.7908, Avg Dice: 0.4116\n",
            "Epoch [14/50], Step [290/350], Avg Loss: 0.7911, Avg Dice: 0.4111\n",
            "Epoch [14/50], Step [295/350], Avg Loss: 0.7902, Avg Dice: 0.4118\n",
            "Epoch [14/50], Step [300/350], Avg Loss: 0.7906, Avg Dice: 0.4114\n",
            "Epoch [14/50], Step [305/350], Avg Loss: 0.7931, Avg Dice: 0.4110\n",
            "Epoch [14/50], Step [310/350], Avg Loss: 0.7930, Avg Dice: 0.4114\n",
            "Epoch [14/50], Step [315/350], Avg Loss: 0.7934, Avg Dice: 0.4115\n",
            "Epoch [14/50], Step [320/350], Avg Loss: 0.7941, Avg Dice: 0.4114\n",
            "Epoch [14/50], Step [325/350], Avg Loss: 0.7946, Avg Dice: 0.4115\n",
            "Epoch [14/50], Step [330/350], Avg Loss: 0.7941, Avg Dice: 0.4120\n",
            "Epoch [14/50], Step [335/350], Avg Loss: 0.7955, Avg Dice: 0.4118\n",
            "Epoch [14/50], Step [340/350], Avg Loss: 0.7961, Avg Dice: 0.4115\n",
            "Epoch [14/50], Step [345/350], Avg Loss: 0.7962, Avg Dice: 0.4117\n",
            "Epoch [14/50], Step [350/350], Avg Loss: 0.7968, Avg Dice: 0.4119\n",
            "End of epoch 14: Avg Loss: 0.7968, Avg Dice: 0.4119\n",
            "Epoch [15/50], Step [5/350], Avg Loss: 0.8453, Avg Dice: 0.4184\n",
            "Epoch [15/50], Step [10/350], Avg Loss: 0.7793, Avg Dice: 0.4039\n",
            "Epoch [15/50], Step [15/350], Avg Loss: 0.7918, Avg Dice: 0.4093\n",
            "Epoch [15/50], Step [20/350], Avg Loss: 0.7832, Avg Dice: 0.4147\n",
            "Epoch [15/50], Step [25/350], Avg Loss: 0.7677, Avg Dice: 0.4174\n",
            "Epoch [15/50], Step [30/350], Avg Loss: 0.7658, Avg Dice: 0.4209\n",
            "Epoch [15/50], Step [35/350], Avg Loss: 0.7650, Avg Dice: 0.4173\n",
            "Epoch [15/50], Step [40/350], Avg Loss: 0.7671, Avg Dice: 0.4152\n",
            "Epoch [15/50], Step [45/350], Avg Loss: 0.7650, Avg Dice: 0.4156\n",
            "Epoch [15/50], Step [50/350], Avg Loss: 0.7677, Avg Dice: 0.4146\n",
            "Epoch [15/50], Step [55/350], Avg Loss: 0.7652, Avg Dice: 0.4144\n",
            "Epoch [15/50], Step [60/350], Avg Loss: 0.7638, Avg Dice: 0.4131\n",
            "Epoch [15/50], Step [65/350], Avg Loss: 0.7621, Avg Dice: 0.4127\n",
            "Epoch [15/50], Step [70/350], Avg Loss: 0.7637, Avg Dice: 0.4124\n",
            "Epoch [15/50], Step [75/350], Avg Loss: 0.7692, Avg Dice: 0.4098\n",
            "Epoch [15/50], Step [80/350], Avg Loss: 0.7707, Avg Dice: 0.4110\n",
            "Epoch [15/50], Step [85/350], Avg Loss: 0.7695, Avg Dice: 0.4117\n",
            "Epoch [15/50], Step [90/350], Avg Loss: 0.7709, Avg Dice: 0.4089\n",
            "Epoch [15/50], Step [95/350], Avg Loss: 0.7721, Avg Dice: 0.4106\n",
            "Epoch [15/50], Step [100/350], Avg Loss: 0.7737, Avg Dice: 0.4124\n",
            "Epoch [15/50], Step [105/350], Avg Loss: 0.7736, Avg Dice: 0.4147\n",
            "Epoch [15/50], Step [110/350], Avg Loss: 0.7700, Avg Dice: 0.4173\n",
            "Epoch [15/50], Step [115/350], Avg Loss: 0.7697, Avg Dice: 0.4169\n",
            "Epoch [15/50], Step [120/350], Avg Loss: 0.7686, Avg Dice: 0.4175\n",
            "Epoch [15/50], Step [125/350], Avg Loss: 0.7693, Avg Dice: 0.4170\n",
            "Epoch [15/50], Step [130/350], Avg Loss: 0.7722, Avg Dice: 0.4154\n",
            "Epoch [15/50], Step [135/350], Avg Loss: 0.7745, Avg Dice: 0.4154\n",
            "Epoch [15/50], Step [140/350], Avg Loss: 0.7731, Avg Dice: 0.4156\n",
            "Epoch [15/50], Step [145/350], Avg Loss: 0.7716, Avg Dice: 0.4156\n",
            "Epoch [15/50], Step [150/350], Avg Loss: 0.7722, Avg Dice: 0.4144\n",
            "Epoch [15/50], Step [155/350], Avg Loss: 0.7707, Avg Dice: 0.4143\n",
            "Epoch [15/50], Step [160/350], Avg Loss: 0.7694, Avg Dice: 0.4139\n",
            "Epoch [15/50], Step [165/350], Avg Loss: 0.7691, Avg Dice: 0.4141\n",
            "Epoch [15/50], Step [170/350], Avg Loss: 0.7697, Avg Dice: 0.4133\n",
            "Epoch [15/50], Step [175/350], Avg Loss: 0.7678, Avg Dice: 0.4139\n",
            "Epoch [15/50], Step [180/350], Avg Loss: 0.7696, Avg Dice: 0.4138\n",
            "Epoch [15/50], Step [185/350], Avg Loss: 0.7690, Avg Dice: 0.4146\n",
            "Epoch [15/50], Step [190/350], Avg Loss: 0.7680, Avg Dice: 0.4146\n",
            "Epoch [15/50], Step [195/350], Avg Loss: 0.7691, Avg Dice: 0.4156\n",
            "Epoch [15/50], Step [200/350], Avg Loss: 0.7705, Avg Dice: 0.4160\n",
            "Epoch [15/50], Step [205/350], Avg Loss: 0.7713, Avg Dice: 0.4167\n",
            "Epoch [15/50], Step [210/350], Avg Loss: 0.7717, Avg Dice: 0.4169\n",
            "Epoch [15/50], Step [215/350], Avg Loss: 0.7708, Avg Dice: 0.4161\n",
            "Epoch [15/50], Step [220/350], Avg Loss: 0.7727, Avg Dice: 0.4155\n",
            "Epoch [15/50], Step [225/350], Avg Loss: 0.7728, Avg Dice: 0.4150\n",
            "Epoch [15/50], Step [230/350], Avg Loss: 0.7728, Avg Dice: 0.4153\n",
            "Epoch [15/50], Step [235/350], Avg Loss: 0.7721, Avg Dice: 0.4149\n",
            "Epoch [15/50], Step [240/350], Avg Loss: 0.7731, Avg Dice: 0.4149\n",
            "Epoch [15/50], Step [245/350], Avg Loss: 0.7730, Avg Dice: 0.4153\n",
            "Epoch [15/50], Step [250/350], Avg Loss: 0.7735, Avg Dice: 0.4152\n",
            "Epoch [15/50], Step [255/350], Avg Loss: 0.7738, Avg Dice: 0.4155\n",
            "Epoch [15/50], Step [260/350], Avg Loss: 0.7735, Avg Dice: 0.4146\n",
            "Epoch [15/50], Step [265/350], Avg Loss: 0.7732, Avg Dice: 0.4156\n",
            "Epoch [15/50], Step [270/350], Avg Loss: 0.7729, Avg Dice: 0.4146\n",
            "Epoch [15/50], Step [275/350], Avg Loss: 0.7726, Avg Dice: 0.4147\n",
            "Epoch [15/50], Step [280/350], Avg Loss: 0.7732, Avg Dice: 0.4143\n",
            "Epoch [15/50], Step [285/350], Avg Loss: 0.7731, Avg Dice: 0.4144\n",
            "Epoch [15/50], Step [290/350], Avg Loss: 0.7731, Avg Dice: 0.4152\n",
            "Epoch [15/50], Step [295/350], Avg Loss: 0.7726, Avg Dice: 0.4157\n",
            "Epoch [15/50], Step [300/350], Avg Loss: 0.7726, Avg Dice: 0.4156\n",
            "Epoch [15/50], Step [305/350], Avg Loss: 0.7742, Avg Dice: 0.4155\n",
            "Epoch [15/50], Step [310/350], Avg Loss: 0.7744, Avg Dice: 0.4157\n",
            "Epoch [15/50], Step [315/350], Avg Loss: 0.7744, Avg Dice: 0.4165\n",
            "Epoch [15/50], Step [320/350], Avg Loss: 0.7754, Avg Dice: 0.4166\n",
            "Epoch [15/50], Step [325/350], Avg Loss: 0.7757, Avg Dice: 0.4169\n",
            "Epoch [15/50], Step [330/350], Avg Loss: 0.7755, Avg Dice: 0.4172\n",
            "Epoch [15/50], Step [335/350], Avg Loss: 0.7752, Avg Dice: 0.4178\n",
            "Epoch [15/50], Step [340/350], Avg Loss: 0.7756, Avg Dice: 0.4182\n",
            "Epoch [15/50], Step [345/350], Avg Loss: 0.7759, Avg Dice: 0.4177\n",
            "Epoch [15/50], Step [350/350], Avg Loss: 0.7769, Avg Dice: 0.4177\n",
            "End of epoch 15: Avg Loss: 0.7769, Avg Dice: 0.4177\n",
            "Epoch [16/50], Step [5/350], Avg Loss: 0.7063, Avg Dice: 0.4644\n",
            "Epoch [16/50], Step [10/350], Avg Loss: 0.7484, Avg Dice: 0.4285\n",
            "Epoch [16/50], Step [15/350], Avg Loss: 0.7558, Avg Dice: 0.4120\n",
            "Epoch [16/50], Step [20/350], Avg Loss: 0.7515, Avg Dice: 0.4165\n",
            "Epoch [16/50], Step [25/350], Avg Loss: 0.7533, Avg Dice: 0.4170\n",
            "Epoch [16/50], Step [30/350], Avg Loss: 0.7457, Avg Dice: 0.4184\n",
            "Epoch [16/50], Step [35/350], Avg Loss: 0.7535, Avg Dice: 0.4182\n",
            "Epoch [16/50], Step [40/350], Avg Loss: 0.7474, Avg Dice: 0.4242\n",
            "Epoch [16/50], Step [45/350], Avg Loss: 0.7575, Avg Dice: 0.4229\n",
            "Epoch [16/50], Step [50/350], Avg Loss: 0.7539, Avg Dice: 0.4174\n",
            "Epoch [16/50], Step [55/350], Avg Loss: 0.7534, Avg Dice: 0.4214\n",
            "Epoch [16/50], Step [60/350], Avg Loss: 0.7550, Avg Dice: 0.4203\n",
            "Epoch [16/50], Step [65/350], Avg Loss: 0.7522, Avg Dice: 0.4186\n",
            "Epoch [16/50], Step [70/350], Avg Loss: 0.7564, Avg Dice: 0.4152\n",
            "Epoch [16/50], Step [75/350], Avg Loss: 0.7587, Avg Dice: 0.4170\n",
            "Epoch [16/50], Step [80/350], Avg Loss: 0.7599, Avg Dice: 0.4153\n",
            "Epoch [16/50], Step [85/350], Avg Loss: 0.7622, Avg Dice: 0.4133\n",
            "Epoch [16/50], Step [90/350], Avg Loss: 0.7587, Avg Dice: 0.4146\n",
            "Epoch [16/50], Step [95/350], Avg Loss: 0.7620, Avg Dice: 0.4134\n",
            "Epoch [16/50], Step [100/350], Avg Loss: 0.7626, Avg Dice: 0.4151\n",
            "Epoch [16/50], Step [105/350], Avg Loss: 0.7624, Avg Dice: 0.4157\n",
            "Epoch [16/50], Step [110/350], Avg Loss: 0.7594, Avg Dice: 0.4165\n",
            "Epoch [16/50], Step [115/350], Avg Loss: 0.7604, Avg Dice: 0.4171\n",
            "Epoch [16/50], Step [120/350], Avg Loss: 0.7591, Avg Dice: 0.4167\n",
            "Epoch [16/50], Step [125/350], Avg Loss: 0.7569, Avg Dice: 0.4187\n",
            "Epoch [16/50], Step [130/350], Avg Loss: 0.7562, Avg Dice: 0.4184\n",
            "Epoch [16/50], Step [135/350], Avg Loss: 0.7567, Avg Dice: 0.4195\n",
            "Epoch [16/50], Step [140/350], Avg Loss: 0.7577, Avg Dice: 0.4191\n",
            "Epoch [16/50], Step [145/350], Avg Loss: 0.7571, Avg Dice: 0.4180\n",
            "Epoch [16/50], Step [150/350], Avg Loss: 0.7559, Avg Dice: 0.4178\n",
            "Epoch [16/50], Step [155/350], Avg Loss: 0.7556, Avg Dice: 0.4180\n",
            "Epoch [16/50], Step [160/350], Avg Loss: 0.7553, Avg Dice: 0.4183\n",
            "Epoch [16/50], Step [165/350], Avg Loss: 0.7548, Avg Dice: 0.4183\n",
            "Epoch [16/50], Step [170/350], Avg Loss: 0.7541, Avg Dice: 0.4187\n",
            "Epoch [16/50], Step [175/350], Avg Loss: 0.7537, Avg Dice: 0.4195\n",
            "Epoch [16/50], Step [180/350], Avg Loss: 0.7540, Avg Dice: 0.4203\n",
            "Epoch [16/50], Step [185/350], Avg Loss: 0.7548, Avg Dice: 0.4204\n",
            "Epoch [16/50], Step [190/350], Avg Loss: 0.7545, Avg Dice: 0.4196\n",
            "Epoch [16/50], Step [195/350], Avg Loss: 0.7538, Avg Dice: 0.4194\n",
            "Epoch [16/50], Step [200/350], Avg Loss: 0.7552, Avg Dice: 0.4202\n",
            "Epoch [16/50], Step [205/350], Avg Loss: 0.7565, Avg Dice: 0.4211\n",
            "Epoch [16/50], Step [210/350], Avg Loss: 0.7563, Avg Dice: 0.4210\n",
            "Epoch [16/50], Step [215/350], Avg Loss: 0.7551, Avg Dice: 0.4200\n",
            "Epoch [16/50], Step [220/350], Avg Loss: 0.7566, Avg Dice: 0.4195\n",
            "Epoch [16/50], Step [225/350], Avg Loss: 0.7573, Avg Dice: 0.4186\n",
            "Epoch [16/50], Step [230/350], Avg Loss: 0.7574, Avg Dice: 0.4184\n",
            "Epoch [16/50], Step [235/350], Avg Loss: 0.7587, Avg Dice: 0.4192\n",
            "Epoch [16/50], Step [240/350], Avg Loss: 0.7597, Avg Dice: 0.4193\n",
            "Epoch [16/50], Step [245/350], Avg Loss: 0.7602, Avg Dice: 0.4179\n",
            "Epoch [16/50], Step [250/350], Avg Loss: 0.7599, Avg Dice: 0.4173\n",
            "Epoch [16/50], Step [255/350], Avg Loss: 0.7603, Avg Dice: 0.4174\n",
            "Epoch [16/50], Step [260/350], Avg Loss: 0.7595, Avg Dice: 0.4179\n",
            "Epoch [16/50], Step [265/350], Avg Loss: 0.7607, Avg Dice: 0.4173\n",
            "Epoch [16/50], Step [270/350], Avg Loss: 0.7610, Avg Dice: 0.4179\n",
            "Epoch [16/50], Step [275/350], Avg Loss: 0.7611, Avg Dice: 0.4181\n",
            "Epoch [16/50], Step [280/350], Avg Loss: 0.7627, Avg Dice: 0.4175\n",
            "Epoch [16/50], Step [285/350], Avg Loss: 0.7620, Avg Dice: 0.4179\n",
            "Epoch [16/50], Step [290/350], Avg Loss: 0.7617, Avg Dice: 0.4187\n",
            "Epoch [16/50], Step [295/350], Avg Loss: 0.7624, Avg Dice: 0.4186\n",
            "Epoch [16/50], Step [300/350], Avg Loss: 0.7625, Avg Dice: 0.4190\n",
            "Epoch [16/50], Step [305/350], Avg Loss: 0.7620, Avg Dice: 0.4190\n",
            "Epoch [16/50], Step [310/350], Avg Loss: 0.7621, Avg Dice: 0.4198\n",
            "Epoch [16/50], Step [315/350], Avg Loss: 0.7615, Avg Dice: 0.4199\n",
            "Epoch [16/50], Step [320/350], Avg Loss: 0.7616, Avg Dice: 0.4200\n",
            "Epoch [16/50], Step [325/350], Avg Loss: 0.7612, Avg Dice: 0.4201\n",
            "Epoch [16/50], Step [330/350], Avg Loss: 0.7613, Avg Dice: 0.4202\n",
            "Epoch [16/50], Step [335/350], Avg Loss: 0.7617, Avg Dice: 0.4202\n",
            "Epoch [16/50], Step [340/350], Avg Loss: 0.7617, Avg Dice: 0.4201\n",
            "Epoch [16/50], Step [345/350], Avg Loss: 0.7616, Avg Dice: 0.4209\n",
            "Epoch [16/50], Step [350/350], Avg Loss: 0.7606, Avg Dice: 0.4213\n",
            "End of epoch 16: Avg Loss: 0.7606, Avg Dice: 0.4213\n",
            "Epoch [17/50], Step [5/350], Avg Loss: 0.7200, Avg Dice: 0.4162\n",
            "Epoch [17/50], Step [10/350], Avg Loss: 0.7301, Avg Dice: 0.4054\n",
            "Epoch [17/50], Step [15/350], Avg Loss: 0.7149, Avg Dice: 0.4055\n",
            "Epoch [17/50], Step [20/350], Avg Loss: 0.7125, Avg Dice: 0.4111\n",
            "Epoch [17/50], Step [25/350], Avg Loss: 0.7187, Avg Dice: 0.4117\n",
            "Epoch [17/50], Step [30/350], Avg Loss: 0.7245, Avg Dice: 0.4158\n",
            "Epoch [17/50], Step [35/350], Avg Loss: 0.7292, Avg Dice: 0.4100\n",
            "Epoch [17/50], Step [40/350], Avg Loss: 0.7282, Avg Dice: 0.4123\n",
            "Epoch [17/50], Step [45/350], Avg Loss: 0.7249, Avg Dice: 0.4204\n",
            "Epoch [17/50], Step [50/350], Avg Loss: 0.7296, Avg Dice: 0.4237\n",
            "Epoch [17/50], Step [55/350], Avg Loss: 0.7256, Avg Dice: 0.4233\n",
            "Epoch [17/50], Step [60/350], Avg Loss: 0.7254, Avg Dice: 0.4235\n",
            "Epoch [17/50], Step [65/350], Avg Loss: 0.7248, Avg Dice: 0.4256\n",
            "Epoch [17/50], Step [70/350], Avg Loss: 0.7262, Avg Dice: 0.4251\n",
            "Epoch [17/50], Step [75/350], Avg Loss: 0.7306, Avg Dice: 0.4235\n",
            "Epoch [17/50], Step [80/350], Avg Loss: 0.7305, Avg Dice: 0.4253\n",
            "Epoch [17/50], Step [85/350], Avg Loss: 0.7322, Avg Dice: 0.4241\n",
            "Epoch [17/50], Step [90/350], Avg Loss: 0.7309, Avg Dice: 0.4239\n",
            "Epoch [17/50], Step [95/350], Avg Loss: 0.7329, Avg Dice: 0.4225\n",
            "Epoch [17/50], Step [100/350], Avg Loss: 0.7346, Avg Dice: 0.4222\n",
            "Epoch [17/50], Step [105/350], Avg Loss: 0.7349, Avg Dice: 0.4239\n",
            "Epoch [17/50], Step [110/350], Avg Loss: 0.7413, Avg Dice: 0.4230\n",
            "Epoch [17/50], Step [115/350], Avg Loss: 0.7414, Avg Dice: 0.4227\n",
            "Epoch [17/50], Step [120/350], Avg Loss: 0.7416, Avg Dice: 0.4227\n",
            "Epoch [17/50], Step [125/350], Avg Loss: 0.7428, Avg Dice: 0.4226\n",
            "Epoch [17/50], Step [130/350], Avg Loss: 0.7414, Avg Dice: 0.4225\n",
            "Epoch [17/50], Step [135/350], Avg Loss: 0.7398, Avg Dice: 0.4235\n",
            "Epoch [17/50], Step [140/350], Avg Loss: 0.7399, Avg Dice: 0.4238\n",
            "Epoch [17/50], Step [145/350], Avg Loss: 0.7383, Avg Dice: 0.4226\n",
            "Epoch [17/50], Step [150/350], Avg Loss: 0.7400, Avg Dice: 0.4230\n",
            "Epoch [17/50], Step [155/350], Avg Loss: 0.7403, Avg Dice: 0.4226\n",
            "Epoch [17/50], Step [160/350], Avg Loss: 0.7387, Avg Dice: 0.4225\n",
            "Epoch [17/50], Step [165/350], Avg Loss: 0.7402, Avg Dice: 0.4219\n",
            "Epoch [17/50], Step [170/350], Avg Loss: 0.7417, Avg Dice: 0.4229\n",
            "Epoch [17/50], Step [175/350], Avg Loss: 0.7408, Avg Dice: 0.4226\n",
            "Epoch [17/50], Step [180/350], Avg Loss: 0.7405, Avg Dice: 0.4230\n",
            "Epoch [17/50], Step [185/350], Avg Loss: 0.7405, Avg Dice: 0.4240\n",
            "Epoch [17/50], Step [190/350], Avg Loss: 0.7402, Avg Dice: 0.4241\n",
            "Epoch [17/50], Step [195/350], Avg Loss: 0.7401, Avg Dice: 0.4242\n",
            "Epoch [17/50], Step [200/350], Avg Loss: 0.7386, Avg Dice: 0.4250\n",
            "Epoch [17/50], Step [205/350], Avg Loss: 0.7397, Avg Dice: 0.4245\n",
            "Epoch [17/50], Step [210/350], Avg Loss: 0.7406, Avg Dice: 0.4237\n",
            "Epoch [17/50], Step [215/350], Avg Loss: 0.7408, Avg Dice: 0.4244\n",
            "Epoch [17/50], Step [220/350], Avg Loss: 0.7420, Avg Dice: 0.4239\n",
            "Epoch [17/50], Step [225/350], Avg Loss: 0.7427, Avg Dice: 0.4240\n",
            "Epoch [17/50], Step [230/350], Avg Loss: 0.7437, Avg Dice: 0.4236\n",
            "Epoch [17/50], Step [235/350], Avg Loss: 0.7428, Avg Dice: 0.4242\n",
            "Epoch [17/50], Step [240/350], Avg Loss: 0.7423, Avg Dice: 0.4248\n",
            "Epoch [17/50], Step [245/350], Avg Loss: 0.7426, Avg Dice: 0.4243\n",
            "Epoch [17/50], Step [250/350], Avg Loss: 0.7435, Avg Dice: 0.4249\n",
            "Epoch [17/50], Step [255/350], Avg Loss: 0.7426, Avg Dice: 0.4246\n",
            "Epoch [17/50], Step [260/350], Avg Loss: 0.7423, Avg Dice: 0.4240\n",
            "Epoch [17/50], Step [265/350], Avg Loss: 0.7426, Avg Dice: 0.4242\n",
            "Epoch [17/50], Step [270/350], Avg Loss: 0.7431, Avg Dice: 0.4243\n",
            "Epoch [17/50], Step [275/350], Avg Loss: 0.7430, Avg Dice: 0.4245\n",
            "Epoch [17/50], Step [280/350], Avg Loss: 0.7423, Avg Dice: 0.4239\n",
            "Epoch [17/50], Step [285/350], Avg Loss: 0.7427, Avg Dice: 0.4240\n",
            "Epoch [17/50], Step [290/350], Avg Loss: 0.7425, Avg Dice: 0.4242\n",
            "Epoch [17/50], Step [295/350], Avg Loss: 0.7432, Avg Dice: 0.4240\n",
            "Epoch [17/50], Step [300/350], Avg Loss: 0.7439, Avg Dice: 0.4240\n",
            "Epoch [17/50], Step [305/350], Avg Loss: 0.7446, Avg Dice: 0.4240\n",
            "Epoch [17/50], Step [310/350], Avg Loss: 0.7447, Avg Dice: 0.4237\n",
            "Epoch [17/50], Step [315/350], Avg Loss: 0.7450, Avg Dice: 0.4235\n",
            "Epoch [17/50], Step [320/350], Avg Loss: 0.7454, Avg Dice: 0.4236\n",
            "Epoch [17/50], Step [325/350], Avg Loss: 0.7454, Avg Dice: 0.4233\n",
            "Epoch [17/50], Step [330/350], Avg Loss: 0.7453, Avg Dice: 0.4233\n",
            "Epoch [17/50], Step [335/350], Avg Loss: 0.7450, Avg Dice: 0.4231\n",
            "Epoch [17/50], Step [340/350], Avg Loss: 0.7451, Avg Dice: 0.4231\n",
            "Epoch [17/50], Step [345/350], Avg Loss: 0.7444, Avg Dice: 0.4243\n",
            "Epoch [17/50], Step [350/350], Avg Loss: 0.7447, Avg Dice: 0.4251\n",
            "End of epoch 17: Avg Loss: 0.7447, Avg Dice: 0.4251\n",
            "Epoch [18/50], Step [5/350], Avg Loss: 0.7129, Avg Dice: 0.4226\n",
            "Epoch [18/50], Step [10/350], Avg Loss: 0.7171, Avg Dice: 0.4515\n",
            "Epoch [18/50], Step [15/350], Avg Loss: 0.7129, Avg Dice: 0.4644\n",
            "Epoch [18/50], Step [20/350], Avg Loss: 0.7027, Avg Dice: 0.4545\n",
            "Epoch [18/50], Step [25/350], Avg Loss: 0.7075, Avg Dice: 0.4477\n",
            "Epoch [18/50], Step [30/350], Avg Loss: 0.7119, Avg Dice: 0.4494\n",
            "Epoch [18/50], Step [35/350], Avg Loss: 0.7090, Avg Dice: 0.4457\n",
            "Epoch [18/50], Step [40/350], Avg Loss: 0.7140, Avg Dice: 0.4425\n",
            "Epoch [18/50], Step [45/350], Avg Loss: 0.7098, Avg Dice: 0.4409\n",
            "Epoch [18/50], Step [50/350], Avg Loss: 0.7079, Avg Dice: 0.4401\n",
            "Epoch [18/50], Step [55/350], Avg Loss: 0.7103, Avg Dice: 0.4392\n",
            "Epoch [18/50], Step [60/350], Avg Loss: 0.7099, Avg Dice: 0.4383\n",
            "Epoch [18/50], Step [65/350], Avg Loss: 0.7053, Avg Dice: 0.4358\n",
            "Epoch [18/50], Step [70/350], Avg Loss: 0.7066, Avg Dice: 0.4365\n",
            "Epoch [18/50], Step [75/350], Avg Loss: 0.7076, Avg Dice: 0.4349\n",
            "Epoch [18/50], Step [80/350], Avg Loss: 0.7079, Avg Dice: 0.4335\n",
            "Epoch [18/50], Step [85/350], Avg Loss: 0.7076, Avg Dice: 0.4322\n",
            "Epoch [18/50], Step [90/350], Avg Loss: 0.7082, Avg Dice: 0.4315\n",
            "Epoch [18/50], Step [95/350], Avg Loss: 0.7052, Avg Dice: 0.4326\n",
            "Epoch [18/50], Step [100/350], Avg Loss: 0.7064, Avg Dice: 0.4338\n",
            "Epoch [18/50], Step [105/350], Avg Loss: 0.7076, Avg Dice: 0.4362\n",
            "Epoch [18/50], Step [110/350], Avg Loss: 0.7090, Avg Dice: 0.4368\n",
            "Epoch [18/50], Step [115/350], Avg Loss: 0.7076, Avg Dice: 0.4374\n",
            "Epoch [18/50], Step [120/350], Avg Loss: 0.7092, Avg Dice: 0.4393\n",
            "Epoch [18/50], Step [125/350], Avg Loss: 0.7082, Avg Dice: 0.4411\n",
            "Epoch [18/50], Step [130/350], Avg Loss: 0.7092, Avg Dice: 0.4401\n",
            "Epoch [18/50], Step [135/350], Avg Loss: 0.7087, Avg Dice: 0.4391\n",
            "Epoch [18/50], Step [140/350], Avg Loss: 0.7090, Avg Dice: 0.4371\n",
            "Epoch [18/50], Step [145/350], Avg Loss: 0.7082, Avg Dice: 0.4362\n",
            "Epoch [18/50], Step [150/350], Avg Loss: 0.7087, Avg Dice: 0.4353\n",
            "Epoch [18/50], Step [155/350], Avg Loss: 0.7097, Avg Dice: 0.4345\n",
            "Epoch [18/50], Step [160/350], Avg Loss: 0.7106, Avg Dice: 0.4346\n",
            "Epoch [18/50], Step [165/350], Avg Loss: 0.7145, Avg Dice: 0.4337\n",
            "Epoch [18/50], Step [170/350], Avg Loss: 0.7154, Avg Dice: 0.4345\n",
            "Epoch [18/50], Step [175/350], Avg Loss: 0.7155, Avg Dice: 0.4338\n",
            "Epoch [18/50], Step [180/350], Avg Loss: 0.7165, Avg Dice: 0.4341\n",
            "Epoch [18/50], Step [185/350], Avg Loss: 0.7179, Avg Dice: 0.4339\n",
            "Epoch [18/50], Step [190/350], Avg Loss: 0.7167, Avg Dice: 0.4334\n",
            "Epoch [18/50], Step [195/350], Avg Loss: 0.7179, Avg Dice: 0.4320\n",
            "Epoch [18/50], Step [200/350], Avg Loss: 0.7196, Avg Dice: 0.4317\n",
            "Epoch [18/50], Step [205/350], Avg Loss: 0.7177, Avg Dice: 0.4323\n",
            "Epoch [18/50], Step [210/350], Avg Loss: 0.7168, Avg Dice: 0.4318\n",
            "Epoch [18/50], Step [215/350], Avg Loss: 0.7179, Avg Dice: 0.4308\n",
            "Epoch [18/50], Step [220/350], Avg Loss: 0.7174, Avg Dice: 0.4314\n",
            "Epoch [18/50], Step [225/350], Avg Loss: 0.7174, Avg Dice: 0.4312\n",
            "Epoch [18/50], Step [230/350], Avg Loss: 0.7169, Avg Dice: 0.4296\n",
            "Epoch [18/50], Step [235/350], Avg Loss: 0.7161, Avg Dice: 0.4295\n",
            "Epoch [18/50], Step [240/350], Avg Loss: 0.7178, Avg Dice: 0.4294\n",
            "Epoch [18/50], Step [245/350], Avg Loss: 0.7175, Avg Dice: 0.4289\n",
            "Epoch [18/50], Step [250/350], Avg Loss: 0.7177, Avg Dice: 0.4286\n",
            "Epoch [18/50], Step [255/350], Avg Loss: 0.7180, Avg Dice: 0.4280\n",
            "Epoch [18/50], Step [260/350], Avg Loss: 0.7183, Avg Dice: 0.4277\n",
            "Epoch [18/50], Step [265/350], Avg Loss: 0.7182, Avg Dice: 0.4272\n",
            "Epoch [18/50], Step [270/350], Avg Loss: 0.7181, Avg Dice: 0.4277\n",
            "Epoch [18/50], Step [275/350], Avg Loss: 0.7187, Avg Dice: 0.4274\n",
            "Epoch [18/50], Step [280/350], Avg Loss: 0.7203, Avg Dice: 0.4274\n",
            "Epoch [18/50], Step [285/350], Avg Loss: 0.7223, Avg Dice: 0.4275\n",
            "Epoch [18/50], Step [290/350], Avg Loss: 0.7234, Avg Dice: 0.4270\n",
            "Epoch [18/50], Step [295/350], Avg Loss: 0.7239, Avg Dice: 0.4273\n",
            "Epoch [18/50], Step [300/350], Avg Loss: 0.7246, Avg Dice: 0.4277\n",
            "Epoch [18/50], Step [305/350], Avg Loss: 0.7257, Avg Dice: 0.4275\n",
            "Epoch [18/50], Step [310/350], Avg Loss: 0.7254, Avg Dice: 0.4275\n",
            "Epoch [18/50], Step [315/350], Avg Loss: 0.7265, Avg Dice: 0.4278\n",
            "Epoch [18/50], Step [320/350], Avg Loss: 0.7263, Avg Dice: 0.4277\n",
            "Epoch [18/50], Step [325/350], Avg Loss: 0.7263, Avg Dice: 0.4275\n",
            "Epoch [18/50], Step [330/350], Avg Loss: 0.7261, Avg Dice: 0.4276\n",
            "Epoch [18/50], Step [335/350], Avg Loss: 0.7259, Avg Dice: 0.4275\n",
            "Epoch [18/50], Step [340/350], Avg Loss: 0.7260, Avg Dice: 0.4275\n",
            "Epoch [18/50], Step [345/350], Avg Loss: 0.7268, Avg Dice: 0.4269\n",
            "Epoch [18/50], Step [350/350], Avg Loss: 0.7260, Avg Dice: 0.4274\n",
            "End of epoch 18: Avg Loss: 0.7260, Avg Dice: 0.4274\n",
            "Epoch [19/50], Step [5/350], Avg Loss: 0.6910, Avg Dice: 0.3762\n",
            "Epoch [19/50], Step [10/350], Avg Loss: 0.6955, Avg Dice: 0.4285\n",
            "Epoch [19/50], Step [15/350], Avg Loss: 0.7021, Avg Dice: 0.4233\n",
            "Epoch [19/50], Step [20/350], Avg Loss: 0.7127, Avg Dice: 0.4265\n",
            "Epoch [19/50], Step [25/350], Avg Loss: 0.7079, Avg Dice: 0.4342\n",
            "Epoch [19/50], Step [30/350], Avg Loss: 0.7066, Avg Dice: 0.4340\n",
            "Epoch [19/50], Step [35/350], Avg Loss: 0.7049, Avg Dice: 0.4334\n",
            "Epoch [19/50], Step [40/350], Avg Loss: 0.7051, Avg Dice: 0.4379\n",
            "Epoch [19/50], Step [45/350], Avg Loss: 0.7052, Avg Dice: 0.4389\n",
            "Epoch [19/50], Step [50/350], Avg Loss: 0.7070, Avg Dice: 0.4419\n",
            "Epoch [19/50], Step [55/350], Avg Loss: 0.7090, Avg Dice: 0.4464\n",
            "Epoch [19/50], Step [60/350], Avg Loss: 0.7049, Avg Dice: 0.4462\n",
            "Epoch [19/50], Step [65/350], Avg Loss: 0.7045, Avg Dice: 0.4456\n",
            "Epoch [19/50], Step [70/350], Avg Loss: 0.7018, Avg Dice: 0.4449\n",
            "Epoch [19/50], Step [75/350], Avg Loss: 0.7028, Avg Dice: 0.4489\n",
            "Epoch [19/50], Step [80/350], Avg Loss: 0.7028, Avg Dice: 0.4489\n",
            "Epoch [19/50], Step [85/350], Avg Loss: 0.7038, Avg Dice: 0.4503\n",
            "Epoch [19/50], Step [90/350], Avg Loss: 0.7020, Avg Dice: 0.4511\n",
            "Epoch [19/50], Step [95/350], Avg Loss: 0.7043, Avg Dice: 0.4476\n",
            "Epoch [19/50], Step [100/350], Avg Loss: 0.7014, Avg Dice: 0.4473\n",
            "Epoch [19/50], Step [105/350], Avg Loss: 0.7014, Avg Dice: 0.4442\n",
            "Epoch [19/50], Step [110/350], Avg Loss: 0.7042, Avg Dice: 0.4438\n",
            "Epoch [19/50], Step [115/350], Avg Loss: 0.7047, Avg Dice: 0.4427\n",
            "Epoch [19/50], Step [120/350], Avg Loss: 0.7065, Avg Dice: 0.4413\n",
            "Epoch [19/50], Step [125/350], Avg Loss: 0.7073, Avg Dice: 0.4414\n",
            "Epoch [19/50], Step [130/350], Avg Loss: 0.7079, Avg Dice: 0.4400\n",
            "Epoch [19/50], Step [135/350], Avg Loss: 0.7047, Avg Dice: 0.4410\n",
            "Epoch [19/50], Step [140/350], Avg Loss: 0.7054, Avg Dice: 0.4394\n",
            "Epoch [19/50], Step [145/350], Avg Loss: 0.7049, Avg Dice: 0.4384\n",
            "Epoch [19/50], Step [150/350], Avg Loss: 0.7041, Avg Dice: 0.4395\n",
            "Epoch [19/50], Step [155/350], Avg Loss: 0.7037, Avg Dice: 0.4398\n",
            "Epoch [19/50], Step [160/350], Avg Loss: 0.7044, Avg Dice: 0.4399\n",
            "Epoch [19/50], Step [165/350], Avg Loss: 0.7057, Avg Dice: 0.4401\n",
            "Epoch [19/50], Step [170/350], Avg Loss: 0.7063, Avg Dice: 0.4392\n",
            "Epoch [19/50], Step [175/350], Avg Loss: 0.7065, Avg Dice: 0.4389\n",
            "Epoch [19/50], Step [180/350], Avg Loss: 0.7077, Avg Dice: 0.4388\n",
            "Epoch [19/50], Step [185/350], Avg Loss: 0.7074, Avg Dice: 0.4387\n",
            "Epoch [19/50], Step [190/350], Avg Loss: 0.7075, Avg Dice: 0.4371\n",
            "Epoch [19/50], Step [195/350], Avg Loss: 0.7081, Avg Dice: 0.4362\n",
            "Epoch [19/50], Step [200/350], Avg Loss: 0.7085, Avg Dice: 0.4355\n",
            "Epoch [19/50], Step [205/350], Avg Loss: 0.7084, Avg Dice: 0.4355\n",
            "Epoch [19/50], Step [210/350], Avg Loss: 0.7087, Avg Dice: 0.4365\n",
            "Epoch [19/50], Step [215/350], Avg Loss: 0.7083, Avg Dice: 0.4364\n",
            "Epoch [19/50], Step [220/350], Avg Loss: 0.7087, Avg Dice: 0.4357\n",
            "Epoch [19/50], Step [225/350], Avg Loss: 0.7084, Avg Dice: 0.4360\n",
            "Epoch [19/50], Step [230/350], Avg Loss: 0.7082, Avg Dice: 0.4352\n",
            "Epoch [19/50], Step [235/350], Avg Loss: 0.7090, Avg Dice: 0.4354\n",
            "Epoch [19/50], Step [240/350], Avg Loss: 0.7100, Avg Dice: 0.4345\n",
            "Epoch [19/50], Step [245/350], Avg Loss: 0.7104, Avg Dice: 0.4344\n",
            "Epoch [19/50], Step [250/350], Avg Loss: 0.7088, Avg Dice: 0.4341\n",
            "Epoch [19/50], Step [255/350], Avg Loss: 0.7097, Avg Dice: 0.4345\n",
            "Epoch [19/50], Step [260/350], Avg Loss: 0.7092, Avg Dice: 0.4349\n",
            "Epoch [19/50], Step [265/350], Avg Loss: 0.7097, Avg Dice: 0.4343\n",
            "Epoch [19/50], Step [270/350], Avg Loss: 0.7093, Avg Dice: 0.4338\n",
            "Epoch [19/50], Step [275/350], Avg Loss: 0.7104, Avg Dice: 0.4341\n",
            "Epoch [19/50], Step [280/350], Avg Loss: 0.7103, Avg Dice: 0.4342\n",
            "Epoch [19/50], Step [285/350], Avg Loss: 0.7109, Avg Dice: 0.4341\n",
            "Epoch [19/50], Step [290/350], Avg Loss: 0.7103, Avg Dice: 0.4346\n",
            "Epoch [19/50], Step [295/350], Avg Loss: 0.7109, Avg Dice: 0.4350\n",
            "Epoch [19/50], Step [300/350], Avg Loss: 0.7104, Avg Dice: 0.4344\n",
            "Epoch [19/50], Step [305/350], Avg Loss: 0.7109, Avg Dice: 0.4344\n",
            "Epoch [19/50], Step [310/350], Avg Loss: 0.7114, Avg Dice: 0.4346\n",
            "Epoch [19/50], Step [315/350], Avg Loss: 0.7104, Avg Dice: 0.4351\n",
            "Epoch [19/50], Step [320/350], Avg Loss: 0.7108, Avg Dice: 0.4349\n",
            "Epoch [19/50], Step [325/350], Avg Loss: 0.7111, Avg Dice: 0.4348\n",
            "Epoch [19/50], Step [330/350], Avg Loss: 0.7112, Avg Dice: 0.4347\n",
            "Epoch [19/50], Step [335/350], Avg Loss: 0.7111, Avg Dice: 0.4345\n",
            "Epoch [19/50], Step [340/350], Avg Loss: 0.7120, Avg Dice: 0.4346\n",
            "Epoch [19/50], Step [345/350], Avg Loss: 0.7119, Avg Dice: 0.4346\n",
            "Epoch [19/50], Step [350/350], Avg Loss: 0.7121, Avg Dice: 0.4344\n",
            "End of epoch 19: Avg Loss: 0.7121, Avg Dice: 0.4344\n",
            "Epoch [20/50], Step [5/350], Avg Loss: 0.6781, Avg Dice: 0.4597\n",
            "Epoch [20/50], Step [10/350], Avg Loss: 0.6544, Avg Dice: 0.4616\n",
            "Epoch [20/50], Step [15/350], Avg Loss: 0.6750, Avg Dice: 0.4583\n",
            "Epoch [20/50], Step [20/350], Avg Loss: 0.6809, Avg Dice: 0.4604\n",
            "Epoch [20/50], Step [25/350], Avg Loss: 0.6847, Avg Dice: 0.4534\n",
            "Epoch [20/50], Step [30/350], Avg Loss: 0.6954, Avg Dice: 0.4526\n",
            "Epoch [20/50], Step [35/350], Avg Loss: 0.6901, Avg Dice: 0.4508\n",
            "Epoch [20/50], Step [40/350], Avg Loss: 0.6845, Avg Dice: 0.4500\n",
            "Epoch [20/50], Step [45/350], Avg Loss: 0.6826, Avg Dice: 0.4499\n",
            "Epoch [20/50], Step [50/350], Avg Loss: 0.6806, Avg Dice: 0.4497\n",
            "Epoch [20/50], Step [55/350], Avg Loss: 0.6843, Avg Dice: 0.4462\n",
            "Epoch [20/50], Step [60/350], Avg Loss: 0.6822, Avg Dice: 0.4498\n",
            "Epoch [20/50], Step [65/350], Avg Loss: 0.6831, Avg Dice: 0.4483\n",
            "Epoch [20/50], Step [70/350], Avg Loss: 0.6862, Avg Dice: 0.4461\n",
            "Epoch [20/50], Step [75/350], Avg Loss: 0.6880, Avg Dice: 0.4450\n",
            "Epoch [20/50], Step [80/350], Avg Loss: 0.6891, Avg Dice: 0.4427\n",
            "Epoch [20/50], Step [85/350], Avg Loss: 0.6886, Avg Dice: 0.4413\n",
            "Epoch [20/50], Step [90/350], Avg Loss: 0.6920, Avg Dice: 0.4379\n",
            "Epoch [20/50], Step [95/350], Avg Loss: 0.6929, Avg Dice: 0.4364\n",
            "Epoch [20/50], Step [100/350], Avg Loss: 0.6906, Avg Dice: 0.4373\n",
            "Epoch [20/50], Step [105/350], Avg Loss: 0.6907, Avg Dice: 0.4379\n",
            "Epoch [20/50], Step [110/350], Avg Loss: 0.6901, Avg Dice: 0.4378\n",
            "Epoch [20/50], Step [115/350], Avg Loss: 0.6897, Avg Dice: 0.4388\n",
            "Epoch [20/50], Step [120/350], Avg Loss: 0.6930, Avg Dice: 0.4364\n",
            "Epoch [20/50], Step [125/350], Avg Loss: 0.6951, Avg Dice: 0.4365\n",
            "Epoch [20/50], Step [130/350], Avg Loss: 0.6969, Avg Dice: 0.4390\n",
            "Epoch [20/50], Step [135/350], Avg Loss: 0.6962, Avg Dice: 0.4390\n",
            "Epoch [20/50], Step [140/350], Avg Loss: 0.6942, Avg Dice: 0.4416\n",
            "Epoch [20/50], Step [145/350], Avg Loss: 0.6936, Avg Dice: 0.4423\n",
            "Epoch [20/50], Step [150/350], Avg Loss: 0.6928, Avg Dice: 0.4435\n",
            "Epoch [20/50], Step [155/350], Avg Loss: 0.6923, Avg Dice: 0.4427\n",
            "Epoch [20/50], Step [160/350], Avg Loss: 0.6918, Avg Dice: 0.4436\n",
            "Epoch [20/50], Step [165/350], Avg Loss: 0.6901, Avg Dice: 0.4451\n",
            "Epoch [20/50], Step [170/350], Avg Loss: 0.6903, Avg Dice: 0.4446\n",
            "Epoch [20/50], Step [175/350], Avg Loss: 0.6905, Avg Dice: 0.4451\n",
            "Epoch [20/50], Step [180/350], Avg Loss: 0.6917, Avg Dice: 0.4436\n",
            "Epoch [20/50], Step [185/350], Avg Loss: 0.6922, Avg Dice: 0.4433\n",
            "Epoch [20/50], Step [190/350], Avg Loss: 0.6936, Avg Dice: 0.4429\n",
            "Epoch [20/50], Step [195/350], Avg Loss: 0.6942, Avg Dice: 0.4440\n",
            "Epoch [20/50], Step [200/350], Avg Loss: 0.6950, Avg Dice: 0.4444\n",
            "Epoch [20/50], Step [205/350], Avg Loss: 0.6941, Avg Dice: 0.4430\n",
            "Epoch [20/50], Step [210/350], Avg Loss: 0.6950, Avg Dice: 0.4430\n",
            "Epoch [20/50], Step [215/350], Avg Loss: 0.6942, Avg Dice: 0.4423\n",
            "Epoch [20/50], Step [220/350], Avg Loss: 0.6953, Avg Dice: 0.4432\n",
            "Epoch [20/50], Step [225/350], Avg Loss: 0.6956, Avg Dice: 0.4439\n",
            "Epoch [20/50], Step [230/350], Avg Loss: 0.6966, Avg Dice: 0.4440\n",
            "Epoch [20/50], Step [235/350], Avg Loss: 0.6965, Avg Dice: 0.4436\n",
            "Epoch [20/50], Step [240/350], Avg Loss: 0.6957, Avg Dice: 0.4430\n",
            "Epoch [20/50], Step [245/350], Avg Loss: 0.6977, Avg Dice: 0.4429\n",
            "Epoch [20/50], Step [250/350], Avg Loss: 0.6979, Avg Dice: 0.4431\n",
            "Epoch [20/50], Step [255/350], Avg Loss: 0.6983, Avg Dice: 0.4424\n",
            "Epoch [20/50], Step [260/350], Avg Loss: 0.6983, Avg Dice: 0.4419\n",
            "Epoch [20/50], Step [265/350], Avg Loss: 0.6976, Avg Dice: 0.4417\n",
            "Epoch [20/50], Step [270/350], Avg Loss: 0.6978, Avg Dice: 0.4421\n",
            "Epoch [20/50], Step [275/350], Avg Loss: 0.6977, Avg Dice: 0.4418\n",
            "Epoch [20/50], Step [280/350], Avg Loss: 0.6978, Avg Dice: 0.4412\n",
            "Epoch [20/50], Step [285/350], Avg Loss: 0.6976, Avg Dice: 0.4415\n",
            "Epoch [20/50], Step [290/350], Avg Loss: 0.6975, Avg Dice: 0.4416\n",
            "Epoch [20/50], Step [295/350], Avg Loss: 0.6974, Avg Dice: 0.4414\n",
            "Epoch [20/50], Step [300/350], Avg Loss: 0.6976, Avg Dice: 0.4416\n",
            "Epoch [20/50], Step [305/350], Avg Loss: 0.6974, Avg Dice: 0.4405\n",
            "Epoch [20/50], Step [310/350], Avg Loss: 0.6981, Avg Dice: 0.4401\n",
            "Epoch [20/50], Step [315/350], Avg Loss: 0.6977, Avg Dice: 0.4401\n",
            "Epoch [20/50], Step [320/350], Avg Loss: 0.6981, Avg Dice: 0.4398\n",
            "Epoch [20/50], Step [325/350], Avg Loss: 0.6986, Avg Dice: 0.4401\n",
            "Epoch [20/50], Step [330/350], Avg Loss: 0.6986, Avg Dice: 0.4396\n",
            "Epoch [20/50], Step [335/350], Avg Loss: 0.6985, Avg Dice: 0.4393\n",
            "Epoch [20/50], Step [340/350], Avg Loss: 0.6981, Avg Dice: 0.4396\n",
            "Epoch [20/50], Step [345/350], Avg Loss: 0.6977, Avg Dice: 0.4400\n",
            "Epoch [20/50], Step [350/350], Avg Loss: 0.6978, Avg Dice: 0.4396\n",
            "End of epoch 20: Avg Loss: 0.6978, Avg Dice: 0.4396\n",
            "Epoch [21/50], Step [5/350], Avg Loss: 0.6497, Avg Dice: 0.4363\n",
            "Epoch [21/50], Step [10/350], Avg Loss: 0.6525, Avg Dice: 0.4522\n",
            "Epoch [21/50], Step [15/350], Avg Loss: 0.6643, Avg Dice: 0.4544\n",
            "Epoch [21/50], Step [20/350], Avg Loss: 0.6564, Avg Dice: 0.4469\n",
            "Epoch [21/50], Step [25/350], Avg Loss: 0.6648, Avg Dice: 0.4560\n",
            "Epoch [21/50], Step [30/350], Avg Loss: 0.6770, Avg Dice: 0.4520\n",
            "Epoch [21/50], Step [35/350], Avg Loss: 0.6788, Avg Dice: 0.4524\n",
            "Epoch [21/50], Step [40/350], Avg Loss: 0.6813, Avg Dice: 0.4448\n",
            "Epoch [21/50], Step [45/350], Avg Loss: 0.6796, Avg Dice: 0.4454\n",
            "Epoch [21/50], Step [50/350], Avg Loss: 0.6814, Avg Dice: 0.4393\n",
            "Epoch [21/50], Step [55/350], Avg Loss: 0.6800, Avg Dice: 0.4391\n",
            "Epoch [21/50], Step [60/350], Avg Loss: 0.6775, Avg Dice: 0.4396\n",
            "Epoch [21/50], Step [65/350], Avg Loss: 0.6807, Avg Dice: 0.4394\n",
            "Epoch [21/50], Step [70/350], Avg Loss: 0.6786, Avg Dice: 0.4394\n",
            "Epoch [21/50], Step [75/350], Avg Loss: 0.6784, Avg Dice: 0.4402\n",
            "Epoch [21/50], Step [80/350], Avg Loss: 0.6807, Avg Dice: 0.4405\n",
            "Epoch [21/50], Step [85/350], Avg Loss: 0.6803, Avg Dice: 0.4422\n",
            "Epoch [21/50], Step [90/350], Avg Loss: 0.6816, Avg Dice: 0.4413\n",
            "Epoch [21/50], Step [95/350], Avg Loss: 0.6821, Avg Dice: 0.4418\n",
            "Epoch [21/50], Step [100/350], Avg Loss: 0.6806, Avg Dice: 0.4415\n",
            "Epoch [21/50], Step [105/350], Avg Loss: 0.6785, Avg Dice: 0.4423\n",
            "Epoch [21/50], Step [110/350], Avg Loss: 0.6793, Avg Dice: 0.4420\n",
            "Epoch [21/50], Step [115/350], Avg Loss: 0.6779, Avg Dice: 0.4434\n",
            "Epoch [21/50], Step [120/350], Avg Loss: 0.6780, Avg Dice: 0.4437\n",
            "Epoch [21/50], Step [125/350], Avg Loss: 0.6781, Avg Dice: 0.4432\n",
            "Epoch [21/50], Step [130/350], Avg Loss: 0.6762, Avg Dice: 0.4425\n",
            "Epoch [21/50], Step [135/350], Avg Loss: 0.6756, Avg Dice: 0.4424\n",
            "Epoch [21/50], Step [140/350], Avg Loss: 0.6777, Avg Dice: 0.4414\n",
            "Epoch [21/50], Step [145/350], Avg Loss: 0.6780, Avg Dice: 0.4428\n",
            "Epoch [21/50], Step [150/350], Avg Loss: 0.6760, Avg Dice: 0.4421\n",
            "Epoch [21/50], Step [155/350], Avg Loss: 0.6755, Avg Dice: 0.4416\n",
            "Epoch [21/50], Step [160/350], Avg Loss: 0.6762, Avg Dice: 0.4420\n",
            "Epoch [21/50], Step [165/350], Avg Loss: 0.6774, Avg Dice: 0.4410\n",
            "Epoch [21/50], Step [170/350], Avg Loss: 0.6778, Avg Dice: 0.4410\n",
            "Epoch [21/50], Step [175/350], Avg Loss: 0.6791, Avg Dice: 0.4411\n",
            "Epoch [21/50], Step [180/350], Avg Loss: 0.6797, Avg Dice: 0.4407\n",
            "Epoch [21/50], Step [185/350], Avg Loss: 0.6793, Avg Dice: 0.4402\n",
            "Epoch [21/50], Step [190/350], Avg Loss: 0.6796, Avg Dice: 0.4406\n",
            "Epoch [21/50], Step [195/350], Avg Loss: 0.6803, Avg Dice: 0.4411\n",
            "Epoch [21/50], Step [200/350], Avg Loss: 0.6798, Avg Dice: 0.4417\n",
            "Epoch [21/50], Step [205/350], Avg Loss: 0.6798, Avg Dice: 0.4413\n",
            "Epoch [21/50], Step [210/350], Avg Loss: 0.6790, Avg Dice: 0.4417\n",
            "Epoch [21/50], Step [215/350], Avg Loss: 0.6780, Avg Dice: 0.4411\n",
            "Epoch [21/50], Step [220/350], Avg Loss: 0.6786, Avg Dice: 0.4416\n",
            "Epoch [21/50], Step [225/350], Avg Loss: 0.6784, Avg Dice: 0.4421\n",
            "Epoch [21/50], Step [230/350], Avg Loss: 0.6778, Avg Dice: 0.4434\n",
            "Epoch [21/50], Step [235/350], Avg Loss: 0.6785, Avg Dice: 0.4435\n",
            "Epoch [21/50], Step [240/350], Avg Loss: 0.6784, Avg Dice: 0.4440\n",
            "Epoch [21/50], Step [245/350], Avg Loss: 0.6787, Avg Dice: 0.4434\n",
            "Epoch [21/50], Step [250/350], Avg Loss: 0.6792, Avg Dice: 0.4432\n",
            "Epoch [21/50], Step [255/350], Avg Loss: 0.6797, Avg Dice: 0.4426\n",
            "Epoch [21/50], Step [260/350], Avg Loss: 0.6796, Avg Dice: 0.4418\n",
            "Epoch [21/50], Step [265/350], Avg Loss: 0.6801, Avg Dice: 0.4422\n",
            "Epoch [21/50], Step [270/350], Avg Loss: 0.6807, Avg Dice: 0.4421\n",
            "Epoch [21/50], Step [275/350], Avg Loss: 0.6807, Avg Dice: 0.4423\n",
            "Epoch [21/50], Step [280/350], Avg Loss: 0.6807, Avg Dice: 0.4415\n",
            "Epoch [21/50], Step [285/350], Avg Loss: 0.6807, Avg Dice: 0.4409\n",
            "Epoch [21/50], Step [290/350], Avg Loss: 0.6802, Avg Dice: 0.4411\n",
            "Epoch [21/50], Step [295/350], Avg Loss: 0.6799, Avg Dice: 0.4416\n",
            "Epoch [21/50], Step [300/350], Avg Loss: 0.6798, Avg Dice: 0.4407\n",
            "Epoch [21/50], Step [305/350], Avg Loss: 0.6806, Avg Dice: 0.4406\n",
            "Epoch [21/50], Step [310/350], Avg Loss: 0.6802, Avg Dice: 0.4410\n",
            "Epoch [21/50], Step [315/350], Avg Loss: 0.6811, Avg Dice: 0.4416\n",
            "Epoch [21/50], Step [320/350], Avg Loss: 0.6812, Avg Dice: 0.4415\n",
            "Epoch [21/50], Step [325/350], Avg Loss: 0.6816, Avg Dice: 0.4417\n",
            "Epoch [21/50], Step [330/350], Avg Loss: 0.6823, Avg Dice: 0.4412\n",
            "Epoch [21/50], Step [335/350], Avg Loss: 0.6822, Avg Dice: 0.4412\n",
            "Epoch [21/50], Step [340/350], Avg Loss: 0.6823, Avg Dice: 0.4412\n",
            "Epoch [21/50], Step [345/350], Avg Loss: 0.6822, Avg Dice: 0.4410\n",
            "Epoch [21/50], Step [350/350], Avg Loss: 0.6820, Avg Dice: 0.4420\n",
            "End of epoch 21: Avg Loss: 0.6820, Avg Dice: 0.4420\n",
            "Epoch [22/50], Step [5/350], Avg Loss: 0.6674, Avg Dice: 0.4471\n",
            "Epoch [22/50], Step [10/350], Avg Loss: 0.6618, Avg Dice: 0.4675\n",
            "Epoch [22/50], Step [15/350], Avg Loss: 0.6538, Avg Dice: 0.4670\n",
            "Epoch [22/50], Step [20/350], Avg Loss: 0.6549, Avg Dice: 0.4527\n",
            "Epoch [22/50], Step [25/350], Avg Loss: 0.6543, Avg Dice: 0.4530\n",
            "Epoch [22/50], Step [30/350], Avg Loss: 0.6555, Avg Dice: 0.4495\n",
            "Epoch [22/50], Step [35/350], Avg Loss: 0.6560, Avg Dice: 0.4461\n",
            "Epoch [22/50], Step [40/350], Avg Loss: 0.6563, Avg Dice: 0.4471\n",
            "Epoch [22/50], Step [45/350], Avg Loss: 0.6558, Avg Dice: 0.4433\n",
            "Epoch [22/50], Step [50/350], Avg Loss: 0.6558, Avg Dice: 0.4398\n",
            "Epoch [22/50], Step [55/350], Avg Loss: 0.6614, Avg Dice: 0.4430\n",
            "Epoch [22/50], Step [60/350], Avg Loss: 0.6612, Avg Dice: 0.4474\n",
            "Epoch [22/50], Step [65/350], Avg Loss: 0.6580, Avg Dice: 0.4485\n",
            "Epoch [22/50], Step [70/350], Avg Loss: 0.6573, Avg Dice: 0.4478\n",
            "Epoch [22/50], Step [75/350], Avg Loss: 0.6582, Avg Dice: 0.4503\n",
            "Epoch [22/50], Step [80/350], Avg Loss: 0.6553, Avg Dice: 0.4492\n",
            "Epoch [22/50], Step [85/350], Avg Loss: 0.6513, Avg Dice: 0.4497\n",
            "Epoch [22/50], Step [90/350], Avg Loss: 0.6517, Avg Dice: 0.4505\n",
            "Epoch [22/50], Step [95/350], Avg Loss: 0.6534, Avg Dice: 0.4482\n",
            "Epoch [22/50], Step [100/350], Avg Loss: 0.6519, Avg Dice: 0.4481\n",
            "Epoch [22/50], Step [105/350], Avg Loss: 0.6515, Avg Dice: 0.4498\n",
            "Epoch [22/50], Step [110/350], Avg Loss: 0.6525, Avg Dice: 0.4487\n",
            "Epoch [22/50], Step [115/350], Avg Loss: 0.6536, Avg Dice: 0.4479\n",
            "Epoch [22/50], Step [120/350], Avg Loss: 0.6550, Avg Dice: 0.4485\n",
            "Epoch [22/50], Step [125/350], Avg Loss: 0.6562, Avg Dice: 0.4490\n",
            "Epoch [22/50], Step [130/350], Avg Loss: 0.6564, Avg Dice: 0.4487\n",
            "Epoch [22/50], Step [135/350], Avg Loss: 0.6567, Avg Dice: 0.4491\n",
            "Epoch [22/50], Step [140/350], Avg Loss: 0.6583, Avg Dice: 0.4481\n",
            "Epoch [22/50], Step [145/350], Avg Loss: 0.6565, Avg Dice: 0.4483\n",
            "Epoch [22/50], Step [150/350], Avg Loss: 0.6572, Avg Dice: 0.4485\n",
            "Epoch [22/50], Step [155/350], Avg Loss: 0.6568, Avg Dice: 0.4482\n",
            "Epoch [22/50], Step [160/350], Avg Loss: 0.6563, Avg Dice: 0.4485\n",
            "Epoch [22/50], Step [165/350], Avg Loss: 0.6572, Avg Dice: 0.4497\n",
            "Epoch [22/50], Step [170/350], Avg Loss: 0.6573, Avg Dice: 0.4512\n",
            "Epoch [22/50], Step [175/350], Avg Loss: 0.6588, Avg Dice: 0.4511\n",
            "Epoch [22/50], Step [180/350], Avg Loss: 0.6579, Avg Dice: 0.4507\n",
            "Epoch [22/50], Step [185/350], Avg Loss: 0.6603, Avg Dice: 0.4492\n",
            "Epoch [22/50], Step [190/350], Avg Loss: 0.6607, Avg Dice: 0.4496\n",
            "Epoch [22/50], Step [195/350], Avg Loss: 0.6608, Avg Dice: 0.4486\n",
            "Epoch [22/50], Step [200/350], Avg Loss: 0.6615, Avg Dice: 0.4503\n",
            "Epoch [22/50], Step [205/350], Avg Loss: 0.6618, Avg Dice: 0.4498\n",
            "Epoch [22/50], Step [210/350], Avg Loss: 0.6623, Avg Dice: 0.4497\n",
            "Epoch [22/50], Step [215/350], Avg Loss: 0.6626, Avg Dice: 0.4497\n",
            "Epoch [22/50], Step [220/350], Avg Loss: 0.6621, Avg Dice: 0.4506\n",
            "Epoch [22/50], Step [225/350], Avg Loss: 0.6624, Avg Dice: 0.4506\n",
            "Epoch [22/50], Step [230/350], Avg Loss: 0.6625, Avg Dice: 0.4511\n",
            "Epoch [22/50], Step [235/350], Avg Loss: 0.6627, Avg Dice: 0.4500\n",
            "Epoch [22/50], Step [240/350], Avg Loss: 0.6632, Avg Dice: 0.4500\n",
            "Epoch [22/50], Step [245/350], Avg Loss: 0.6632, Avg Dice: 0.4494\n",
            "Epoch [22/50], Step [250/350], Avg Loss: 0.6619, Avg Dice: 0.4488\n",
            "Epoch [22/50], Step [255/350], Avg Loss: 0.6614, Avg Dice: 0.4485\n",
            "Epoch [22/50], Step [260/350], Avg Loss: 0.6615, Avg Dice: 0.4486\n",
            "Epoch [22/50], Step [265/350], Avg Loss: 0.6628, Avg Dice: 0.4487\n",
            "Epoch [22/50], Step [270/350], Avg Loss: 0.6626, Avg Dice: 0.4494\n",
            "Epoch [22/50], Step [275/350], Avg Loss: 0.6631, Avg Dice: 0.4492\n",
            "Epoch [22/50], Step [280/350], Avg Loss: 0.6632, Avg Dice: 0.4492\n",
            "Epoch [22/50], Step [285/350], Avg Loss: 0.6631, Avg Dice: 0.4490\n",
            "Epoch [22/50], Step [290/350], Avg Loss: 0.6641, Avg Dice: 0.4489\n",
            "Epoch [22/50], Step [295/350], Avg Loss: 0.6643, Avg Dice: 0.4481\n",
            "Epoch [22/50], Step [300/350], Avg Loss: 0.6637, Avg Dice: 0.4485\n",
            "Epoch [22/50], Step [305/350], Avg Loss: 0.6634, Avg Dice: 0.4488\n",
            "Epoch [22/50], Step [310/350], Avg Loss: 0.6636, Avg Dice: 0.4490\n",
            "Epoch [22/50], Step [315/350], Avg Loss: 0.6642, Avg Dice: 0.4492\n",
            "Epoch [22/50], Step [320/350], Avg Loss: 0.6648, Avg Dice: 0.4496\n",
            "Epoch [22/50], Step [325/350], Avg Loss: 0.6651, Avg Dice: 0.4495\n",
            "Epoch [22/50], Step [330/350], Avg Loss: 0.6647, Avg Dice: 0.4494\n",
            "Epoch [22/50], Step [335/350], Avg Loss: 0.6647, Avg Dice: 0.4499\n",
            "Epoch [22/50], Step [340/350], Avg Loss: 0.6655, Avg Dice: 0.4499\n",
            "Epoch [22/50], Step [345/350], Avg Loss: 0.6655, Avg Dice: 0.4501\n",
            "Epoch [22/50], Step [350/350], Avg Loss: 0.6663, Avg Dice: 0.4505\n",
            "End of epoch 22: Avg Loss: 0.6663, Avg Dice: 0.4505\n",
            "Epoch [23/50], Step [5/350], Avg Loss: 0.6379, Avg Dice: 0.4201\n",
            "Epoch [23/50], Step [10/350], Avg Loss: 0.6837, Avg Dice: 0.4319\n",
            "Epoch [23/50], Step [15/350], Avg Loss: 0.6857, Avg Dice: 0.4415\n",
            "Epoch [23/50], Step [20/350], Avg Loss: 0.6859, Avg Dice: 0.4385\n",
            "Epoch [23/50], Step [25/350], Avg Loss: 0.6720, Avg Dice: 0.4504\n",
            "Epoch [23/50], Step [30/350], Avg Loss: 0.6736, Avg Dice: 0.4431\n",
            "Epoch [23/50], Step [35/350], Avg Loss: 0.6720, Avg Dice: 0.4409\n",
            "Epoch [23/50], Step [40/350], Avg Loss: 0.6743, Avg Dice: 0.4425\n",
            "Epoch [23/50], Step [45/350], Avg Loss: 0.6710, Avg Dice: 0.4457\n",
            "Epoch [23/50], Step [50/350], Avg Loss: 0.6696, Avg Dice: 0.4440\n",
            "Epoch [23/50], Step [55/350], Avg Loss: 0.6665, Avg Dice: 0.4464\n",
            "Epoch [23/50], Step [60/350], Avg Loss: 0.6594, Avg Dice: 0.4520\n",
            "Epoch [23/50], Step [65/350], Avg Loss: 0.6577, Avg Dice: 0.4537\n",
            "Epoch [23/50], Step [70/350], Avg Loss: 0.6582, Avg Dice: 0.4560\n",
            "Epoch [23/50], Step [75/350], Avg Loss: 0.6555, Avg Dice: 0.4574\n",
            "Epoch [23/50], Step [80/350], Avg Loss: 0.6575, Avg Dice: 0.4570\n",
            "Epoch [23/50], Step [85/350], Avg Loss: 0.6560, Avg Dice: 0.4555\n",
            "Epoch [23/50], Step [90/350], Avg Loss: 0.6559, Avg Dice: 0.4545\n",
            "Epoch [23/50], Step [95/350], Avg Loss: 0.6556, Avg Dice: 0.4556\n",
            "Epoch [23/50], Step [100/350], Avg Loss: 0.6536, Avg Dice: 0.4545\n",
            "Epoch [23/50], Step [105/350], Avg Loss: 0.6541, Avg Dice: 0.4550\n",
            "Epoch [23/50], Step [110/350], Avg Loss: 0.6541, Avg Dice: 0.4552\n",
            "Epoch [23/50], Step [115/350], Avg Loss: 0.6547, Avg Dice: 0.4549\n",
            "Epoch [23/50], Step [120/350], Avg Loss: 0.6554, Avg Dice: 0.4558\n",
            "Epoch [23/50], Step [125/350], Avg Loss: 0.6551, Avg Dice: 0.4565\n",
            "Epoch [23/50], Step [130/350], Avg Loss: 0.6539, Avg Dice: 0.4565\n",
            "Epoch [23/50], Step [135/350], Avg Loss: 0.6529, Avg Dice: 0.4566\n",
            "Epoch [23/50], Step [140/350], Avg Loss: 0.6521, Avg Dice: 0.4569\n",
            "Epoch [23/50], Step [145/350], Avg Loss: 0.6520, Avg Dice: 0.4574\n",
            "Epoch [23/50], Step [150/350], Avg Loss: 0.6522, Avg Dice: 0.4575\n",
            "Epoch [23/50], Step [155/350], Avg Loss: 0.6522, Avg Dice: 0.4575\n",
            "Epoch [23/50], Step [160/350], Avg Loss: 0.6518, Avg Dice: 0.4574\n",
            "Epoch [23/50], Step [165/350], Avg Loss: 0.6501, Avg Dice: 0.4583\n",
            "Epoch [23/50], Step [170/350], Avg Loss: 0.6503, Avg Dice: 0.4598\n",
            "Epoch [23/50], Step [175/350], Avg Loss: 0.6504, Avg Dice: 0.4601\n",
            "Epoch [23/50], Step [180/350], Avg Loss: 0.6513, Avg Dice: 0.4601\n",
            "Epoch [23/50], Step [185/350], Avg Loss: 0.6507, Avg Dice: 0.4600\n",
            "Epoch [23/50], Step [190/350], Avg Loss: 0.6505, Avg Dice: 0.4599\n",
            "Epoch [23/50], Step [195/350], Avg Loss: 0.6512, Avg Dice: 0.4587\n",
            "Epoch [23/50], Step [200/350], Avg Loss: 0.6518, Avg Dice: 0.4582\n",
            "Epoch [23/50], Step [205/350], Avg Loss: 0.6525, Avg Dice: 0.4575\n",
            "Epoch [23/50], Step [210/350], Avg Loss: 0.6551, Avg Dice: 0.4570\n",
            "Epoch [23/50], Step [215/350], Avg Loss: 0.6550, Avg Dice: 0.4575\n",
            "Epoch [23/50], Step [220/350], Avg Loss: 0.6550, Avg Dice: 0.4573\n",
            "Epoch [23/50], Step [225/350], Avg Loss: 0.6544, Avg Dice: 0.4571\n",
            "Epoch [23/50], Step [230/350], Avg Loss: 0.6550, Avg Dice: 0.4564\n",
            "Epoch [23/50], Step [235/350], Avg Loss: 0.6553, Avg Dice: 0.4563\n",
            "Epoch [23/50], Step [240/350], Avg Loss: 0.6543, Avg Dice: 0.4572\n",
            "Epoch [23/50], Step [245/350], Avg Loss: 0.6536, Avg Dice: 0.4576\n",
            "Epoch [23/50], Step [250/350], Avg Loss: 0.6530, Avg Dice: 0.4568\n",
            "Epoch [23/50], Step [255/350], Avg Loss: 0.6530, Avg Dice: 0.4573\n",
            "Epoch [23/50], Step [260/350], Avg Loss: 0.6527, Avg Dice: 0.4571\n",
            "Epoch [23/50], Step [265/350], Avg Loss: 0.6527, Avg Dice: 0.4564\n",
            "Epoch [23/50], Step [270/350], Avg Loss: 0.6534, Avg Dice: 0.4566\n",
            "Epoch [23/50], Step [275/350], Avg Loss: 0.6531, Avg Dice: 0.4563\n",
            "Epoch [23/50], Step [280/350], Avg Loss: 0.6531, Avg Dice: 0.4567\n",
            "Epoch [23/50], Step [285/350], Avg Loss: 0.6529, Avg Dice: 0.4576\n",
            "Epoch [23/50], Step [290/350], Avg Loss: 0.6529, Avg Dice: 0.4580\n",
            "Epoch [23/50], Step [295/350], Avg Loss: 0.6534, Avg Dice: 0.4573\n",
            "Epoch [23/50], Step [300/350], Avg Loss: 0.6531, Avg Dice: 0.4574\n",
            "Epoch [23/50], Step [305/350], Avg Loss: 0.6536, Avg Dice: 0.4570\n",
            "Epoch [23/50], Step [310/350], Avg Loss: 0.6546, Avg Dice: 0.4559\n",
            "Epoch [23/50], Step [315/350], Avg Loss: 0.6544, Avg Dice: 0.4566\n",
            "Epoch [23/50], Step [320/350], Avg Loss: 0.6539, Avg Dice: 0.4563\n",
            "Epoch [23/50], Step [325/350], Avg Loss: 0.6546, Avg Dice: 0.4562\n",
            "Epoch [23/50], Step [330/350], Avg Loss: 0.6548, Avg Dice: 0.4564\n",
            "Epoch [23/50], Step [335/350], Avg Loss: 0.6550, Avg Dice: 0.4564\n",
            "Epoch [23/50], Step [340/350], Avg Loss: 0.6549, Avg Dice: 0.4566\n",
            "Epoch [23/50], Step [345/350], Avg Loss: 0.6554, Avg Dice: 0.4567\n",
            "Epoch [23/50], Step [350/350], Avg Loss: 0.6553, Avg Dice: 0.4564\n",
            "End of epoch 23: Avg Loss: 0.6553, Avg Dice: 0.4564\n",
            "Epoch [24/50], Step [5/350], Avg Loss: 0.6012, Avg Dice: 0.4378\n",
            "Epoch [24/50], Step [10/350], Avg Loss: 0.6258, Avg Dice: 0.4531\n",
            "Epoch [24/50], Step [15/350], Avg Loss: 0.6370, Avg Dice: 0.4599\n",
            "Epoch [24/50], Step [20/350], Avg Loss: 0.6411, Avg Dice: 0.4577\n",
            "Epoch [24/50], Step [25/350], Avg Loss: 0.6445, Avg Dice: 0.4594\n",
            "Epoch [24/50], Step [30/350], Avg Loss: 0.6518, Avg Dice: 0.4567\n",
            "Epoch [24/50], Step [35/350], Avg Loss: 0.6539, Avg Dice: 0.4529\n",
            "Epoch [24/50], Step [40/350], Avg Loss: 0.6540, Avg Dice: 0.4530\n",
            "Epoch [24/50], Step [45/350], Avg Loss: 0.6513, Avg Dice: 0.4512\n",
            "Epoch [24/50], Step [50/350], Avg Loss: 0.6456, Avg Dice: 0.4555\n",
            "Epoch [24/50], Step [55/350], Avg Loss: 0.6436, Avg Dice: 0.4557\n",
            "Epoch [24/50], Step [60/350], Avg Loss: 0.6427, Avg Dice: 0.4575\n",
            "Epoch [24/50], Step [65/350], Avg Loss: 0.6453, Avg Dice: 0.4609\n",
            "Epoch [24/50], Step [70/350], Avg Loss: 0.6437, Avg Dice: 0.4639\n",
            "Epoch [24/50], Step [75/350], Avg Loss: 0.6428, Avg Dice: 0.4646\n",
            "Epoch [24/50], Step [80/350], Avg Loss: 0.6421, Avg Dice: 0.4659\n",
            "Epoch [24/50], Step [85/350], Avg Loss: 0.6419, Avg Dice: 0.4665\n",
            "Epoch [24/50], Step [90/350], Avg Loss: 0.6408, Avg Dice: 0.4652\n",
            "Epoch [24/50], Step [95/350], Avg Loss: 0.6387, Avg Dice: 0.4668\n",
            "Epoch [24/50], Step [100/350], Avg Loss: 0.6381, Avg Dice: 0.4686\n",
            "Epoch [24/50], Step [105/350], Avg Loss: 0.6395, Avg Dice: 0.4674\n",
            "Epoch [24/50], Step [110/350], Avg Loss: 0.6381, Avg Dice: 0.4665\n",
            "Epoch [24/50], Step [115/350], Avg Loss: 0.6394, Avg Dice: 0.4665\n",
            "Epoch [24/50], Step [120/350], Avg Loss: 0.6394, Avg Dice: 0.4664\n",
            "Epoch [24/50], Step [125/350], Avg Loss: 0.6417, Avg Dice: 0.4660\n",
            "Epoch [24/50], Step [130/350], Avg Loss: 0.6412, Avg Dice: 0.4649\n",
            "Epoch [24/50], Step [135/350], Avg Loss: 0.6412, Avg Dice: 0.4645\n",
            "Epoch [24/50], Step [140/350], Avg Loss: 0.6407, Avg Dice: 0.4632\n",
            "Epoch [24/50], Step [145/350], Avg Loss: 0.6398, Avg Dice: 0.4633\n",
            "Epoch [24/50], Step [150/350], Avg Loss: 0.6390, Avg Dice: 0.4628\n",
            "Epoch [24/50], Step [155/350], Avg Loss: 0.6418, Avg Dice: 0.4617\n",
            "Epoch [24/50], Step [160/350], Avg Loss: 0.6419, Avg Dice: 0.4615\n",
            "Epoch [24/50], Step [165/350], Avg Loss: 0.6420, Avg Dice: 0.4613\n",
            "Epoch [24/50], Step [170/350], Avg Loss: 0.6413, Avg Dice: 0.4624\n",
            "Epoch [24/50], Step [175/350], Avg Loss: 0.6414, Avg Dice: 0.4615\n",
            "Epoch [24/50], Step [180/350], Avg Loss: 0.6411, Avg Dice: 0.4622\n",
            "Epoch [24/50], Step [185/350], Avg Loss: 0.6402, Avg Dice: 0.4625\n",
            "Epoch [24/50], Step [190/350], Avg Loss: 0.6393, Avg Dice: 0.4623\n",
            "Epoch [24/50], Step [195/350], Avg Loss: 0.6385, Avg Dice: 0.4627\n",
            "Epoch [24/50], Step [200/350], Avg Loss: 0.6390, Avg Dice: 0.4621\n",
            "Epoch [24/50], Step [205/350], Avg Loss: 0.6387, Avg Dice: 0.4612\n",
            "Epoch [24/50], Step [210/350], Avg Loss: 0.6385, Avg Dice: 0.4606\n",
            "Epoch [24/50], Step [215/350], Avg Loss: 0.6385, Avg Dice: 0.4612\n",
            "Epoch [24/50], Step [220/350], Avg Loss: 0.6381, Avg Dice: 0.4609\n",
            "Epoch [24/50], Step [225/350], Avg Loss: 0.6380, Avg Dice: 0.4608\n",
            "Epoch [24/50], Step [230/350], Avg Loss: 0.6387, Avg Dice: 0.4605\n",
            "Epoch [24/50], Step [235/350], Avg Loss: 0.6390, Avg Dice: 0.4614\n",
            "Epoch [24/50], Step [240/350], Avg Loss: 0.6385, Avg Dice: 0.4609\n",
            "Epoch [24/50], Step [245/350], Avg Loss: 0.6377, Avg Dice: 0.4600\n",
            "Epoch [24/50], Step [250/350], Avg Loss: 0.6369, Avg Dice: 0.4598\n",
            "Epoch [24/50], Step [255/350], Avg Loss: 0.6372, Avg Dice: 0.4602\n",
            "Epoch [24/50], Step [260/350], Avg Loss: 0.6374, Avg Dice: 0.4602\n",
            "Epoch [24/50], Step [265/350], Avg Loss: 0.6373, Avg Dice: 0.4607\n",
            "Epoch [24/50], Step [270/350], Avg Loss: 0.6380, Avg Dice: 0.4602\n",
            "Epoch [24/50], Step [275/350], Avg Loss: 0.6378, Avg Dice: 0.4605\n",
            "Epoch [24/50], Step [280/350], Avg Loss: 0.6378, Avg Dice: 0.4595\n",
            "Epoch [24/50], Step [285/350], Avg Loss: 0.6380, Avg Dice: 0.4586\n",
            "Epoch [24/50], Step [290/350], Avg Loss: 0.6384, Avg Dice: 0.4584\n",
            "Epoch [24/50], Step [295/350], Avg Loss: 0.6393, Avg Dice: 0.4591\n",
            "Epoch [24/50], Step [300/350], Avg Loss: 0.6393, Avg Dice: 0.4592\n",
            "Epoch [24/50], Step [305/350], Avg Loss: 0.6395, Avg Dice: 0.4598\n",
            "Epoch [24/50], Step [310/350], Avg Loss: 0.6391, Avg Dice: 0.4596\n",
            "Epoch [24/50], Step [315/350], Avg Loss: 0.6395, Avg Dice: 0.4596\n",
            "Epoch [24/50], Step [320/350], Avg Loss: 0.6396, Avg Dice: 0.4588\n",
            "Epoch [24/50], Step [325/350], Avg Loss: 0.6395, Avg Dice: 0.4585\n",
            "Epoch [24/50], Step [330/350], Avg Loss: 0.6398, Avg Dice: 0.4587\n",
            "Epoch [24/50], Step [335/350], Avg Loss: 0.6399, Avg Dice: 0.4591\n",
            "Epoch [24/50], Step [340/350], Avg Loss: 0.6407, Avg Dice: 0.4591\n",
            "Epoch [24/50], Step [345/350], Avg Loss: 0.6410, Avg Dice: 0.4591\n",
            "Epoch [24/50], Step [350/350], Avg Loss: 0.6415, Avg Dice: 0.4592\n",
            "End of epoch 24: Avg Loss: 0.6415, Avg Dice: 0.4592\n",
            "Epoch [25/50], Step [5/350], Avg Loss: 0.5931, Avg Dice: 0.4605\n",
            "Epoch [25/50], Step [10/350], Avg Loss: 0.5901, Avg Dice: 0.4586\n",
            "Epoch [25/50], Step [15/350], Avg Loss: 0.6102, Avg Dice: 0.4551\n",
            "Epoch [25/50], Step [20/350], Avg Loss: 0.6123, Avg Dice: 0.4564\n",
            "Epoch [25/50], Step [25/350], Avg Loss: 0.6196, Avg Dice: 0.4635\n",
            "Epoch [25/50], Step [30/350], Avg Loss: 0.6156, Avg Dice: 0.4633\n",
            "Epoch [25/50], Step [35/350], Avg Loss: 0.6134, Avg Dice: 0.4647\n",
            "Epoch [25/50], Step [40/350], Avg Loss: 0.6205, Avg Dice: 0.4664\n",
            "Epoch [25/50], Step [45/350], Avg Loss: 0.6202, Avg Dice: 0.4692\n",
            "Epoch [25/50], Step [50/350], Avg Loss: 0.6219, Avg Dice: 0.4709\n",
            "Epoch [25/50], Step [55/350], Avg Loss: 0.6226, Avg Dice: 0.4722\n",
            "Epoch [25/50], Step [60/350], Avg Loss: 0.6256, Avg Dice: 0.4739\n",
            "Epoch [25/50], Step [65/350], Avg Loss: 0.6276, Avg Dice: 0.4696\n",
            "Epoch [25/50], Step [70/350], Avg Loss: 0.6278, Avg Dice: 0.4666\n",
            "Epoch [25/50], Step [75/350], Avg Loss: 0.6248, Avg Dice: 0.4655\n",
            "Epoch [25/50], Step [80/350], Avg Loss: 0.6240, Avg Dice: 0.4654\n",
            "Epoch [25/50], Step [85/350], Avg Loss: 0.6255, Avg Dice: 0.4651\n",
            "Epoch [25/50], Step [90/350], Avg Loss: 0.6239, Avg Dice: 0.4666\n",
            "Epoch [25/50], Step [95/350], Avg Loss: 0.6231, Avg Dice: 0.4679\n",
            "Epoch [25/50], Step [100/350], Avg Loss: 0.6257, Avg Dice: 0.4650\n",
            "Epoch [25/50], Step [105/350], Avg Loss: 0.6253, Avg Dice: 0.4655\n",
            "Epoch [25/50], Step [110/350], Avg Loss: 0.6250, Avg Dice: 0.4656\n",
            "Epoch [25/50], Step [115/350], Avg Loss: 0.6265, Avg Dice: 0.4644\n",
            "Epoch [25/50], Step [120/350], Avg Loss: 0.6251, Avg Dice: 0.4636\n",
            "Epoch [25/50], Step [125/350], Avg Loss: 0.6264, Avg Dice: 0.4641\n",
            "Epoch [25/50], Step [130/350], Avg Loss: 0.6267, Avg Dice: 0.4643\n",
            "Epoch [25/50], Step [135/350], Avg Loss: 0.6258, Avg Dice: 0.4634\n",
            "Epoch [25/50], Step [140/350], Avg Loss: 0.6266, Avg Dice: 0.4631\n",
            "Epoch [25/50], Step [145/350], Avg Loss: 0.6266, Avg Dice: 0.4636\n",
            "Epoch [25/50], Step [150/350], Avg Loss: 0.6262, Avg Dice: 0.4641\n",
            "Epoch [25/50], Step [155/350], Avg Loss: 0.6245, Avg Dice: 0.4644\n",
            "Epoch [25/50], Step [160/350], Avg Loss: 0.6226, Avg Dice: 0.4654\n",
            "Epoch [25/50], Step [165/350], Avg Loss: 0.6227, Avg Dice: 0.4655\n",
            "Epoch [25/50], Step [170/350], Avg Loss: 0.6238, Avg Dice: 0.4648\n",
            "Epoch [25/50], Step [175/350], Avg Loss: 0.6238, Avg Dice: 0.4653\n",
            "Epoch [25/50], Step [180/350], Avg Loss: 0.6239, Avg Dice: 0.4651\n",
            "Epoch [25/50], Step [185/350], Avg Loss: 0.6242, Avg Dice: 0.4659\n",
            "Epoch [25/50], Step [190/350], Avg Loss: 0.6245, Avg Dice: 0.4661\n",
            "Epoch [25/50], Step [195/350], Avg Loss: 0.6247, Avg Dice: 0.4662\n",
            "Epoch [25/50], Step [200/350], Avg Loss: 0.6266, Avg Dice: 0.4658\n",
            "Epoch [25/50], Step [205/350], Avg Loss: 0.6262, Avg Dice: 0.4672\n",
            "Epoch [25/50], Step [210/350], Avg Loss: 0.6266, Avg Dice: 0.4672\n",
            "Epoch [25/50], Step [215/350], Avg Loss: 0.6262, Avg Dice: 0.4669\n",
            "Epoch [25/50], Step [220/350], Avg Loss: 0.6257, Avg Dice: 0.4663\n",
            "Epoch [25/50], Step [225/350], Avg Loss: 0.6258, Avg Dice: 0.4664\n",
            "Epoch [25/50], Step [230/350], Avg Loss: 0.6260, Avg Dice: 0.4666\n",
            "Epoch [25/50], Step [235/350], Avg Loss: 0.6262, Avg Dice: 0.4658\n",
            "Epoch [25/50], Step [240/350], Avg Loss: 0.6264, Avg Dice: 0.4663\n",
            "Epoch [25/50], Step [245/350], Avg Loss: 0.6258, Avg Dice: 0.4665\n",
            "Epoch [25/50], Step [250/350], Avg Loss: 0.6254, Avg Dice: 0.4663\n",
            "Epoch [25/50], Step [255/350], Avg Loss: 0.6251, Avg Dice: 0.4663\n",
            "Epoch [25/50], Step [260/350], Avg Loss: 0.6257, Avg Dice: 0.4661\n",
            "Epoch [25/50], Step [265/350], Avg Loss: 0.6259, Avg Dice: 0.4670\n",
            "Epoch [25/50], Step [270/350], Avg Loss: 0.6267, Avg Dice: 0.4667\n",
            "Epoch [25/50], Step [275/350], Avg Loss: 0.6280, Avg Dice: 0.4657\n",
            "Epoch [25/50], Step [280/350], Avg Loss: 0.6285, Avg Dice: 0.4658\n",
            "Epoch [25/50], Step [285/350], Avg Loss: 0.6275, Avg Dice: 0.4660\n",
            "Epoch [25/50], Step [290/350], Avg Loss: 0.6277, Avg Dice: 0.4658\n",
            "Epoch [25/50], Step [295/350], Avg Loss: 0.6272, Avg Dice: 0.4651\n",
            "Epoch [25/50], Step [300/350], Avg Loss: 0.6284, Avg Dice: 0.4646\n",
            "Epoch [25/50], Step [305/350], Avg Loss: 0.6283, Avg Dice: 0.4645\n",
            "Epoch [25/50], Step [310/350], Avg Loss: 0.6283, Avg Dice: 0.4642\n",
            "Epoch [25/50], Step [315/350], Avg Loss: 0.6281, Avg Dice: 0.4637\n",
            "Epoch [25/50], Step [320/350], Avg Loss: 0.6286, Avg Dice: 0.4631\n",
            "Epoch [25/50], Step [325/350], Avg Loss: 0.6285, Avg Dice: 0.4630\n",
            "Epoch [25/50], Step [330/350], Avg Loss: 0.6284, Avg Dice: 0.4630\n",
            "Epoch [25/50], Step [335/350], Avg Loss: 0.6278, Avg Dice: 0.4636\n",
            "Epoch [25/50], Step [340/350], Avg Loss: 0.6278, Avg Dice: 0.4637\n",
            "Epoch [25/50], Step [345/350], Avg Loss: 0.6291, Avg Dice: 0.4640\n",
            "Epoch [25/50], Step [350/350], Avg Loss: 0.6291, Avg Dice: 0.4642\n",
            "End of epoch 25: Avg Loss: 0.6291, Avg Dice: 0.4642\n",
            "Epoch [26/50], Step [5/350], Avg Loss: 0.6250, Avg Dice: 0.4682\n",
            "Epoch [26/50], Step [10/350], Avg Loss: 0.6122, Avg Dice: 0.4643\n",
            "Epoch [26/50], Step [15/350], Avg Loss: 0.6029, Avg Dice: 0.4721\n",
            "Epoch [26/50], Step [20/350], Avg Loss: 0.6000, Avg Dice: 0.4831\n",
            "Epoch [26/50], Step [25/350], Avg Loss: 0.6013, Avg Dice: 0.4819\n",
            "Epoch [26/50], Step [30/350], Avg Loss: 0.5996, Avg Dice: 0.4770\n",
            "Epoch [26/50], Step [35/350], Avg Loss: 0.5998, Avg Dice: 0.4823\n",
            "Epoch [26/50], Step [40/350], Avg Loss: 0.5990, Avg Dice: 0.4817\n",
            "Epoch [26/50], Step [45/350], Avg Loss: 0.6020, Avg Dice: 0.4791\n",
            "Epoch [26/50], Step [50/350], Avg Loss: 0.6049, Avg Dice: 0.4785\n",
            "Epoch [26/50], Step [55/350], Avg Loss: 0.6068, Avg Dice: 0.4754\n",
            "Epoch [26/50], Step [60/350], Avg Loss: 0.6078, Avg Dice: 0.4751\n",
            "Epoch [26/50], Step [65/350], Avg Loss: 0.6061, Avg Dice: 0.4725\n",
            "Epoch [26/50], Step [70/350], Avg Loss: 0.6054, Avg Dice: 0.4738\n",
            "Epoch [26/50], Step [75/350], Avg Loss: 0.6048, Avg Dice: 0.4743\n",
            "Epoch [26/50], Step [80/350], Avg Loss: 0.6056, Avg Dice: 0.4735\n",
            "Epoch [26/50], Step [85/350], Avg Loss: 0.6042, Avg Dice: 0.4725\n",
            "Epoch [26/50], Step [90/350], Avg Loss: 0.6049, Avg Dice: 0.4734\n",
            "Epoch [26/50], Step [95/350], Avg Loss: 0.6045, Avg Dice: 0.4722\n",
            "Epoch [26/50], Step [100/350], Avg Loss: 0.6046, Avg Dice: 0.4718\n",
            "Epoch [26/50], Step [105/350], Avg Loss: 0.6053, Avg Dice: 0.4718\n",
            "Epoch [26/50], Step [110/350], Avg Loss: 0.6053, Avg Dice: 0.4720\n",
            "Epoch [26/50], Step [115/350], Avg Loss: 0.6047, Avg Dice: 0.4718\n",
            "Epoch [26/50], Step [120/350], Avg Loss: 0.6035, Avg Dice: 0.4732\n",
            "Epoch [26/50], Step [125/350], Avg Loss: 0.6032, Avg Dice: 0.4730\n",
            "Epoch [26/50], Step [130/350], Avg Loss: 0.6045, Avg Dice: 0.4727\n",
            "Epoch [26/50], Step [135/350], Avg Loss: 0.6052, Avg Dice: 0.4722\n",
            "Epoch [26/50], Step [140/350], Avg Loss: 0.6051, Avg Dice: 0.4722\n",
            "Epoch [26/50], Step [145/350], Avg Loss: 0.6051, Avg Dice: 0.4723\n",
            "Epoch [26/50], Step [150/350], Avg Loss: 0.6041, Avg Dice: 0.4728\n",
            "Epoch [26/50], Step [155/350], Avg Loss: 0.6038, Avg Dice: 0.4724\n",
            "Epoch [26/50], Step [160/350], Avg Loss: 0.6046, Avg Dice: 0.4705\n",
            "Epoch [26/50], Step [165/350], Avg Loss: 0.6065, Avg Dice: 0.4684\n",
            "Epoch [26/50], Step [170/350], Avg Loss: 0.6069, Avg Dice: 0.4683\n",
            "Epoch [26/50], Step [175/350], Avg Loss: 0.6072, Avg Dice: 0.4698\n",
            "Epoch [26/50], Step [180/350], Avg Loss: 0.6076, Avg Dice: 0.4699\n",
            "Epoch [26/50], Step [185/350], Avg Loss: 0.6083, Avg Dice: 0.4702\n",
            "Epoch [26/50], Step [190/350], Avg Loss: 0.6092, Avg Dice: 0.4698\n",
            "Epoch [26/50], Step [195/350], Avg Loss: 0.6088, Avg Dice: 0.4693\n",
            "Epoch [26/50], Step [200/350], Avg Loss: 0.6097, Avg Dice: 0.4696\n",
            "Epoch [26/50], Step [205/350], Avg Loss: 0.6101, Avg Dice: 0.4692\n",
            "Epoch [26/50], Step [210/350], Avg Loss: 0.6104, Avg Dice: 0.4695\n",
            "Epoch [26/50], Step [215/350], Avg Loss: 0.6108, Avg Dice: 0.4695\n",
            "Epoch [26/50], Step [220/350], Avg Loss: 0.6120, Avg Dice: 0.4694\n",
            "Epoch [26/50], Step [225/350], Avg Loss: 0.6120, Avg Dice: 0.4699\n",
            "Epoch [26/50], Step [230/350], Avg Loss: 0.6113, Avg Dice: 0.4694\n",
            "Epoch [26/50], Step [235/350], Avg Loss: 0.6109, Avg Dice: 0.4690\n",
            "Epoch [26/50], Step [240/350], Avg Loss: 0.6116, Avg Dice: 0.4694\n",
            "Epoch [26/50], Step [245/350], Avg Loss: 0.6124, Avg Dice: 0.4689\n",
            "Epoch [26/50], Step [250/350], Avg Loss: 0.6132, Avg Dice: 0.4690\n",
            "Epoch [26/50], Step [255/350], Avg Loss: 0.6125, Avg Dice: 0.4697\n",
            "Epoch [26/50], Step [260/350], Avg Loss: 0.6122, Avg Dice: 0.4699\n",
            "Epoch [26/50], Step [265/350], Avg Loss: 0.6126, Avg Dice: 0.4698\n",
            "Epoch [26/50], Step [270/350], Avg Loss: 0.6122, Avg Dice: 0.4706\n",
            "Epoch [26/50], Step [275/350], Avg Loss: 0.6118, Avg Dice: 0.4715\n",
            "Epoch [26/50], Step [280/350], Avg Loss: 0.6128, Avg Dice: 0.4713\n",
            "Epoch [26/50], Step [285/350], Avg Loss: 0.6124, Avg Dice: 0.4707\n",
            "Epoch [26/50], Step [290/350], Avg Loss: 0.6129, Avg Dice: 0.4703\n",
            "Epoch [26/50], Step [295/350], Avg Loss: 0.6127, Avg Dice: 0.4710\n",
            "Epoch [26/50], Step [300/350], Avg Loss: 0.6135, Avg Dice: 0.4711\n",
            "Epoch [26/50], Step [305/350], Avg Loss: 0.6142, Avg Dice: 0.4708\n",
            "Epoch [26/50], Step [310/350], Avg Loss: 0.6146, Avg Dice: 0.4709\n",
            "Epoch [26/50], Step [315/350], Avg Loss: 0.6150, Avg Dice: 0.4706\n",
            "Epoch [26/50], Step [320/350], Avg Loss: 0.6146, Avg Dice: 0.4702\n",
            "Epoch [26/50], Step [325/350], Avg Loss: 0.6143, Avg Dice: 0.4702\n",
            "Epoch [26/50], Step [330/350], Avg Loss: 0.6147, Avg Dice: 0.4701\n",
            "Epoch [26/50], Step [335/350], Avg Loss: 0.6148, Avg Dice: 0.4696\n",
            "Epoch [26/50], Step [340/350], Avg Loss: 0.6149, Avg Dice: 0.4694\n",
            "Epoch [26/50], Step [345/350], Avg Loss: 0.6151, Avg Dice: 0.4692\n",
            "Epoch [26/50], Step [350/350], Avg Loss: 0.6158, Avg Dice: 0.4685\n",
            "End of epoch 26: Avg Loss: 0.6158, Avg Dice: 0.4685\n",
            "Epoch [27/50], Step [5/350], Avg Loss: 0.5302, Avg Dice: 0.4555\n",
            "Epoch [27/50], Step [10/350], Avg Loss: 0.5547, Avg Dice: 0.4767\n",
            "Epoch [27/50], Step [15/350], Avg Loss: 0.5654, Avg Dice: 0.4646\n",
            "Epoch [27/50], Step [20/350], Avg Loss: 0.5665, Avg Dice: 0.4746\n",
            "Epoch [27/50], Step [25/350], Avg Loss: 0.5767, Avg Dice: 0.4748\n",
            "Epoch [27/50], Step [30/350], Avg Loss: 0.5825, Avg Dice: 0.4693\n",
            "Epoch [27/50], Step [35/350], Avg Loss: 0.5808, Avg Dice: 0.4791\n",
            "Epoch [27/50], Step [40/350], Avg Loss: 0.5799, Avg Dice: 0.4801\n",
            "Epoch [27/50], Step [45/350], Avg Loss: 0.5795, Avg Dice: 0.4809\n",
            "Epoch [27/50], Step [50/350], Avg Loss: 0.5816, Avg Dice: 0.4795\n",
            "Epoch [27/50], Step [55/350], Avg Loss: 0.5864, Avg Dice: 0.4771\n",
            "Epoch [27/50], Step [60/350], Avg Loss: 0.5888, Avg Dice: 0.4761\n",
            "Epoch [27/50], Step [65/350], Avg Loss: 0.5882, Avg Dice: 0.4761\n",
            "Epoch [27/50], Step [70/350], Avg Loss: 0.5874, Avg Dice: 0.4789\n",
            "Epoch [27/50], Step [75/350], Avg Loss: 0.5878, Avg Dice: 0.4810\n",
            "Epoch [27/50], Step [80/350], Avg Loss: 0.5887, Avg Dice: 0.4799\n",
            "Epoch [27/50], Step [85/350], Avg Loss: 0.5874, Avg Dice: 0.4809\n",
            "Epoch [27/50], Step [90/350], Avg Loss: 0.5865, Avg Dice: 0.4796\n",
            "Epoch [27/50], Step [95/350], Avg Loss: 0.5867, Avg Dice: 0.4820\n",
            "Epoch [27/50], Step [100/350], Avg Loss: 0.5897, Avg Dice: 0.4816\n",
            "Epoch [27/50], Step [105/350], Avg Loss: 0.5905, Avg Dice: 0.4810\n",
            "Epoch [27/50], Step [110/350], Avg Loss: 0.5919, Avg Dice: 0.4823\n",
            "Epoch [27/50], Step [115/350], Avg Loss: 0.5925, Avg Dice: 0.4831\n",
            "Epoch [27/50], Step [120/350], Avg Loss: 0.5932, Avg Dice: 0.4839\n",
            "Epoch [27/50], Step [125/350], Avg Loss: 0.5930, Avg Dice: 0.4830\n",
            "Epoch [27/50], Step [130/350], Avg Loss: 0.5929, Avg Dice: 0.4834\n",
            "Epoch [27/50], Step [135/350], Avg Loss: 0.5948, Avg Dice: 0.4811\n",
            "Epoch [27/50], Step [140/350], Avg Loss: 0.5961, Avg Dice: 0.4835\n",
            "Epoch [27/50], Step [145/350], Avg Loss: 0.5969, Avg Dice: 0.4849\n",
            "Epoch [27/50], Step [150/350], Avg Loss: 0.5966, Avg Dice: 0.4848\n",
            "Epoch [27/50], Step [155/350], Avg Loss: 0.5983, Avg Dice: 0.4842\n",
            "Epoch [27/50], Step [160/350], Avg Loss: 0.5998, Avg Dice: 0.4843\n",
            "Epoch [27/50], Step [165/350], Avg Loss: 0.5991, Avg Dice: 0.4861\n",
            "Epoch [27/50], Step [170/350], Avg Loss: 0.5982, Avg Dice: 0.4858\n",
            "Epoch [27/50], Step [175/350], Avg Loss: 0.5996, Avg Dice: 0.4849\n",
            "Epoch [27/50], Step [180/350], Avg Loss: 0.5999, Avg Dice: 0.4845\n",
            "Epoch [27/50], Step [185/350], Avg Loss: 0.6001, Avg Dice: 0.4847\n",
            "Epoch [27/50], Step [190/350], Avg Loss: 0.6014, Avg Dice: 0.4845\n",
            "Epoch [27/50], Step [195/350], Avg Loss: 0.6022, Avg Dice: 0.4831\n",
            "Epoch [27/50], Step [200/350], Avg Loss: 0.6036, Avg Dice: 0.4831\n",
            "Epoch [27/50], Step [205/350], Avg Loss: 0.6025, Avg Dice: 0.4820\n",
            "Epoch [27/50], Step [210/350], Avg Loss: 0.6027, Avg Dice: 0.4833\n",
            "Epoch [27/50], Step [215/350], Avg Loss: 0.6034, Avg Dice: 0.4823\n",
            "Epoch [27/50], Step [220/350], Avg Loss: 0.6042, Avg Dice: 0.4819\n",
            "Epoch [27/50], Step [225/350], Avg Loss: 0.6037, Avg Dice: 0.4822\n",
            "Epoch [27/50], Step [230/350], Avg Loss: 0.6045, Avg Dice: 0.4826\n",
            "Epoch [27/50], Step [235/350], Avg Loss: 0.6052, Avg Dice: 0.4822\n",
            "Epoch [27/50], Step [240/350], Avg Loss: 0.6057, Avg Dice: 0.4808\n",
            "Epoch [27/50], Step [245/350], Avg Loss: 0.6050, Avg Dice: 0.4805\n",
            "Epoch [27/50], Step [250/350], Avg Loss: 0.6053, Avg Dice: 0.4801\n",
            "Epoch [27/50], Step [255/350], Avg Loss: 0.6053, Avg Dice: 0.4799\n",
            "Epoch [27/50], Step [260/350], Avg Loss: 0.6064, Avg Dice: 0.4800\n",
            "Epoch [27/50], Step [265/350], Avg Loss: 0.6062, Avg Dice: 0.4806\n",
            "Epoch [27/50], Step [270/350], Avg Loss: 0.6062, Avg Dice: 0.4795\n",
            "Epoch [27/50], Step [275/350], Avg Loss: 0.6070, Avg Dice: 0.4790\n",
            "Epoch [27/50], Step [280/350], Avg Loss: 0.6069, Avg Dice: 0.4798\n",
            "Epoch [27/50], Step [285/350], Avg Loss: 0.6066, Avg Dice: 0.4796\n",
            "Epoch [27/50], Step [290/350], Avg Loss: 0.6061, Avg Dice: 0.4794\n",
            "Epoch [27/50], Step [295/350], Avg Loss: 0.6065, Avg Dice: 0.4787\n",
            "Epoch [27/50], Step [300/350], Avg Loss: 0.6063, Avg Dice: 0.4779\n",
            "Epoch [27/50], Step [305/350], Avg Loss: 0.6070, Avg Dice: 0.4773\n",
            "Epoch [27/50], Step [310/350], Avg Loss: 0.6065, Avg Dice: 0.4781\n",
            "Epoch [27/50], Step [315/350], Avg Loss: 0.6065, Avg Dice: 0.4777\n",
            "Epoch [27/50], Step [320/350], Avg Loss: 0.6069, Avg Dice: 0.4777\n",
            "Epoch [27/50], Step [325/350], Avg Loss: 0.6068, Avg Dice: 0.4781\n",
            "Epoch [27/50], Step [330/350], Avg Loss: 0.6069, Avg Dice: 0.4782\n",
            "Epoch [27/50], Step [335/350], Avg Loss: 0.6071, Avg Dice: 0.4780\n",
            "Epoch [27/50], Step [340/350], Avg Loss: 0.6072, Avg Dice: 0.4780\n",
            "Epoch [27/50], Step [345/350], Avg Loss: 0.6074, Avg Dice: 0.4777\n",
            "Epoch [27/50], Step [350/350], Avg Loss: 0.6075, Avg Dice: 0.4772\n",
            "End of epoch 27: Avg Loss: 0.6075, Avg Dice: 0.4772\n",
            "Epoch [28/50], Step [5/350], Avg Loss: 0.6103, Avg Dice: 0.4703\n",
            "Epoch [28/50], Step [10/350], Avg Loss: 0.5966, Avg Dice: 0.4586\n",
            "Epoch [28/50], Step [15/350], Avg Loss: 0.5846, Avg Dice: 0.4722\n",
            "Epoch [28/50], Step [20/350], Avg Loss: 0.5787, Avg Dice: 0.4806\n",
            "Epoch [28/50], Step [25/350], Avg Loss: 0.5840, Avg Dice: 0.4747\n",
            "Epoch [28/50], Step [30/350], Avg Loss: 0.5870, Avg Dice: 0.4717\n",
            "Epoch [28/50], Step [35/350], Avg Loss: 0.5853, Avg Dice: 0.4754\n",
            "Epoch [28/50], Step [40/350], Avg Loss: 0.5907, Avg Dice: 0.4757\n",
            "Epoch [28/50], Step [45/350], Avg Loss: 0.5865, Avg Dice: 0.4819\n",
            "Epoch [28/50], Step [50/350], Avg Loss: 0.5869, Avg Dice: 0.4814\n",
            "Epoch [28/50], Step [55/350], Avg Loss: 0.5913, Avg Dice: 0.4812\n",
            "Epoch [28/50], Step [60/350], Avg Loss: 0.5914, Avg Dice: 0.4828\n",
            "Epoch [28/50], Step [65/350], Avg Loss: 0.5923, Avg Dice: 0.4813\n",
            "Epoch [28/50], Step [70/350], Avg Loss: 0.5947, Avg Dice: 0.4812\n",
            "Epoch [28/50], Step [75/350], Avg Loss: 0.5960, Avg Dice: 0.4788\n",
            "Epoch [28/50], Step [80/350], Avg Loss: 0.5963, Avg Dice: 0.4789\n",
            "Epoch [28/50], Step [85/350], Avg Loss: 0.5959, Avg Dice: 0.4796\n",
            "Epoch [28/50], Step [90/350], Avg Loss: 0.5961, Avg Dice: 0.4783\n",
            "Epoch [28/50], Step [95/350], Avg Loss: 0.5982, Avg Dice: 0.4759\n",
            "Epoch [28/50], Step [100/350], Avg Loss: 0.5991, Avg Dice: 0.4745\n",
            "Epoch [28/50], Step [105/350], Avg Loss: 0.5970, Avg Dice: 0.4758\n",
            "Epoch [28/50], Step [110/350], Avg Loss: 0.5968, Avg Dice: 0.4781\n",
            "Epoch [28/50], Step [115/350], Avg Loss: 0.5943, Avg Dice: 0.4783\n",
            "Epoch [28/50], Step [120/350], Avg Loss: 0.5971, Avg Dice: 0.4773\n",
            "Epoch [28/50], Step [125/350], Avg Loss: 0.5958, Avg Dice: 0.4766\n",
            "Epoch [28/50], Step [130/350], Avg Loss: 0.5962, Avg Dice: 0.4781\n",
            "Epoch [28/50], Step [135/350], Avg Loss: 0.5983, Avg Dice: 0.4771\n",
            "Epoch [28/50], Step [140/350], Avg Loss: 0.5981, Avg Dice: 0.4778\n",
            "Epoch [28/50], Step [145/350], Avg Loss: 0.5964, Avg Dice: 0.4799\n",
            "Epoch [28/50], Step [150/350], Avg Loss: 0.5962, Avg Dice: 0.4801\n",
            "Epoch [28/50], Step [155/350], Avg Loss: 0.5975, Avg Dice: 0.4799\n",
            "Epoch [28/50], Step [160/350], Avg Loss: 0.5978, Avg Dice: 0.4798\n",
            "Epoch [28/50], Step [165/350], Avg Loss: 0.5981, Avg Dice: 0.4791\n",
            "Epoch [28/50], Step [170/350], Avg Loss: 0.5981, Avg Dice: 0.4785\n",
            "Epoch [28/50], Step [175/350], Avg Loss: 0.5974, Avg Dice: 0.4792\n",
            "Epoch [28/50], Step [180/350], Avg Loss: 0.5977, Avg Dice: 0.4772\n",
            "Epoch [28/50], Step [185/350], Avg Loss: 0.5968, Avg Dice: 0.4761\n",
            "Epoch [28/50], Step [190/350], Avg Loss: 0.5967, Avg Dice: 0.4767\n",
            "Epoch [28/50], Step [195/350], Avg Loss: 0.5979, Avg Dice: 0.4759\n",
            "Epoch [28/50], Step [200/350], Avg Loss: 0.5976, Avg Dice: 0.4767\n",
            "Epoch [28/50], Step [205/350], Avg Loss: 0.5974, Avg Dice: 0.4759\n",
            "Epoch [28/50], Step [210/350], Avg Loss: 0.5971, Avg Dice: 0.4763\n",
            "Epoch [28/50], Step [215/350], Avg Loss: 0.5966, Avg Dice: 0.4754\n",
            "Epoch [28/50], Step [220/350], Avg Loss: 0.5969, Avg Dice: 0.4748\n",
            "Epoch [28/50], Step [225/350], Avg Loss: 0.5967, Avg Dice: 0.4748\n",
            "Epoch [28/50], Step [230/350], Avg Loss: 0.5968, Avg Dice: 0.4747\n",
            "Epoch [28/50], Step [235/350], Avg Loss: 0.5963, Avg Dice: 0.4745\n",
            "Epoch [28/50], Step [240/350], Avg Loss: 0.5957, Avg Dice: 0.4738\n",
            "Epoch [28/50], Step [245/350], Avg Loss: 0.5954, Avg Dice: 0.4749\n",
            "Epoch [28/50], Step [250/350], Avg Loss: 0.5951, Avg Dice: 0.4753\n",
            "Epoch [28/50], Step [255/350], Avg Loss: 0.5950, Avg Dice: 0.4753\n",
            "Epoch [28/50], Step [260/350], Avg Loss: 0.5951, Avg Dice: 0.4752\n",
            "Epoch [28/50], Step [265/350], Avg Loss: 0.5951, Avg Dice: 0.4748\n",
            "Epoch [28/50], Step [270/350], Avg Loss: 0.5954, Avg Dice: 0.4754\n",
            "Epoch [28/50], Step [275/350], Avg Loss: 0.5960, Avg Dice: 0.4755\n",
            "Epoch [28/50], Step [280/350], Avg Loss: 0.5961, Avg Dice: 0.4759\n",
            "Epoch [28/50], Step [285/350], Avg Loss: 0.5962, Avg Dice: 0.4761\n",
            "Epoch [28/50], Step [290/350], Avg Loss: 0.5962, Avg Dice: 0.4755\n",
            "Epoch [28/50], Step [295/350], Avg Loss: 0.5961, Avg Dice: 0.4760\n",
            "Epoch [28/50], Step [300/350], Avg Loss: 0.5960, Avg Dice: 0.4759\n",
            "Epoch [28/50], Step [305/350], Avg Loss: 0.5957, Avg Dice: 0.4761\n",
            "Epoch [28/50], Step [310/350], Avg Loss: 0.5962, Avg Dice: 0.4763\n",
            "Epoch [28/50], Step [315/350], Avg Loss: 0.5963, Avg Dice: 0.4763\n",
            "Epoch [28/50], Step [320/350], Avg Loss: 0.5965, Avg Dice: 0.4761\n",
            "Epoch [28/50], Step [325/350], Avg Loss: 0.5963, Avg Dice: 0.4762\n",
            "Epoch [28/50], Step [330/350], Avg Loss: 0.5963, Avg Dice: 0.4761\n",
            "Epoch [28/50], Step [335/350], Avg Loss: 0.5963, Avg Dice: 0.4767\n",
            "Epoch [28/50], Step [340/350], Avg Loss: 0.5953, Avg Dice: 0.4766\n",
            "Epoch [28/50], Step [345/350], Avg Loss: 0.5955, Avg Dice: 0.4766\n",
            "Epoch [28/50], Step [350/350], Avg Loss: 0.5954, Avg Dice: 0.4766\n",
            "End of epoch 28: Avg Loss: 0.5954, Avg Dice: 0.4766\n",
            "Epoch [29/50], Step [5/350], Avg Loss: 0.5892, Avg Dice: 0.5254\n",
            "Epoch [29/50], Step [10/350], Avg Loss: 0.6007, Avg Dice: 0.4983\n",
            "Epoch [29/50], Step [15/350], Avg Loss: 0.5855, Avg Dice: 0.5165\n",
            "Epoch [29/50], Step [20/350], Avg Loss: 0.5837, Avg Dice: 0.5030\n",
            "Epoch [29/50], Step [25/350], Avg Loss: 0.5843, Avg Dice: 0.4964\n",
            "Epoch [29/50], Step [30/350], Avg Loss: 0.5858, Avg Dice: 0.5007\n",
            "Epoch [29/50], Step [35/350], Avg Loss: 0.5835, Avg Dice: 0.4994\n",
            "Epoch [29/50], Step [40/350], Avg Loss: 0.5779, Avg Dice: 0.4910\n",
            "Epoch [29/50], Step [45/350], Avg Loss: 0.5754, Avg Dice: 0.4902\n",
            "Epoch [29/50], Step [50/350], Avg Loss: 0.5790, Avg Dice: 0.4874\n",
            "Epoch [29/50], Step [55/350], Avg Loss: 0.5776, Avg Dice: 0.4860\n",
            "Epoch [29/50], Step [60/350], Avg Loss: 0.5774, Avg Dice: 0.4862\n",
            "Epoch [29/50], Step [65/350], Avg Loss: 0.5787, Avg Dice: 0.4856\n",
            "Epoch [29/50], Step [70/350], Avg Loss: 0.5797, Avg Dice: 0.4850\n",
            "Epoch [29/50], Step [75/350], Avg Loss: 0.5761, Avg Dice: 0.4850\n",
            "Epoch [29/50], Step [80/350], Avg Loss: 0.5747, Avg Dice: 0.4884\n",
            "Epoch [29/50], Step [85/350], Avg Loss: 0.5755, Avg Dice: 0.4877\n",
            "Epoch [29/50], Step [90/350], Avg Loss: 0.5750, Avg Dice: 0.4863\n",
            "Epoch [29/50], Step [95/350], Avg Loss: 0.5745, Avg Dice: 0.4880\n",
            "Epoch [29/50], Step [100/350], Avg Loss: 0.5736, Avg Dice: 0.4906\n",
            "Epoch [29/50], Step [105/350], Avg Loss: 0.5728, Avg Dice: 0.4907\n",
            "Epoch [29/50], Step [110/350], Avg Loss: 0.5729, Avg Dice: 0.4896\n",
            "Epoch [29/50], Step [115/350], Avg Loss: 0.5730, Avg Dice: 0.4919\n",
            "Epoch [29/50], Step [120/350], Avg Loss: 0.5728, Avg Dice: 0.4915\n",
            "Epoch [29/50], Step [125/350], Avg Loss: 0.5724, Avg Dice: 0.4908\n",
            "Epoch [29/50], Step [130/350], Avg Loss: 0.5726, Avg Dice: 0.4900\n",
            "Epoch [29/50], Step [135/350], Avg Loss: 0.5737, Avg Dice: 0.4905\n",
            "Epoch [29/50], Step [140/350], Avg Loss: 0.5738, Avg Dice: 0.4899\n",
            "Epoch [29/50], Step [145/350], Avg Loss: 0.5742, Avg Dice: 0.4910\n",
            "Epoch [29/50], Step [150/350], Avg Loss: 0.5738, Avg Dice: 0.4907\n",
            "Epoch [29/50], Step [155/350], Avg Loss: 0.5730, Avg Dice: 0.4900\n",
            "Epoch [29/50], Step [160/350], Avg Loss: 0.5730, Avg Dice: 0.4905\n",
            "Epoch [29/50], Step [165/350], Avg Loss: 0.5743, Avg Dice: 0.4898\n",
            "Epoch [29/50], Step [170/350], Avg Loss: 0.5752, Avg Dice: 0.4900\n",
            "Epoch [29/50], Step [175/350], Avg Loss: 0.5764, Avg Dice: 0.4890\n",
            "Epoch [29/50], Step [180/350], Avg Loss: 0.5768, Avg Dice: 0.4887\n",
            "Epoch [29/50], Step [185/350], Avg Loss: 0.5773, Avg Dice: 0.4884\n",
            "Epoch [29/50], Step [190/350], Avg Loss: 0.5766, Avg Dice: 0.4877\n",
            "Epoch [29/50], Step [195/350], Avg Loss: 0.5771, Avg Dice: 0.4864\n",
            "Epoch [29/50], Step [200/350], Avg Loss: 0.5781, Avg Dice: 0.4860\n",
            "Epoch [29/50], Step [205/350], Avg Loss: 0.5781, Avg Dice: 0.4860\n",
            "Epoch [29/50], Step [210/350], Avg Loss: 0.5788, Avg Dice: 0.4856\n",
            "Epoch [29/50], Step [215/350], Avg Loss: 0.5797, Avg Dice: 0.4847\n",
            "Epoch [29/50], Step [220/350], Avg Loss: 0.5800, Avg Dice: 0.4849\n",
            "Epoch [29/50], Step [225/350], Avg Loss: 0.5800, Avg Dice: 0.4851\n",
            "Epoch [29/50], Step [230/350], Avg Loss: 0.5814, Avg Dice: 0.4858\n",
            "Epoch [29/50], Step [235/350], Avg Loss: 0.5813, Avg Dice: 0.4857\n",
            "Epoch [29/50], Step [240/350], Avg Loss: 0.5814, Avg Dice: 0.4845\n",
            "Epoch [29/50], Step [245/350], Avg Loss: 0.5815, Avg Dice: 0.4847\n",
            "Epoch [29/50], Step [250/350], Avg Loss: 0.5810, Avg Dice: 0.4850\n",
            "Epoch [29/50], Step [255/350], Avg Loss: 0.5813, Avg Dice: 0.4859\n",
            "Epoch [29/50], Step [260/350], Avg Loss: 0.5813, Avg Dice: 0.4862\n",
            "Epoch [29/50], Step [265/350], Avg Loss: 0.5816, Avg Dice: 0.4861\n",
            "Epoch [29/50], Step [270/350], Avg Loss: 0.5812, Avg Dice: 0.4867\n",
            "Epoch [29/50], Step [275/350], Avg Loss: 0.5811, Avg Dice: 0.4872\n",
            "Epoch [29/50], Step [280/350], Avg Loss: 0.5810, Avg Dice: 0.4862\n",
            "Epoch [29/50], Step [285/350], Avg Loss: 0.5803, Avg Dice: 0.4863\n",
            "Epoch [29/50], Step [290/350], Avg Loss: 0.5800, Avg Dice: 0.4861\n",
            "Epoch [29/50], Step [295/350], Avg Loss: 0.5800, Avg Dice: 0.4864\n",
            "Epoch [29/50], Step [300/350], Avg Loss: 0.5795, Avg Dice: 0.4865\n",
            "Epoch [29/50], Step [305/350], Avg Loss: 0.5795, Avg Dice: 0.4865\n",
            "Epoch [29/50], Step [310/350], Avg Loss: 0.5800, Avg Dice: 0.4862\n",
            "Epoch [29/50], Step [315/350], Avg Loss: 0.5809, Avg Dice: 0.4861\n",
            "Epoch [29/50], Step [320/350], Avg Loss: 0.5811, Avg Dice: 0.4859\n",
            "Epoch [29/50], Step [325/350], Avg Loss: 0.5807, Avg Dice: 0.4859\n",
            "Epoch [29/50], Step [330/350], Avg Loss: 0.5808, Avg Dice: 0.4863\n",
            "Epoch [29/50], Step [335/350], Avg Loss: 0.5812, Avg Dice: 0.4861\n",
            "Epoch [29/50], Step [340/350], Avg Loss: 0.5812, Avg Dice: 0.4860\n",
            "Epoch [29/50], Step [345/350], Avg Loss: 0.5815, Avg Dice: 0.4861\n",
            "Epoch [29/50], Step [350/350], Avg Loss: 0.5815, Avg Dice: 0.4857\n",
            "End of epoch 29: Avg Loss: 0.5815, Avg Dice: 0.4857\n",
            "Epoch [30/50], Step [5/350], Avg Loss: 0.5303, Avg Dice: 0.4894\n",
            "Epoch [30/50], Step [10/350], Avg Loss: 0.5440, Avg Dice: 0.4901\n",
            "Epoch [30/50], Step [15/350], Avg Loss: 0.5487, Avg Dice: 0.4815\n",
            "Epoch [30/50], Step [20/350], Avg Loss: 0.5562, Avg Dice: 0.4847\n",
            "Epoch [30/50], Step [25/350], Avg Loss: 0.5668, Avg Dice: 0.4831\n",
            "Epoch [30/50], Step [30/350], Avg Loss: 0.5627, Avg Dice: 0.4867\n",
            "Epoch [30/50], Step [35/350], Avg Loss: 0.5676, Avg Dice: 0.4875\n",
            "Epoch [30/50], Step [40/350], Avg Loss: 0.5709, Avg Dice: 0.4873\n",
            "Epoch [30/50], Step [45/350], Avg Loss: 0.5754, Avg Dice: 0.4890\n",
            "Epoch [30/50], Step [50/350], Avg Loss: 0.5749, Avg Dice: 0.4909\n",
            "Epoch [30/50], Step [55/350], Avg Loss: 0.5757, Avg Dice: 0.4896\n",
            "Epoch [30/50], Step [60/350], Avg Loss: 0.5752, Avg Dice: 0.4900\n",
            "Epoch [30/50], Step [65/350], Avg Loss: 0.5743, Avg Dice: 0.4932\n",
            "Epoch [30/50], Step [70/350], Avg Loss: 0.5734, Avg Dice: 0.4919\n",
            "Epoch [30/50], Step [75/350], Avg Loss: 0.5743, Avg Dice: 0.4916\n",
            "Epoch [30/50], Step [80/350], Avg Loss: 0.5730, Avg Dice: 0.4922\n",
            "Epoch [30/50], Step [85/350], Avg Loss: 0.5746, Avg Dice: 0.4906\n",
            "Epoch [30/50], Step [90/350], Avg Loss: 0.5750, Avg Dice: 0.4947\n",
            "Epoch [30/50], Step [95/350], Avg Loss: 0.5733, Avg Dice: 0.4944\n",
            "Epoch [30/50], Step [100/350], Avg Loss: 0.5739, Avg Dice: 0.4944\n",
            "Epoch [30/50], Step [105/350], Avg Loss: 0.5748, Avg Dice: 0.4931\n",
            "Epoch [30/50], Step [110/350], Avg Loss: 0.5722, Avg Dice: 0.4921\n",
            "Epoch [30/50], Step [115/350], Avg Loss: 0.5720, Avg Dice: 0.4924\n",
            "Epoch [30/50], Step [120/350], Avg Loss: 0.5717, Avg Dice: 0.4918\n",
            "Epoch [30/50], Step [125/350], Avg Loss: 0.5715, Avg Dice: 0.4928\n",
            "Epoch [30/50], Step [130/350], Avg Loss: 0.5725, Avg Dice: 0.4937\n",
            "Epoch [30/50], Step [135/350], Avg Loss: 0.5724, Avg Dice: 0.4943\n",
            "Epoch [30/50], Step [140/350], Avg Loss: 0.5715, Avg Dice: 0.4950\n",
            "Epoch [30/50], Step [145/350], Avg Loss: 0.5708, Avg Dice: 0.4966\n",
            "Epoch [30/50], Step [150/350], Avg Loss: 0.5685, Avg Dice: 0.4962\n",
            "Epoch [30/50], Step [155/350], Avg Loss: 0.5687, Avg Dice: 0.4944\n",
            "Epoch [30/50], Step [160/350], Avg Loss: 0.5684, Avg Dice: 0.4941\n",
            "Epoch [30/50], Step [165/350], Avg Loss: 0.5681, Avg Dice: 0.4931\n",
            "Epoch [30/50], Step [170/350], Avg Loss: 0.5683, Avg Dice: 0.4925\n",
            "Epoch [30/50], Step [175/350], Avg Loss: 0.5683, Avg Dice: 0.4931\n",
            "Epoch [30/50], Step [180/350], Avg Loss: 0.5690, Avg Dice: 0.4921\n",
            "Epoch [30/50], Step [185/350], Avg Loss: 0.5682, Avg Dice: 0.4925\n",
            "Epoch [30/50], Step [190/350], Avg Loss: 0.5676, Avg Dice: 0.4909\n",
            "Epoch [30/50], Step [195/350], Avg Loss: 0.5692, Avg Dice: 0.4903\n",
            "Epoch [30/50], Step [200/350], Avg Loss: 0.5687, Avg Dice: 0.4901\n",
            "Epoch [30/50], Step [205/350], Avg Loss: 0.5686, Avg Dice: 0.4905\n",
            "Epoch [30/50], Step [210/350], Avg Loss: 0.5693, Avg Dice: 0.4908\n",
            "Epoch [30/50], Step [215/350], Avg Loss: 0.5698, Avg Dice: 0.4919\n",
            "Epoch [30/50], Step [220/350], Avg Loss: 0.5701, Avg Dice: 0.4921\n",
            "Epoch [30/50], Step [225/350], Avg Loss: 0.5700, Avg Dice: 0.4919\n",
            "Epoch [30/50], Step [230/350], Avg Loss: 0.5699, Avg Dice: 0.4913\n",
            "Epoch [30/50], Step [235/350], Avg Loss: 0.5688, Avg Dice: 0.4926\n",
            "Epoch [30/50], Step [240/350], Avg Loss: 0.5689, Avg Dice: 0.4928\n",
            "Epoch [30/50], Step [245/350], Avg Loss: 0.5693, Avg Dice: 0.4929\n",
            "Epoch [30/50], Step [250/350], Avg Loss: 0.5704, Avg Dice: 0.4928\n",
            "Epoch [30/50], Step [255/350], Avg Loss: 0.5710, Avg Dice: 0.4926\n",
            "Epoch [30/50], Step [260/350], Avg Loss: 0.5714, Avg Dice: 0.4930\n",
            "Epoch [30/50], Step [265/350], Avg Loss: 0.5711, Avg Dice: 0.4927\n",
            "Epoch [30/50], Step [270/350], Avg Loss: 0.5718, Avg Dice: 0.4925\n",
            "Epoch [30/50], Step [275/350], Avg Loss: 0.5722, Avg Dice: 0.4915\n",
            "Epoch [30/50], Step [280/350], Avg Loss: 0.5725, Avg Dice: 0.4915\n",
            "Epoch [30/50], Step [285/350], Avg Loss: 0.5729, Avg Dice: 0.4919\n",
            "Epoch [30/50], Step [290/350], Avg Loss: 0.5733, Avg Dice: 0.4921\n",
            "Epoch [30/50], Step [295/350], Avg Loss: 0.5729, Avg Dice: 0.4918\n",
            "Epoch [30/50], Step [300/350], Avg Loss: 0.5725, Avg Dice: 0.4922\n",
            "Epoch [30/50], Step [305/350], Avg Loss: 0.5723, Avg Dice: 0.4922\n",
            "Epoch [30/50], Step [310/350], Avg Loss: 0.5726, Avg Dice: 0.4917\n",
            "Epoch [30/50], Step [315/350], Avg Loss: 0.5730, Avg Dice: 0.4919\n",
            "Epoch [30/50], Step [320/350], Avg Loss: 0.5729, Avg Dice: 0.4916\n",
            "Epoch [30/50], Step [325/350], Avg Loss: 0.5733, Avg Dice: 0.4903\n",
            "Epoch [30/50], Step [330/350], Avg Loss: 0.5733, Avg Dice: 0.4900\n",
            "Epoch [30/50], Step [335/350], Avg Loss: 0.5734, Avg Dice: 0.4897\n",
            "Epoch [30/50], Step [340/350], Avg Loss: 0.5731, Avg Dice: 0.4888\n",
            "Epoch [30/50], Step [345/350], Avg Loss: 0.5733, Avg Dice: 0.4891\n",
            "Epoch [30/50], Step [350/350], Avg Loss: 0.5731, Avg Dice: 0.4891\n",
            "End of epoch 30: Avg Loss: 0.5731, Avg Dice: 0.4891\n",
            "Epoch [31/50], Step [5/350], Avg Loss: 0.5477, Avg Dice: 0.5242\n",
            "Epoch [31/50], Step [10/350], Avg Loss: 0.5600, Avg Dice: 0.5019\n",
            "Epoch [31/50], Step [15/350], Avg Loss: 0.5508, Avg Dice: 0.5040\n",
            "Epoch [31/50], Step [20/350], Avg Loss: 0.5539, Avg Dice: 0.5091\n",
            "Epoch [31/50], Step [25/350], Avg Loss: 0.5562, Avg Dice: 0.5121\n",
            "Epoch [31/50], Step [30/350], Avg Loss: 0.5574, Avg Dice: 0.5026\n",
            "Epoch [31/50], Step [35/350], Avg Loss: 0.5521, Avg Dice: 0.5050\n",
            "Epoch [31/50], Step [40/350], Avg Loss: 0.5521, Avg Dice: 0.5082\n",
            "Epoch [31/50], Step [45/350], Avg Loss: 0.5485, Avg Dice: 0.5069\n",
            "Epoch [31/50], Step [50/350], Avg Loss: 0.5460, Avg Dice: 0.5096\n",
            "Epoch [31/50], Step [55/350], Avg Loss: 0.5478, Avg Dice: 0.5085\n",
            "Epoch [31/50], Step [60/350], Avg Loss: 0.5480, Avg Dice: 0.5094\n",
            "Epoch [31/50], Step [65/350], Avg Loss: 0.5473, Avg Dice: 0.5085\n",
            "Epoch [31/50], Step [70/350], Avg Loss: 0.5469, Avg Dice: 0.5063\n",
            "Epoch [31/50], Step [75/350], Avg Loss: 0.5497, Avg Dice: 0.5061\n",
            "Epoch [31/50], Step [80/350], Avg Loss: 0.5507, Avg Dice: 0.5055\n",
            "Epoch [31/50], Step [85/350], Avg Loss: 0.5507, Avg Dice: 0.5057\n",
            "Epoch [31/50], Step [90/350], Avg Loss: 0.5514, Avg Dice: 0.5048\n",
            "Epoch [31/50], Step [95/350], Avg Loss: 0.5520, Avg Dice: 0.5031\n",
            "Epoch [31/50], Step [100/350], Avg Loss: 0.5521, Avg Dice: 0.5041\n",
            "Epoch [31/50], Step [105/350], Avg Loss: 0.5528, Avg Dice: 0.5039\n",
            "Epoch [31/50], Step [110/350], Avg Loss: 0.5524, Avg Dice: 0.5028\n",
            "Epoch [31/50], Step [115/350], Avg Loss: 0.5529, Avg Dice: 0.5025\n",
            "Epoch [31/50], Step [120/350], Avg Loss: 0.5532, Avg Dice: 0.5011\n",
            "Epoch [31/50], Step [125/350], Avg Loss: 0.5543, Avg Dice: 0.5013\n",
            "Epoch [31/50], Step [130/350], Avg Loss: 0.5529, Avg Dice: 0.5011\n",
            "Epoch [31/50], Step [135/350], Avg Loss: 0.5538, Avg Dice: 0.4997\n",
            "Epoch [31/50], Step [140/350], Avg Loss: 0.5550, Avg Dice: 0.5004\n",
            "Epoch [31/50], Step [145/350], Avg Loss: 0.5563, Avg Dice: 0.4998\n",
            "Epoch [31/50], Step [150/350], Avg Loss: 0.5576, Avg Dice: 0.4976\n",
            "Epoch [31/50], Step [155/350], Avg Loss: 0.5569, Avg Dice: 0.4993\n",
            "Epoch [31/50], Step [160/350], Avg Loss: 0.5579, Avg Dice: 0.4994\n",
            "Epoch [31/50], Step [165/350], Avg Loss: 0.5587, Avg Dice: 0.4983\n",
            "Epoch [31/50], Step [170/350], Avg Loss: 0.5590, Avg Dice: 0.4990\n",
            "Epoch [31/50], Step [175/350], Avg Loss: 0.5595, Avg Dice: 0.4981\n",
            "Epoch [31/50], Step [180/350], Avg Loss: 0.5596, Avg Dice: 0.4986\n",
            "Epoch [31/50], Step [185/350], Avg Loss: 0.5598, Avg Dice: 0.4984\n",
            "Epoch [31/50], Step [190/350], Avg Loss: 0.5599, Avg Dice: 0.4975\n",
            "Epoch [31/50], Step [195/350], Avg Loss: 0.5595, Avg Dice: 0.4974\n",
            "Epoch [31/50], Step [200/350], Avg Loss: 0.5586, Avg Dice: 0.4979\n",
            "Epoch [31/50], Step [205/350], Avg Loss: 0.5587, Avg Dice: 0.4977\n",
            "Epoch [31/50], Step [210/350], Avg Loss: 0.5586, Avg Dice: 0.4961\n",
            "Epoch [31/50], Step [215/350], Avg Loss: 0.5583, Avg Dice: 0.4960\n",
            "Epoch [31/50], Step [220/350], Avg Loss: 0.5588, Avg Dice: 0.4952\n",
            "Epoch [31/50], Step [225/350], Avg Loss: 0.5587, Avg Dice: 0.4940\n",
            "Epoch [31/50], Step [230/350], Avg Loss: 0.5593, Avg Dice: 0.4942\n",
            "Epoch [31/50], Step [235/350], Avg Loss: 0.5593, Avg Dice: 0.4945\n",
            "Epoch [31/50], Step [240/350], Avg Loss: 0.5589, Avg Dice: 0.4952\n",
            "Epoch [31/50], Step [245/350], Avg Loss: 0.5594, Avg Dice: 0.4962\n",
            "Epoch [31/50], Step [250/350], Avg Loss: 0.5592, Avg Dice: 0.4966\n",
            "Epoch [31/50], Step [255/350], Avg Loss: 0.5591, Avg Dice: 0.4966\n",
            "Epoch [31/50], Step [260/350], Avg Loss: 0.5592, Avg Dice: 0.4964\n",
            "Epoch [31/50], Step [265/350], Avg Loss: 0.5590, Avg Dice: 0.4972\n",
            "Epoch [31/50], Step [270/350], Avg Loss: 0.5597, Avg Dice: 0.4973\n",
            "Epoch [31/50], Step [275/350], Avg Loss: 0.5601, Avg Dice: 0.4964\n",
            "Epoch [31/50], Step [280/350], Avg Loss: 0.5602, Avg Dice: 0.4969\n",
            "Epoch [31/50], Step [285/350], Avg Loss: 0.5605, Avg Dice: 0.4966\n",
            "Epoch [31/50], Step [290/350], Avg Loss: 0.5606, Avg Dice: 0.4965\n",
            "Epoch [31/50], Step [295/350], Avg Loss: 0.5613, Avg Dice: 0.4963\n",
            "Epoch [31/50], Step [300/350], Avg Loss: 0.5615, Avg Dice: 0.4959\n",
            "Epoch [31/50], Step [305/350], Avg Loss: 0.5613, Avg Dice: 0.4960\n",
            "Epoch [31/50], Step [310/350], Avg Loss: 0.5608, Avg Dice: 0.4957\n",
            "Epoch [31/50], Step [315/350], Avg Loss: 0.5612, Avg Dice: 0.4953\n",
            "Epoch [31/50], Step [320/350], Avg Loss: 0.5614, Avg Dice: 0.4952\n",
            "Epoch [31/50], Step [325/350], Avg Loss: 0.5618, Avg Dice: 0.4949\n",
            "Epoch [31/50], Step [330/350], Avg Loss: 0.5624, Avg Dice: 0.4945\n",
            "Epoch [31/50], Step [335/350], Avg Loss: 0.5623, Avg Dice: 0.4955\n",
            "Epoch [31/50], Step [340/350], Avg Loss: 0.5619, Avg Dice: 0.4944\n",
            "Epoch [31/50], Step [345/350], Avg Loss: 0.5619, Avg Dice: 0.4944\n",
            "Epoch [31/50], Step [350/350], Avg Loss: 0.5626, Avg Dice: 0.4938\n",
            "End of epoch 31: Avg Loss: 0.5626, Avg Dice: 0.4938\n",
            "Epoch [32/50], Step [5/350], Avg Loss: 0.4998, Avg Dice: 0.5331\n",
            "Epoch [32/50], Step [10/350], Avg Loss: 0.5283, Avg Dice: 0.5140\n",
            "Epoch [32/50], Step [15/350], Avg Loss: 0.5312, Avg Dice: 0.5242\n",
            "Epoch [32/50], Step [20/350], Avg Loss: 0.5330, Avg Dice: 0.5179\n",
            "Epoch [32/50], Step [25/350], Avg Loss: 0.5347, Avg Dice: 0.5208\n",
            "Epoch [32/50], Step [30/350], Avg Loss: 0.5435, Avg Dice: 0.5177\n",
            "Epoch [32/50], Step [35/350], Avg Loss: 0.5500, Avg Dice: 0.5238\n",
            "Epoch [32/50], Step [40/350], Avg Loss: 0.5531, Avg Dice: 0.5192\n",
            "Epoch [32/50], Step [45/350], Avg Loss: 0.5545, Avg Dice: 0.5174\n",
            "Epoch [32/50], Step [50/350], Avg Loss: 0.5539, Avg Dice: 0.5141\n",
            "Epoch [32/50], Step [55/350], Avg Loss: 0.5508, Avg Dice: 0.5119\n",
            "Epoch [32/50], Step [60/350], Avg Loss: 0.5517, Avg Dice: 0.5145\n",
            "Epoch [32/50], Step [65/350], Avg Loss: 0.5503, Avg Dice: 0.5144\n",
            "Epoch [32/50], Step [70/350], Avg Loss: 0.5508, Avg Dice: 0.5140\n",
            "Epoch [32/50], Step [75/350], Avg Loss: 0.5490, Avg Dice: 0.5127\n",
            "Epoch [32/50], Step [80/350], Avg Loss: 0.5483, Avg Dice: 0.5119\n",
            "Epoch [32/50], Step [85/350], Avg Loss: 0.5500, Avg Dice: 0.5112\n",
            "Epoch [32/50], Step [90/350], Avg Loss: 0.5511, Avg Dice: 0.5114\n",
            "Epoch [32/50], Step [95/350], Avg Loss: 0.5502, Avg Dice: 0.5117\n",
            "Epoch [32/50], Step [100/350], Avg Loss: 0.5493, Avg Dice: 0.5143\n",
            "Epoch [32/50], Step [105/350], Avg Loss: 0.5512, Avg Dice: 0.5139\n",
            "Epoch [32/50], Step [110/350], Avg Loss: 0.5511, Avg Dice: 0.5141\n",
            "Epoch [32/50], Step [115/350], Avg Loss: 0.5498, Avg Dice: 0.5134\n",
            "Epoch [32/50], Step [120/350], Avg Loss: 0.5477, Avg Dice: 0.5123\n",
            "Epoch [32/50], Step [125/350], Avg Loss: 0.5482, Avg Dice: 0.5109\n",
            "Epoch [32/50], Step [130/350], Avg Loss: 0.5474, Avg Dice: 0.5100\n",
            "Epoch [32/50], Step [135/350], Avg Loss: 0.5480, Avg Dice: 0.5103\n",
            "Epoch [32/50], Step [140/350], Avg Loss: 0.5490, Avg Dice: 0.5105\n",
            "Epoch [32/50], Step [145/350], Avg Loss: 0.5484, Avg Dice: 0.5104\n",
            "Epoch [32/50], Step [150/350], Avg Loss: 0.5487, Avg Dice: 0.5094\n",
            "Epoch [32/50], Step [155/350], Avg Loss: 0.5503, Avg Dice: 0.5082\n",
            "Epoch [32/50], Step [160/350], Avg Loss: 0.5505, Avg Dice: 0.5082\n",
            "Epoch [32/50], Step [165/350], Avg Loss: 0.5497, Avg Dice: 0.5081\n",
            "Epoch [32/50], Step [170/350], Avg Loss: 0.5498, Avg Dice: 0.5077\n",
            "Epoch [32/50], Step [175/350], Avg Loss: 0.5502, Avg Dice: 0.5059\n",
            "Epoch [32/50], Step [180/350], Avg Loss: 0.5500, Avg Dice: 0.5065\n",
            "Epoch [32/50], Step [185/350], Avg Loss: 0.5509, Avg Dice: 0.5062\n",
            "Epoch [32/50], Step [190/350], Avg Loss: 0.5513, Avg Dice: 0.5058\n",
            "Epoch [32/50], Step [195/350], Avg Loss: 0.5521, Avg Dice: 0.5048\n",
            "Epoch [32/50], Step [200/350], Avg Loss: 0.5512, Avg Dice: 0.5047\n",
            "Epoch [32/50], Step [205/350], Avg Loss: 0.5516, Avg Dice: 0.5043\n",
            "Epoch [32/50], Step [210/350], Avg Loss: 0.5521, Avg Dice: 0.5037\n",
            "Epoch [32/50], Step [215/350], Avg Loss: 0.5524, Avg Dice: 0.5039\n",
            "Epoch [32/50], Step [220/350], Avg Loss: 0.5523, Avg Dice: 0.5029\n",
            "Epoch [32/50], Step [225/350], Avg Loss: 0.5517, Avg Dice: 0.5019\n",
            "Epoch [32/50], Step [230/350], Avg Loss: 0.5523, Avg Dice: 0.5019\n",
            "Epoch [32/50], Step [235/350], Avg Loss: 0.5523, Avg Dice: 0.5019\n",
            "Epoch [32/50], Step [240/350], Avg Loss: 0.5521, Avg Dice: 0.5021\n",
            "Epoch [32/50], Step [245/350], Avg Loss: 0.5528, Avg Dice: 0.5016\n",
            "Epoch [32/50], Step [250/350], Avg Loss: 0.5527, Avg Dice: 0.5026\n",
            "Epoch [32/50], Step [255/350], Avg Loss: 0.5522, Avg Dice: 0.5021\n",
            "Epoch [32/50], Step [260/350], Avg Loss: 0.5520, Avg Dice: 0.5024\n",
            "Epoch [32/50], Step [265/350], Avg Loss: 0.5522, Avg Dice: 0.5021\n",
            "Epoch [32/50], Step [270/350], Avg Loss: 0.5521, Avg Dice: 0.5014\n",
            "Epoch [32/50], Step [275/350], Avg Loss: 0.5524, Avg Dice: 0.5011\n",
            "Epoch [32/50], Step [280/350], Avg Loss: 0.5529, Avg Dice: 0.5011\n",
            "Epoch [32/50], Step [285/350], Avg Loss: 0.5527, Avg Dice: 0.5008\n",
            "Epoch [32/50], Step [290/350], Avg Loss: 0.5529, Avg Dice: 0.5005\n",
            "Epoch [32/50], Step [295/350], Avg Loss: 0.5538, Avg Dice: 0.4992\n",
            "Epoch [32/50], Step [300/350], Avg Loss: 0.5540, Avg Dice: 0.4992\n",
            "Epoch [32/50], Step [305/350], Avg Loss: 0.5541, Avg Dice: 0.4994\n",
            "Epoch [32/50], Step [310/350], Avg Loss: 0.5542, Avg Dice: 0.4992\n",
            "Epoch [32/50], Step [315/350], Avg Loss: 0.5545, Avg Dice: 0.4995\n",
            "Epoch [32/50], Step [320/350], Avg Loss: 0.5548, Avg Dice: 0.4994\n",
            "Epoch [32/50], Step [325/350], Avg Loss: 0.5555, Avg Dice: 0.4993\n",
            "Epoch [32/50], Step [330/350], Avg Loss: 0.5553, Avg Dice: 0.4996\n",
            "Epoch [32/50], Step [335/350], Avg Loss: 0.5551, Avg Dice: 0.5002\n",
            "Epoch [32/50], Step [340/350], Avg Loss: 0.5548, Avg Dice: 0.5000\n",
            "Epoch [32/50], Step [345/350], Avg Loss: 0.5549, Avg Dice: 0.5006\n",
            "Epoch [32/50], Step [350/350], Avg Loss: 0.5555, Avg Dice: 0.5001\n",
            "End of epoch 32: Avg Loss: 0.5555, Avg Dice: 0.5001\n",
            "Epoch [33/50], Step [5/350], Avg Loss: 0.5517, Avg Dice: 0.5255\n",
            "Epoch [33/50], Step [10/350], Avg Loss: 0.5534, Avg Dice: 0.5238\n",
            "Epoch [33/50], Step [15/350], Avg Loss: 0.5575, Avg Dice: 0.5168\n",
            "Epoch [33/50], Step [20/350], Avg Loss: 0.5572, Avg Dice: 0.5111\n",
            "Epoch [33/50], Step [25/350], Avg Loss: 0.5549, Avg Dice: 0.4933\n",
            "Epoch [33/50], Step [30/350], Avg Loss: 0.5541, Avg Dice: 0.5027\n",
            "Epoch [33/50], Step [35/350], Avg Loss: 0.5488, Avg Dice: 0.4981\n",
            "Epoch [33/50], Step [40/350], Avg Loss: 0.5449, Avg Dice: 0.5028\n",
            "Epoch [33/50], Step [45/350], Avg Loss: 0.5411, Avg Dice: 0.5035\n",
            "Epoch [33/50], Step [50/350], Avg Loss: 0.5410, Avg Dice: 0.5036\n",
            "Epoch [33/50], Step [55/350], Avg Loss: 0.5431, Avg Dice: 0.5048\n",
            "Epoch [33/50], Step [60/350], Avg Loss: 0.5434, Avg Dice: 0.5073\n",
            "Epoch [33/50], Step [65/350], Avg Loss: 0.5473, Avg Dice: 0.5039\n",
            "Epoch [33/50], Step [70/350], Avg Loss: 0.5465, Avg Dice: 0.5025\n",
            "Epoch [33/50], Step [75/350], Avg Loss: 0.5447, Avg Dice: 0.5051\n",
            "Epoch [33/50], Step [80/350], Avg Loss: 0.5449, Avg Dice: 0.5042\n",
            "Epoch [33/50], Step [85/350], Avg Loss: 0.5434, Avg Dice: 0.5038\n",
            "Epoch [33/50], Step [90/350], Avg Loss: 0.5434, Avg Dice: 0.5030\n",
            "Epoch [33/50], Step [95/350], Avg Loss: 0.5447, Avg Dice: 0.5015\n",
            "Epoch [33/50], Step [100/350], Avg Loss: 0.5449, Avg Dice: 0.5030\n",
            "Epoch [33/50], Step [105/350], Avg Loss: 0.5461, Avg Dice: 0.5035\n",
            "Epoch [33/50], Step [110/350], Avg Loss: 0.5476, Avg Dice: 0.5033\n",
            "Epoch [33/50], Step [115/350], Avg Loss: 0.5473, Avg Dice: 0.5034\n",
            "Epoch [33/50], Step [120/350], Avg Loss: 0.5476, Avg Dice: 0.5032\n",
            "Epoch [33/50], Step [125/350], Avg Loss: 0.5483, Avg Dice: 0.5030\n",
            "Epoch [33/50], Step [130/350], Avg Loss: 0.5484, Avg Dice: 0.5037\n",
            "Epoch [33/50], Step [135/350], Avg Loss: 0.5492, Avg Dice: 0.5035\n",
            "Epoch [33/50], Step [140/350], Avg Loss: 0.5486, Avg Dice: 0.5028\n",
            "Epoch [33/50], Step [145/350], Avg Loss: 0.5488, Avg Dice: 0.5030\n",
            "Epoch [33/50], Step [150/350], Avg Loss: 0.5481, Avg Dice: 0.5016\n",
            "Epoch [33/50], Step [155/350], Avg Loss: 0.5470, Avg Dice: 0.5031\n",
            "Epoch [33/50], Step [160/350], Avg Loss: 0.5462, Avg Dice: 0.5047\n",
            "Epoch [33/50], Step [165/350], Avg Loss: 0.5465, Avg Dice: 0.5044\n",
            "Epoch [33/50], Step [170/350], Avg Loss: 0.5455, Avg Dice: 0.5041\n",
            "Epoch [33/50], Step [175/350], Avg Loss: 0.5467, Avg Dice: 0.5039\n",
            "Epoch [33/50], Step [180/350], Avg Loss: 0.5467, Avg Dice: 0.5037\n",
            "Epoch [33/50], Step [185/350], Avg Loss: 0.5478, Avg Dice: 0.5028\n",
            "Epoch [33/50], Step [190/350], Avg Loss: 0.5478, Avg Dice: 0.5023\n",
            "Epoch [33/50], Step [195/350], Avg Loss: 0.5479, Avg Dice: 0.5043\n",
            "Epoch [33/50], Step [200/350], Avg Loss: 0.5480, Avg Dice: 0.5049\n",
            "Epoch [33/50], Step [205/350], Avg Loss: 0.5490, Avg Dice: 0.5050\n",
            "Epoch [33/50], Step [210/350], Avg Loss: 0.5493, Avg Dice: 0.5041\n",
            "Epoch [33/50], Step [215/350], Avg Loss: 0.5492, Avg Dice: 0.5039\n",
            "Epoch [33/50], Step [220/350], Avg Loss: 0.5487, Avg Dice: 0.5040\n",
            "Epoch [33/50], Step [225/350], Avg Loss: 0.5490, Avg Dice: 0.5041\n",
            "Epoch [33/50], Step [230/350], Avg Loss: 0.5492, Avg Dice: 0.5040\n",
            "Epoch [33/50], Step [235/350], Avg Loss: 0.5493, Avg Dice: 0.5036\n",
            "Epoch [33/50], Step [240/350], Avg Loss: 0.5489, Avg Dice: 0.5033\n",
            "Epoch [33/50], Step [245/350], Avg Loss: 0.5491, Avg Dice: 0.5030\n",
            "Epoch [33/50], Step [250/350], Avg Loss: 0.5493, Avg Dice: 0.5031\n",
            "Epoch [33/50], Step [255/350], Avg Loss: 0.5487, Avg Dice: 0.5041\n",
            "Epoch [33/50], Step [260/350], Avg Loss: 0.5480, Avg Dice: 0.5043\n",
            "Epoch [33/50], Step [265/350], Avg Loss: 0.5479, Avg Dice: 0.5043\n",
            "Epoch [33/50], Step [270/350], Avg Loss: 0.5481, Avg Dice: 0.5035\n",
            "Epoch [33/50], Step [275/350], Avg Loss: 0.5476, Avg Dice: 0.5033\n",
            "Epoch [33/50], Step [280/350], Avg Loss: 0.5474, Avg Dice: 0.5029\n",
            "Epoch [33/50], Step [285/350], Avg Loss: 0.5474, Avg Dice: 0.5029\n",
            "Epoch [33/50], Step [290/350], Avg Loss: 0.5470, Avg Dice: 0.5032\n",
            "Epoch [33/50], Step [295/350], Avg Loss: 0.5472, Avg Dice: 0.5022\n",
            "Epoch [33/50], Step [300/350], Avg Loss: 0.5475, Avg Dice: 0.5012\n",
            "Epoch [33/50], Step [305/350], Avg Loss: 0.5467, Avg Dice: 0.5011\n",
            "Epoch [33/50], Step [310/350], Avg Loss: 0.5472, Avg Dice: 0.5009\n",
            "Epoch [33/50], Step [315/350], Avg Loss: 0.5476, Avg Dice: 0.5013\n",
            "Epoch [33/50], Step [320/350], Avg Loss: 0.5477, Avg Dice: 0.5014\n",
            "Epoch [33/50], Step [325/350], Avg Loss: 0.5479, Avg Dice: 0.5007\n",
            "Epoch [33/50], Step [330/350], Avg Loss: 0.5481, Avg Dice: 0.5006\n",
            "Epoch [33/50], Step [335/350], Avg Loss: 0.5481, Avg Dice: 0.5002\n",
            "Epoch [33/50], Step [340/350], Avg Loss: 0.5486, Avg Dice: 0.5004\n",
            "Epoch [33/50], Step [345/350], Avg Loss: 0.5487, Avg Dice: 0.5005\n",
            "Epoch [33/50], Step [350/350], Avg Loss: 0.5486, Avg Dice: 0.5001\n",
            "End of epoch 33: Avg Loss: 0.5486, Avg Dice: 0.5001\n",
            "Epoch [34/50], Step [5/350], Avg Loss: 0.5372, Avg Dice: 0.5055\n",
            "Epoch [34/50], Step [10/350], Avg Loss: 0.5393, Avg Dice: 0.5164\n",
            "Epoch [34/50], Step [15/350], Avg Loss: 0.5372, Avg Dice: 0.5009\n",
            "Epoch [34/50], Step [20/350], Avg Loss: 0.5353, Avg Dice: 0.4951\n",
            "Epoch [34/50], Step [25/350], Avg Loss: 0.5326, Avg Dice: 0.5061\n",
            "Epoch [34/50], Step [30/350], Avg Loss: 0.5296, Avg Dice: 0.5064\n",
            "Epoch [34/50], Step [35/350], Avg Loss: 0.5310, Avg Dice: 0.5050\n",
            "Epoch [34/50], Step [40/350], Avg Loss: 0.5325, Avg Dice: 0.5012\n",
            "Epoch [34/50], Step [45/350], Avg Loss: 0.5330, Avg Dice: 0.5044\n",
            "Epoch [34/50], Step [50/350], Avg Loss: 0.5355, Avg Dice: 0.5036\n",
            "Epoch [34/50], Step [55/350], Avg Loss: 0.5331, Avg Dice: 0.5091\n",
            "Epoch [34/50], Step [60/350], Avg Loss: 0.5320, Avg Dice: 0.5093\n",
            "Epoch [34/50], Step [65/350], Avg Loss: 0.5350, Avg Dice: 0.5100\n",
            "Epoch [34/50], Step [70/350], Avg Loss: 0.5351, Avg Dice: 0.5112\n",
            "Epoch [34/50], Step [75/350], Avg Loss: 0.5331, Avg Dice: 0.5111\n",
            "Epoch [34/50], Step [80/350], Avg Loss: 0.5322, Avg Dice: 0.5069\n",
            "Epoch [34/50], Step [85/350], Avg Loss: 0.5306, Avg Dice: 0.5039\n",
            "Epoch [34/50], Step [90/350], Avg Loss: 0.5305, Avg Dice: 0.5066\n",
            "Epoch [34/50], Step [95/350], Avg Loss: 0.5294, Avg Dice: 0.5038\n",
            "Epoch [34/50], Step [100/350], Avg Loss: 0.5311, Avg Dice: 0.5038\n",
            "Epoch [34/50], Step [105/350], Avg Loss: 0.5293, Avg Dice: 0.5044\n",
            "Epoch [34/50], Step [110/350], Avg Loss: 0.5290, Avg Dice: 0.5040\n",
            "Epoch [34/50], Step [115/350], Avg Loss: 0.5284, Avg Dice: 0.5037\n",
            "Epoch [34/50], Step [120/350], Avg Loss: 0.5289, Avg Dice: 0.5024\n",
            "Epoch [34/50], Step [125/350], Avg Loss: 0.5292, Avg Dice: 0.5007\n",
            "Epoch [34/50], Step [130/350], Avg Loss: 0.5303, Avg Dice: 0.4999\n",
            "Epoch [34/50], Step [135/350], Avg Loss: 0.5303, Avg Dice: 0.4994\n",
            "Epoch [34/50], Step [140/350], Avg Loss: 0.5299, Avg Dice: 0.5006\n",
            "Epoch [34/50], Step [145/350], Avg Loss: 0.5297, Avg Dice: 0.5017\n",
            "Epoch [34/50], Step [150/350], Avg Loss: 0.5297, Avg Dice: 0.5018\n",
            "Epoch [34/50], Step [155/350], Avg Loss: 0.5303, Avg Dice: 0.5014\n",
            "Epoch [34/50], Step [160/350], Avg Loss: 0.5298, Avg Dice: 0.5008\n",
            "Epoch [34/50], Step [165/350], Avg Loss: 0.5298, Avg Dice: 0.5015\n",
            "Epoch [34/50], Step [170/350], Avg Loss: 0.5296, Avg Dice: 0.5023\n",
            "Epoch [34/50], Step [175/350], Avg Loss: 0.5303, Avg Dice: 0.5018\n",
            "Epoch [34/50], Step [180/350], Avg Loss: 0.5305, Avg Dice: 0.5021\n",
            "Epoch [34/50], Step [185/350], Avg Loss: 0.5308, Avg Dice: 0.5024\n",
            "Epoch [34/50], Step [190/350], Avg Loss: 0.5313, Avg Dice: 0.5016\n",
            "Epoch [34/50], Step [195/350], Avg Loss: 0.5312, Avg Dice: 0.5021\n",
            "Epoch [34/50], Step [200/350], Avg Loss: 0.5317, Avg Dice: 0.5030\n",
            "Epoch [34/50], Step [205/350], Avg Loss: 0.5323, Avg Dice: 0.5030\n",
            "Epoch [34/50], Step [210/350], Avg Loss: 0.5330, Avg Dice: 0.5034\n",
            "Epoch [34/50], Step [215/350], Avg Loss: 0.5328, Avg Dice: 0.5048\n",
            "Epoch [34/50], Step [220/350], Avg Loss: 0.5326, Avg Dice: 0.5045\n",
            "Epoch [34/50], Step [225/350], Avg Loss: 0.5328, Avg Dice: 0.5050\n",
            "Epoch [34/50], Step [230/350], Avg Loss: 0.5325, Avg Dice: 0.5042\n",
            "Epoch [34/50], Step [235/350], Avg Loss: 0.5325, Avg Dice: 0.5039\n",
            "Epoch [34/50], Step [240/350], Avg Loss: 0.5327, Avg Dice: 0.5046\n",
            "Epoch [34/50], Step [245/350], Avg Loss: 0.5328, Avg Dice: 0.5059\n",
            "Epoch [34/50], Step [250/350], Avg Loss: 0.5328, Avg Dice: 0.5058\n",
            "Epoch [34/50], Step [255/350], Avg Loss: 0.5336, Avg Dice: 0.5060\n",
            "Epoch [34/50], Step [260/350], Avg Loss: 0.5341, Avg Dice: 0.5060\n",
            "Epoch [34/50], Step [265/350], Avg Loss: 0.5345, Avg Dice: 0.5062\n",
            "Epoch [34/50], Step [270/350], Avg Loss: 0.5349, Avg Dice: 0.5066\n",
            "Epoch [34/50], Step [275/350], Avg Loss: 0.5349, Avg Dice: 0.5067\n",
            "Epoch [34/50], Step [280/350], Avg Loss: 0.5350, Avg Dice: 0.5069\n",
            "Epoch [34/50], Step [285/350], Avg Loss: 0.5355, Avg Dice: 0.5063\n",
            "Epoch [34/50], Step [290/350], Avg Loss: 0.5357, Avg Dice: 0.5062\n",
            "Epoch [34/50], Step [295/350], Avg Loss: 0.5360, Avg Dice: 0.5062\n",
            "Epoch [34/50], Step [300/350], Avg Loss: 0.5361, Avg Dice: 0.5065\n",
            "Epoch [34/50], Step [305/350], Avg Loss: 0.5360, Avg Dice: 0.5063\n",
            "Epoch [34/50], Step [310/350], Avg Loss: 0.5356, Avg Dice: 0.5056\n",
            "Epoch [34/50], Step [315/350], Avg Loss: 0.5357, Avg Dice: 0.5054\n",
            "Epoch [34/50], Step [320/350], Avg Loss: 0.5359, Avg Dice: 0.5049\n",
            "Epoch [34/50], Step [325/350], Avg Loss: 0.5359, Avg Dice: 0.5044\n",
            "Epoch [34/50], Step [330/350], Avg Loss: 0.5359, Avg Dice: 0.5050\n",
            "Epoch [34/50], Step [335/350], Avg Loss: 0.5359, Avg Dice: 0.5055\n",
            "Epoch [34/50], Step [340/350], Avg Loss: 0.5362, Avg Dice: 0.5052\n",
            "Epoch [34/50], Step [345/350], Avg Loss: 0.5368, Avg Dice: 0.5060\n",
            "Epoch [34/50], Step [350/350], Avg Loss: 0.5367, Avg Dice: 0.5065\n",
            "End of epoch 34: Avg Loss: 0.5367, Avg Dice: 0.5065\n",
            "Epoch [35/50], Step [5/350], Avg Loss: 0.5306, Avg Dice: 0.4983\n",
            "Epoch [35/50], Step [10/350], Avg Loss: 0.5230, Avg Dice: 0.4844\n",
            "Epoch [35/50], Step [15/350], Avg Loss: 0.5271, Avg Dice: 0.4847\n",
            "Epoch [35/50], Step [20/350], Avg Loss: 0.5304, Avg Dice: 0.4934\n",
            "Epoch [35/50], Step [25/350], Avg Loss: 0.5350, Avg Dice: 0.5108\n",
            "Epoch [35/50], Step [30/350], Avg Loss: 0.5374, Avg Dice: 0.5093\n",
            "Epoch [35/50], Step [35/350], Avg Loss: 0.5314, Avg Dice: 0.5078\n",
            "Epoch [35/50], Step [40/350], Avg Loss: 0.5357, Avg Dice: 0.5100\n",
            "Epoch [35/50], Step [45/350], Avg Loss: 0.5339, Avg Dice: 0.5101\n",
            "Epoch [35/50], Step [50/350], Avg Loss: 0.5347, Avg Dice: 0.5109\n",
            "Epoch [35/50], Step [55/350], Avg Loss: 0.5356, Avg Dice: 0.5104\n",
            "Epoch [35/50], Step [60/350], Avg Loss: 0.5352, Avg Dice: 0.5073\n",
            "Epoch [35/50], Step [65/350], Avg Loss: 0.5331, Avg Dice: 0.5111\n",
            "Epoch [35/50], Step [70/350], Avg Loss: 0.5316, Avg Dice: 0.5152\n",
            "Epoch [35/50], Step [75/350], Avg Loss: 0.5319, Avg Dice: 0.5155\n",
            "Epoch [35/50], Step [80/350], Avg Loss: 0.5316, Avg Dice: 0.5146\n",
            "Epoch [35/50], Step [85/350], Avg Loss: 0.5305, Avg Dice: 0.5141\n",
            "Epoch [35/50], Step [90/350], Avg Loss: 0.5283, Avg Dice: 0.5126\n",
            "Epoch [35/50], Step [95/350], Avg Loss: 0.5290, Avg Dice: 0.5128\n",
            "Epoch [35/50], Step [100/350], Avg Loss: 0.5283, Avg Dice: 0.5140\n",
            "Epoch [35/50], Step [105/350], Avg Loss: 0.5298, Avg Dice: 0.5157\n",
            "Epoch [35/50], Step [110/350], Avg Loss: 0.5287, Avg Dice: 0.5147\n",
            "Epoch [35/50], Step [115/350], Avg Loss: 0.5291, Avg Dice: 0.5157\n",
            "Epoch [35/50], Step [120/350], Avg Loss: 0.5288, Avg Dice: 0.5155\n",
            "Epoch [35/50], Step [125/350], Avg Loss: 0.5287, Avg Dice: 0.5158\n",
            "Epoch [35/50], Step [130/350], Avg Loss: 0.5298, Avg Dice: 0.5162\n",
            "Epoch [35/50], Step [135/350], Avg Loss: 0.5297, Avg Dice: 0.5161\n",
            "Epoch [35/50], Step [140/350], Avg Loss: 0.5295, Avg Dice: 0.5175\n",
            "Epoch [35/50], Step [145/350], Avg Loss: 0.5296, Avg Dice: 0.5168\n",
            "Epoch [35/50], Step [150/350], Avg Loss: 0.5290, Avg Dice: 0.5172\n",
            "Epoch [35/50], Step [155/350], Avg Loss: 0.5298, Avg Dice: 0.5170\n",
            "Epoch [35/50], Step [160/350], Avg Loss: 0.5302, Avg Dice: 0.5174\n",
            "Epoch [35/50], Step [165/350], Avg Loss: 0.5301, Avg Dice: 0.5163\n",
            "Epoch [35/50], Step [170/350], Avg Loss: 0.5306, Avg Dice: 0.5145\n",
            "Epoch [35/50], Step [175/350], Avg Loss: 0.5303, Avg Dice: 0.5130\n",
            "Epoch [35/50], Step [180/350], Avg Loss: 0.5304, Avg Dice: 0.5129\n",
            "Epoch [35/50], Step [185/350], Avg Loss: 0.5296, Avg Dice: 0.5125\n",
            "Epoch [35/50], Step [190/350], Avg Loss: 0.5298, Avg Dice: 0.5118\n",
            "Epoch [35/50], Step [195/350], Avg Loss: 0.5302, Avg Dice: 0.5107\n",
            "Epoch [35/50], Step [200/350], Avg Loss: 0.5308, Avg Dice: 0.5112\n",
            "Epoch [35/50], Step [205/350], Avg Loss: 0.5309, Avg Dice: 0.5115\n",
            "Epoch [35/50], Step [210/350], Avg Loss: 0.5314, Avg Dice: 0.5116\n",
            "Epoch [35/50], Step [215/350], Avg Loss: 0.5314, Avg Dice: 0.5108\n",
            "Epoch [35/50], Step [220/350], Avg Loss: 0.5314, Avg Dice: 0.5112\n",
            "Epoch [35/50], Step [225/350], Avg Loss: 0.5316, Avg Dice: 0.5110\n",
            "Epoch [35/50], Step [230/350], Avg Loss: 0.5308, Avg Dice: 0.5108\n",
            "Epoch [35/50], Step [235/350], Avg Loss: 0.5306, Avg Dice: 0.5112\n",
            "Epoch [35/50], Step [240/350], Avg Loss: 0.5300, Avg Dice: 0.5117\n",
            "Epoch [35/50], Step [245/350], Avg Loss: 0.5297, Avg Dice: 0.5125\n",
            "Epoch [35/50], Step [250/350], Avg Loss: 0.5303, Avg Dice: 0.5129\n",
            "Epoch [35/50], Step [255/350], Avg Loss: 0.5304, Avg Dice: 0.5128\n",
            "Epoch [35/50], Step [260/350], Avg Loss: 0.5299, Avg Dice: 0.5129\n",
            "Epoch [35/50], Step [265/350], Avg Loss: 0.5305, Avg Dice: 0.5125\n",
            "Epoch [35/50], Step [270/350], Avg Loss: 0.5306, Avg Dice: 0.5129\n",
            "Epoch [35/50], Step [275/350], Avg Loss: 0.5312, Avg Dice: 0.5126\n",
            "Epoch [35/50], Step [280/350], Avg Loss: 0.5313, Avg Dice: 0.5135\n",
            "Epoch [35/50], Step [285/350], Avg Loss: 0.5318, Avg Dice: 0.5130\n",
            "Epoch [35/50], Step [290/350], Avg Loss: 0.5312, Avg Dice: 0.5133\n",
            "Epoch [35/50], Step [295/350], Avg Loss: 0.5310, Avg Dice: 0.5132\n",
            "Epoch [35/50], Step [300/350], Avg Loss: 0.5312, Avg Dice: 0.5129\n",
            "Epoch [35/50], Step [305/350], Avg Loss: 0.5314, Avg Dice: 0.5124\n",
            "Epoch [35/50], Step [310/350], Avg Loss: 0.5316, Avg Dice: 0.5124\n",
            "Epoch [35/50], Step [315/350], Avg Loss: 0.5310, Avg Dice: 0.5125\n",
            "Epoch [35/50], Step [320/350], Avg Loss: 0.5308, Avg Dice: 0.5124\n",
            "Epoch [35/50], Step [325/350], Avg Loss: 0.5306, Avg Dice: 0.5131\n",
            "Epoch [35/50], Step [330/350], Avg Loss: 0.5310, Avg Dice: 0.5123\n",
            "Epoch [35/50], Step [335/350], Avg Loss: 0.5312, Avg Dice: 0.5124\n",
            "Epoch [35/50], Step [340/350], Avg Loss: 0.5307, Avg Dice: 0.5123\n",
            "Epoch [35/50], Step [345/350], Avg Loss: 0.5309, Avg Dice: 0.5124\n",
            "Epoch [35/50], Step [350/350], Avg Loss: 0.5307, Avg Dice: 0.5125\n",
            "End of epoch 35: Avg Loss: 0.5307, Avg Dice: 0.5125\n",
            "Epoch [36/50], Step [5/350], Avg Loss: 0.5166, Avg Dice: 0.5242\n",
            "Epoch [36/50], Step [10/350], Avg Loss: 0.5101, Avg Dice: 0.5341\n",
            "Epoch [36/50], Step [15/350], Avg Loss: 0.5093, Avg Dice: 0.5232\n",
            "Epoch [36/50], Step [20/350], Avg Loss: 0.5045, Avg Dice: 0.5314\n",
            "Epoch [36/50], Step [25/350], Avg Loss: 0.5086, Avg Dice: 0.5153\n",
            "Epoch [36/50], Step [30/350], Avg Loss: 0.5089, Avg Dice: 0.5125\n",
            "Epoch [36/50], Step [35/350], Avg Loss: 0.5139, Avg Dice: 0.5074\n",
            "Epoch [36/50], Step [40/350], Avg Loss: 0.5118, Avg Dice: 0.5092\n",
            "Epoch [36/50], Step [45/350], Avg Loss: 0.5070, Avg Dice: 0.5125\n",
            "Epoch [36/50], Step [50/350], Avg Loss: 0.5069, Avg Dice: 0.5104\n",
            "Epoch [36/50], Step [55/350], Avg Loss: 0.5081, Avg Dice: 0.5112\n",
            "Epoch [36/50], Step [60/350], Avg Loss: 0.5106, Avg Dice: 0.5083\n",
            "Epoch [36/50], Step [65/350], Avg Loss: 0.5110, Avg Dice: 0.5128\n",
            "Epoch [36/50], Step [70/350], Avg Loss: 0.5096, Avg Dice: 0.5123\n",
            "Epoch [36/50], Step [75/350], Avg Loss: 0.5083, Avg Dice: 0.5140\n",
            "Epoch [36/50], Step [80/350], Avg Loss: 0.5065, Avg Dice: 0.5144\n",
            "Epoch [36/50], Step [85/350], Avg Loss: 0.5071, Avg Dice: 0.5146\n",
            "Epoch [36/50], Step [90/350], Avg Loss: 0.5069, Avg Dice: 0.5137\n",
            "Epoch [36/50], Step [95/350], Avg Loss: 0.5079, Avg Dice: 0.5149\n",
            "Epoch [36/50], Step [100/350], Avg Loss: 0.5088, Avg Dice: 0.5147\n",
            "Epoch [36/50], Step [105/350], Avg Loss: 0.5093, Avg Dice: 0.5156\n",
            "Epoch [36/50], Step [110/350], Avg Loss: 0.5094, Avg Dice: 0.5147\n",
            "Epoch [36/50], Step [115/350], Avg Loss: 0.5103, Avg Dice: 0.5155\n",
            "Epoch [36/50], Step [120/350], Avg Loss: 0.5104, Avg Dice: 0.5152\n",
            "Epoch [36/50], Step [125/350], Avg Loss: 0.5109, Avg Dice: 0.5158\n",
            "Epoch [36/50], Step [130/350], Avg Loss: 0.5109, Avg Dice: 0.5164\n",
            "Epoch [36/50], Step [135/350], Avg Loss: 0.5116, Avg Dice: 0.5170\n",
            "Epoch [36/50], Step [140/350], Avg Loss: 0.5119, Avg Dice: 0.5183\n",
            "Epoch [36/50], Step [145/350], Avg Loss: 0.5120, Avg Dice: 0.5191\n",
            "Epoch [36/50], Step [150/350], Avg Loss: 0.5130, Avg Dice: 0.5186\n",
            "Epoch [36/50], Step [155/350], Avg Loss: 0.5139, Avg Dice: 0.5178\n",
            "Epoch [36/50], Step [160/350], Avg Loss: 0.5140, Avg Dice: 0.5188\n",
            "Epoch [36/50], Step [165/350], Avg Loss: 0.5136, Avg Dice: 0.5191\n",
            "Epoch [36/50], Step [170/350], Avg Loss: 0.5141, Avg Dice: 0.5195\n",
            "Epoch [36/50], Step [175/350], Avg Loss: 0.5152, Avg Dice: 0.5200\n",
            "Epoch [36/50], Step [180/350], Avg Loss: 0.5160, Avg Dice: 0.5192\n",
            "Epoch [36/50], Step [185/350], Avg Loss: 0.5174, Avg Dice: 0.5183\n",
            "Epoch [36/50], Step [190/350], Avg Loss: 0.5176, Avg Dice: 0.5175\n",
            "Epoch [36/50], Step [195/350], Avg Loss: 0.5180, Avg Dice: 0.5177\n",
            "Epoch [36/50], Step [200/350], Avg Loss: 0.5180, Avg Dice: 0.5166\n",
            "Epoch [36/50], Step [205/350], Avg Loss: 0.5178, Avg Dice: 0.5167\n",
            "Epoch [36/50], Step [210/350], Avg Loss: 0.5179, Avg Dice: 0.5163\n",
            "Epoch [36/50], Step [215/350], Avg Loss: 0.5185, Avg Dice: 0.5159\n",
            "Epoch [36/50], Step [220/350], Avg Loss: 0.5176, Avg Dice: 0.5152\n",
            "Epoch [36/50], Step [225/350], Avg Loss: 0.5170, Avg Dice: 0.5149\n",
            "Epoch [36/50], Step [230/350], Avg Loss: 0.5168, Avg Dice: 0.5145\n",
            "Epoch [36/50], Step [235/350], Avg Loss: 0.5167, Avg Dice: 0.5150\n",
            "Epoch [36/50], Step [240/350], Avg Loss: 0.5167, Avg Dice: 0.5151\n",
            "Epoch [36/50], Step [245/350], Avg Loss: 0.5170, Avg Dice: 0.5146\n",
            "Epoch [36/50], Step [250/350], Avg Loss: 0.5166, Avg Dice: 0.5153\n",
            "Epoch [36/50], Step [255/350], Avg Loss: 0.5161, Avg Dice: 0.5150\n",
            "Epoch [36/50], Step [260/350], Avg Loss: 0.5163, Avg Dice: 0.5152\n",
            "Epoch [36/50], Step [265/350], Avg Loss: 0.5164, Avg Dice: 0.5149\n",
            "Epoch [36/50], Step [270/350], Avg Loss: 0.5167, Avg Dice: 0.5154\n",
            "Epoch [36/50], Step [275/350], Avg Loss: 0.5164, Avg Dice: 0.5162\n",
            "Epoch [36/50], Step [280/350], Avg Loss: 0.5166, Avg Dice: 0.5156\n",
            "Epoch [36/50], Step [285/350], Avg Loss: 0.5170, Avg Dice: 0.5155\n",
            "Epoch [36/50], Step [290/350], Avg Loss: 0.5181, Avg Dice: 0.5153\n",
            "Epoch [36/50], Step [295/350], Avg Loss: 0.5178, Avg Dice: 0.5148\n",
            "Epoch [36/50], Step [300/350], Avg Loss: 0.5178, Avg Dice: 0.5149\n",
            "Epoch [36/50], Step [305/350], Avg Loss: 0.5183, Avg Dice: 0.5146\n",
            "Epoch [36/50], Step [310/350], Avg Loss: 0.5190, Avg Dice: 0.5142\n",
            "Epoch [36/50], Step [315/350], Avg Loss: 0.5193, Avg Dice: 0.5143\n",
            "Epoch [36/50], Step [320/350], Avg Loss: 0.5197, Avg Dice: 0.5148\n",
            "Epoch [36/50], Step [325/350], Avg Loss: 0.5196, Avg Dice: 0.5150\n",
            "Epoch [36/50], Step [330/350], Avg Loss: 0.5198, Avg Dice: 0.5141\n",
            "Epoch [36/50], Step [335/350], Avg Loss: 0.5200, Avg Dice: 0.5142\n",
            "Epoch [36/50], Step [340/350], Avg Loss: 0.5206, Avg Dice: 0.5138\n",
            "Epoch [36/50], Step [345/350], Avg Loss: 0.5206, Avg Dice: 0.5135\n",
            "Epoch [36/50], Step [350/350], Avg Loss: 0.5210, Avg Dice: 0.5135\n",
            "End of epoch 36: Avg Loss: 0.5210, Avg Dice: 0.5135\n",
            "Epoch [37/50], Step [5/350], Avg Loss: 0.5309, Avg Dice: 0.4775\n",
            "Epoch [37/50], Step [10/350], Avg Loss: 0.5074, Avg Dice: 0.5000\n",
            "Epoch [37/50], Step [15/350], Avg Loss: 0.5162, Avg Dice: 0.4970\n",
            "Epoch [37/50], Step [20/350], Avg Loss: 0.5187, Avg Dice: 0.5003\n",
            "Epoch [37/50], Step [25/350], Avg Loss: 0.5214, Avg Dice: 0.5064\n",
            "Epoch [37/50], Step [30/350], Avg Loss: 0.5202, Avg Dice: 0.4982\n",
            "Epoch [37/50], Step [35/350], Avg Loss: 0.5212, Avg Dice: 0.5031\n",
            "Epoch [37/50], Step [40/350], Avg Loss: 0.5197, Avg Dice: 0.5057\n",
            "Epoch [37/50], Step [45/350], Avg Loss: 0.5189, Avg Dice: 0.5115\n",
            "Epoch [37/50], Step [50/350], Avg Loss: 0.5173, Avg Dice: 0.5202\n",
            "Epoch [37/50], Step [55/350], Avg Loss: 0.5126, Avg Dice: 0.5248\n",
            "Epoch [37/50], Step [60/350], Avg Loss: 0.5129, Avg Dice: 0.5231\n",
            "Epoch [37/50], Step [65/350], Avg Loss: 0.5103, Avg Dice: 0.5211\n",
            "Epoch [37/50], Step [70/350], Avg Loss: 0.5105, Avg Dice: 0.5209\n",
            "Epoch [37/50], Step [75/350], Avg Loss: 0.5087, Avg Dice: 0.5242\n",
            "Epoch [37/50], Step [80/350], Avg Loss: 0.5061, Avg Dice: 0.5251\n",
            "Epoch [37/50], Step [85/350], Avg Loss: 0.5079, Avg Dice: 0.5225\n",
            "Epoch [37/50], Step [90/350], Avg Loss: 0.5082, Avg Dice: 0.5215\n",
            "Epoch [37/50], Step [95/350], Avg Loss: 0.5075, Avg Dice: 0.5203\n",
            "Epoch [37/50], Step [100/350], Avg Loss: 0.5082, Avg Dice: 0.5218\n",
            "Epoch [37/50], Step [105/350], Avg Loss: 0.5090, Avg Dice: 0.5210\n",
            "Epoch [37/50], Step [110/350], Avg Loss: 0.5097, Avg Dice: 0.5225\n",
            "Epoch [37/50], Step [115/350], Avg Loss: 0.5099, Avg Dice: 0.5207\n",
            "Epoch [37/50], Step [120/350], Avg Loss: 0.5095, Avg Dice: 0.5204\n",
            "Epoch [37/50], Step [125/350], Avg Loss: 0.5107, Avg Dice: 0.5196\n",
            "Epoch [37/50], Step [130/350], Avg Loss: 0.5102, Avg Dice: 0.5179\n",
            "Epoch [37/50], Step [135/350], Avg Loss: 0.5090, Avg Dice: 0.5185\n",
            "Epoch [37/50], Step [140/350], Avg Loss: 0.5097, Avg Dice: 0.5187\n",
            "Epoch [37/50], Step [145/350], Avg Loss: 0.5104, Avg Dice: 0.5197\n",
            "Epoch [37/50], Step [150/350], Avg Loss: 0.5106, Avg Dice: 0.5199\n",
            "Epoch [37/50], Step [155/350], Avg Loss: 0.5106, Avg Dice: 0.5210\n",
            "Epoch [37/50], Step [160/350], Avg Loss: 0.5111, Avg Dice: 0.5206\n",
            "Epoch [37/50], Step [165/350], Avg Loss: 0.5111, Avg Dice: 0.5207\n",
            "Epoch [37/50], Step [170/350], Avg Loss: 0.5120, Avg Dice: 0.5195\n",
            "Epoch [37/50], Step [175/350], Avg Loss: 0.5130, Avg Dice: 0.5189\n",
            "Epoch [37/50], Step [180/350], Avg Loss: 0.5134, Avg Dice: 0.5201\n",
            "Epoch [37/50], Step [185/350], Avg Loss: 0.5140, Avg Dice: 0.5193\n",
            "Epoch [37/50], Step [190/350], Avg Loss: 0.5142, Avg Dice: 0.5189\n",
            "Epoch [37/50], Step [195/350], Avg Loss: 0.5149, Avg Dice: 0.5182\n",
            "Epoch [37/50], Step [200/350], Avg Loss: 0.5142, Avg Dice: 0.5194\n",
            "Epoch [37/50], Step [205/350], Avg Loss: 0.5142, Avg Dice: 0.5205\n",
            "Epoch [37/50], Step [210/350], Avg Loss: 0.5135, Avg Dice: 0.5201\n",
            "Epoch [37/50], Step [215/350], Avg Loss: 0.5143, Avg Dice: 0.5196\n",
            "Epoch [37/50], Step [220/350], Avg Loss: 0.5136, Avg Dice: 0.5204\n",
            "Epoch [37/50], Step [225/350], Avg Loss: 0.5143, Avg Dice: 0.5207\n",
            "Epoch [37/50], Step [230/350], Avg Loss: 0.5146, Avg Dice: 0.5212\n",
            "Epoch [37/50], Step [235/350], Avg Loss: 0.5149, Avg Dice: 0.5214\n",
            "Epoch [37/50], Step [240/350], Avg Loss: 0.5153, Avg Dice: 0.5209\n",
            "Epoch [37/50], Step [245/350], Avg Loss: 0.5154, Avg Dice: 0.5219\n",
            "Epoch [37/50], Step [250/350], Avg Loss: 0.5155, Avg Dice: 0.5221\n",
            "Epoch [37/50], Step [255/350], Avg Loss: 0.5153, Avg Dice: 0.5222\n",
            "Epoch [37/50], Step [260/350], Avg Loss: 0.5152, Avg Dice: 0.5225\n",
            "Epoch [37/50], Step [265/350], Avg Loss: 0.5154, Avg Dice: 0.5217\n",
            "Epoch [37/50], Step [270/350], Avg Loss: 0.5156, Avg Dice: 0.5208\n",
            "Epoch [37/50], Step [275/350], Avg Loss: 0.5153, Avg Dice: 0.5210\n",
            "Epoch [37/50], Step [280/350], Avg Loss: 0.5153, Avg Dice: 0.5208\n",
            "Epoch [37/50], Step [285/350], Avg Loss: 0.5158, Avg Dice: 0.5202\n",
            "Epoch [37/50], Step [290/350], Avg Loss: 0.5154, Avg Dice: 0.5200\n",
            "Epoch [37/50], Step [295/350], Avg Loss: 0.5148, Avg Dice: 0.5202\n",
            "Epoch [37/50], Step [300/350], Avg Loss: 0.5151, Avg Dice: 0.5198\n",
            "Epoch [37/50], Step [305/350], Avg Loss: 0.5153, Avg Dice: 0.5201\n",
            "Epoch [37/50], Step [310/350], Avg Loss: 0.5152, Avg Dice: 0.5204\n",
            "Epoch [37/50], Step [315/350], Avg Loss: 0.5157, Avg Dice: 0.5201\n",
            "Epoch [37/50], Step [320/350], Avg Loss: 0.5164, Avg Dice: 0.5205\n",
            "Epoch [37/50], Step [325/350], Avg Loss: 0.5163, Avg Dice: 0.5204\n",
            "Epoch [37/50], Step [330/350], Avg Loss: 0.5163, Avg Dice: 0.5205\n",
            "Epoch [37/50], Step [335/350], Avg Loss: 0.5161, Avg Dice: 0.5206\n",
            "Epoch [37/50], Step [340/350], Avg Loss: 0.5161, Avg Dice: 0.5206\n",
            "Epoch [37/50], Step [345/350], Avg Loss: 0.5162, Avg Dice: 0.5203\n",
            "Epoch [37/50], Step [350/350], Avg Loss: 0.5162, Avg Dice: 0.5204\n",
            "End of epoch 37: Avg Loss: 0.5162, Avg Dice: 0.5204\n",
            "Epoch [38/50], Step [5/350], Avg Loss: 0.5186, Avg Dice: 0.5213\n",
            "Epoch [38/50], Step [10/350], Avg Loss: 0.5062, Avg Dice: 0.5189\n",
            "Epoch [38/50], Step [15/350], Avg Loss: 0.5163, Avg Dice: 0.5138\n",
            "Epoch [38/50], Step [20/350], Avg Loss: 0.5166, Avg Dice: 0.5210\n",
            "Epoch [38/50], Step [25/350], Avg Loss: 0.5164, Avg Dice: 0.5201\n",
            "Epoch [38/50], Step [30/350], Avg Loss: 0.5188, Avg Dice: 0.5188\n",
            "Epoch [38/50], Step [35/350], Avg Loss: 0.5207, Avg Dice: 0.5161\n",
            "Epoch [38/50], Step [40/350], Avg Loss: 0.5169, Avg Dice: 0.5131\n",
            "Epoch [38/50], Step [45/350], Avg Loss: 0.5144, Avg Dice: 0.5150\n",
            "Epoch [38/50], Step [50/350], Avg Loss: 0.5161, Avg Dice: 0.5148\n",
            "Epoch [38/50], Step [55/350], Avg Loss: 0.5142, Avg Dice: 0.5141\n",
            "Epoch [38/50], Step [60/350], Avg Loss: 0.5132, Avg Dice: 0.5160\n",
            "Epoch [38/50], Step [65/350], Avg Loss: 0.5128, Avg Dice: 0.5157\n",
            "Epoch [38/50], Step [70/350], Avg Loss: 0.5131, Avg Dice: 0.5184\n",
            "Epoch [38/50], Step [75/350], Avg Loss: 0.5117, Avg Dice: 0.5181\n",
            "Epoch [38/50], Step [80/350], Avg Loss: 0.5103, Avg Dice: 0.5162\n",
            "Epoch [38/50], Step [85/350], Avg Loss: 0.5108, Avg Dice: 0.5167\n",
            "Epoch [38/50], Step [90/350], Avg Loss: 0.5094, Avg Dice: 0.5176\n",
            "Epoch [38/50], Step [95/350], Avg Loss: 0.5109, Avg Dice: 0.5154\n",
            "Epoch [38/50], Step [100/350], Avg Loss: 0.5119, Avg Dice: 0.5148\n",
            "Epoch [38/50], Step [105/350], Avg Loss: 0.5132, Avg Dice: 0.5165\n",
            "Epoch [38/50], Step [110/350], Avg Loss: 0.5142, Avg Dice: 0.5156\n",
            "Epoch [38/50], Step [115/350], Avg Loss: 0.5139, Avg Dice: 0.5156\n",
            "Epoch [38/50], Step [120/350], Avg Loss: 0.5122, Avg Dice: 0.5156\n",
            "Epoch [38/50], Step [125/350], Avg Loss: 0.5111, Avg Dice: 0.5157\n",
            "Epoch [38/50], Step [130/350], Avg Loss: 0.5108, Avg Dice: 0.5164\n",
            "Epoch [38/50], Step [135/350], Avg Loss: 0.5095, Avg Dice: 0.5164\n",
            "Epoch [38/50], Step [140/350], Avg Loss: 0.5095, Avg Dice: 0.5164\n",
            "Epoch [38/50], Step [145/350], Avg Loss: 0.5104, Avg Dice: 0.5146\n",
            "Epoch [38/50], Step [150/350], Avg Loss: 0.5093, Avg Dice: 0.5140\n",
            "Epoch [38/50], Step [155/350], Avg Loss: 0.5091, Avg Dice: 0.5144\n",
            "Epoch [38/50], Step [160/350], Avg Loss: 0.5087, Avg Dice: 0.5142\n",
            "Epoch [38/50], Step [165/350], Avg Loss: 0.5088, Avg Dice: 0.5145\n",
            "Epoch [38/50], Step [170/350], Avg Loss: 0.5083, Avg Dice: 0.5149\n",
            "Epoch [38/50], Step [175/350], Avg Loss: 0.5095, Avg Dice: 0.5156\n",
            "Epoch [38/50], Step [180/350], Avg Loss: 0.5091, Avg Dice: 0.5153\n",
            "Epoch [38/50], Step [185/350], Avg Loss: 0.5095, Avg Dice: 0.5148\n",
            "Epoch [38/50], Step [190/350], Avg Loss: 0.5088, Avg Dice: 0.5142\n",
            "Epoch [38/50], Step [195/350], Avg Loss: 0.5088, Avg Dice: 0.5144\n",
            "Epoch [38/50], Step [200/350], Avg Loss: 0.5086, Avg Dice: 0.5134\n",
            "Epoch [38/50], Step [205/350], Avg Loss: 0.5082, Avg Dice: 0.5134\n",
            "Epoch [38/50], Step [210/350], Avg Loss: 0.5077, Avg Dice: 0.5133\n",
            "Epoch [38/50], Step [215/350], Avg Loss: 0.5084, Avg Dice: 0.5131\n",
            "Epoch [38/50], Step [220/350], Avg Loss: 0.5088, Avg Dice: 0.5120\n",
            "Epoch [38/50], Step [225/350], Avg Loss: 0.5087, Avg Dice: 0.5127\n",
            "Epoch [38/50], Step [230/350], Avg Loss: 0.5088, Avg Dice: 0.5133\n",
            "Epoch [38/50], Step [235/350], Avg Loss: 0.5083, Avg Dice: 0.5134\n",
            "Epoch [38/50], Step [240/350], Avg Loss: 0.5091, Avg Dice: 0.5148\n",
            "Epoch [38/50], Step [245/350], Avg Loss: 0.5095, Avg Dice: 0.5158\n",
            "Epoch [38/50], Step [250/350], Avg Loss: 0.5089, Avg Dice: 0.5177\n",
            "Epoch [38/50], Step [255/350], Avg Loss: 0.5085, Avg Dice: 0.5176\n",
            "Epoch [38/50], Step [260/350], Avg Loss: 0.5085, Avg Dice: 0.5175\n",
            "Epoch [38/50], Step [265/350], Avg Loss: 0.5089, Avg Dice: 0.5184\n",
            "Epoch [38/50], Step [270/350], Avg Loss: 0.5090, Avg Dice: 0.5184\n",
            "Epoch [38/50], Step [275/350], Avg Loss: 0.5089, Avg Dice: 0.5185\n",
            "Epoch [38/50], Step [280/350], Avg Loss: 0.5091, Avg Dice: 0.5184\n",
            "Epoch [38/50], Step [285/350], Avg Loss: 0.5092, Avg Dice: 0.5187\n",
            "Epoch [38/50], Step [290/350], Avg Loss: 0.5092, Avg Dice: 0.5194\n",
            "Epoch [38/50], Step [295/350], Avg Loss: 0.5096, Avg Dice: 0.5193\n",
            "Epoch [38/50], Step [300/350], Avg Loss: 0.5098, Avg Dice: 0.5195\n",
            "Epoch [38/50], Step [305/350], Avg Loss: 0.5097, Avg Dice: 0.5203\n",
            "Epoch [38/50], Step [310/350], Avg Loss: 0.5097, Avg Dice: 0.5204\n",
            "Epoch [38/50], Step [315/350], Avg Loss: 0.5095, Avg Dice: 0.5207\n",
            "Epoch [38/50], Step [320/350], Avg Loss: 0.5099, Avg Dice: 0.5206\n",
            "Epoch [38/50], Step [325/350], Avg Loss: 0.5099, Avg Dice: 0.5204\n",
            "Epoch [38/50], Step [330/350], Avg Loss: 0.5106, Avg Dice: 0.5202\n",
            "Epoch [38/50], Step [335/350], Avg Loss: 0.5106, Avg Dice: 0.5197\n",
            "Epoch [38/50], Step [340/350], Avg Loss: 0.5113, Avg Dice: 0.5203\n",
            "Epoch [38/50], Step [345/350], Avg Loss: 0.5109, Avg Dice: 0.5209\n",
            "Epoch [38/50], Step [350/350], Avg Loss: 0.5107, Avg Dice: 0.5210\n",
            "End of epoch 38: Avg Loss: 0.5107, Avg Dice: 0.5210\n",
            "Epoch [39/50], Step [5/350], Avg Loss: 0.4722, Avg Dice: 0.5332\n",
            "Epoch [39/50], Step [10/350], Avg Loss: 0.4856, Avg Dice: 0.5436\n",
            "Epoch [39/50], Step [15/350], Avg Loss: 0.5015, Avg Dice: 0.5343\n",
            "Epoch [39/50], Step [20/350], Avg Loss: 0.5020, Avg Dice: 0.5387\n",
            "Epoch [39/50], Step [25/350], Avg Loss: 0.5037, Avg Dice: 0.5259\n",
            "Epoch [39/50], Step [30/350], Avg Loss: 0.5021, Avg Dice: 0.5220\n",
            "Epoch [39/50], Step [35/350], Avg Loss: 0.4967, Avg Dice: 0.5271\n",
            "Epoch [39/50], Step [40/350], Avg Loss: 0.4972, Avg Dice: 0.5238\n",
            "Epoch [39/50], Step [45/350], Avg Loss: 0.4933, Avg Dice: 0.5274\n",
            "Epoch [39/50], Step [50/350], Avg Loss: 0.4932, Avg Dice: 0.5295\n",
            "Epoch [39/50], Step [55/350], Avg Loss: 0.4939, Avg Dice: 0.5298\n",
            "Epoch [39/50], Step [60/350], Avg Loss: 0.4925, Avg Dice: 0.5289\n",
            "Epoch [39/50], Step [65/350], Avg Loss: 0.4919, Avg Dice: 0.5267\n",
            "Epoch [39/50], Step [70/350], Avg Loss: 0.4917, Avg Dice: 0.5236\n",
            "Epoch [39/50], Step [75/350], Avg Loss: 0.4906, Avg Dice: 0.5256\n",
            "Epoch [39/50], Step [80/350], Avg Loss: 0.4902, Avg Dice: 0.5231\n",
            "Epoch [39/50], Step [85/350], Avg Loss: 0.4903, Avg Dice: 0.5205\n",
            "Epoch [39/50], Step [90/350], Avg Loss: 0.4892, Avg Dice: 0.5220\n",
            "Epoch [39/50], Step [95/350], Avg Loss: 0.4918, Avg Dice: 0.5204\n",
            "Epoch [39/50], Step [100/350], Avg Loss: 0.4918, Avg Dice: 0.5213\n",
            "Epoch [39/50], Step [105/350], Avg Loss: 0.4939, Avg Dice: 0.5216\n",
            "Epoch [39/50], Step [110/350], Avg Loss: 0.4939, Avg Dice: 0.5228\n",
            "Epoch [39/50], Step [115/350], Avg Loss: 0.4939, Avg Dice: 0.5228\n",
            "Epoch [39/50], Step [120/350], Avg Loss: 0.4954, Avg Dice: 0.5252\n",
            "Epoch [39/50], Step [125/350], Avg Loss: 0.4961, Avg Dice: 0.5256\n",
            "Epoch [39/50], Step [130/350], Avg Loss: 0.4969, Avg Dice: 0.5250\n",
            "Epoch [39/50], Step [135/350], Avg Loss: 0.4968, Avg Dice: 0.5245\n",
            "Epoch [39/50], Step [140/350], Avg Loss: 0.4979, Avg Dice: 0.5247\n",
            "Epoch [39/50], Step [145/350], Avg Loss: 0.4984, Avg Dice: 0.5235\n",
            "Epoch [39/50], Step [150/350], Avg Loss: 0.4984, Avg Dice: 0.5230\n",
            "Epoch [39/50], Step [155/350], Avg Loss: 0.4991, Avg Dice: 0.5235\n",
            "Epoch [39/50], Step [160/350], Avg Loss: 0.4985, Avg Dice: 0.5245\n",
            "Epoch [39/50], Step [165/350], Avg Loss: 0.4985, Avg Dice: 0.5232\n",
            "Epoch [39/50], Step [170/350], Avg Loss: 0.4992, Avg Dice: 0.5232\n",
            "Epoch [39/50], Step [175/350], Avg Loss: 0.4984, Avg Dice: 0.5243\n",
            "Epoch [39/50], Step [180/350], Avg Loss: 0.4979, Avg Dice: 0.5244\n",
            "Epoch [39/50], Step [185/350], Avg Loss: 0.4983, Avg Dice: 0.5251\n",
            "Epoch [39/50], Step [190/350], Avg Loss: 0.4985, Avg Dice: 0.5258\n",
            "Epoch [39/50], Step [195/350], Avg Loss: 0.4987, Avg Dice: 0.5254\n",
            "Epoch [39/50], Step [200/350], Avg Loss: 0.4992, Avg Dice: 0.5258\n",
            "Epoch [39/50], Step [205/350], Avg Loss: 0.4993, Avg Dice: 0.5253\n",
            "Epoch [39/50], Step [210/350], Avg Loss: 0.4983, Avg Dice: 0.5265\n",
            "Epoch [39/50], Step [215/350], Avg Loss: 0.4980, Avg Dice: 0.5261\n",
            "Epoch [39/50], Step [220/350], Avg Loss: 0.4986, Avg Dice: 0.5266\n",
            "Epoch [39/50], Step [225/350], Avg Loss: 0.4986, Avg Dice: 0.5265\n",
            "Epoch [39/50], Step [230/350], Avg Loss: 0.4983, Avg Dice: 0.5270\n",
            "Epoch [39/50], Step [235/350], Avg Loss: 0.4979, Avg Dice: 0.5253\n",
            "Epoch [39/50], Step [240/350], Avg Loss: 0.4986, Avg Dice: 0.5249\n",
            "Epoch [39/50], Step [245/350], Avg Loss: 0.4986, Avg Dice: 0.5256\n",
            "Epoch [39/50], Step [250/350], Avg Loss: 0.4983, Avg Dice: 0.5265\n",
            "Epoch [39/50], Step [255/350], Avg Loss: 0.4982, Avg Dice: 0.5267\n",
            "Epoch [39/50], Step [260/350], Avg Loss: 0.4987, Avg Dice: 0.5267\n",
            "Epoch [39/50], Step [265/350], Avg Loss: 0.4987, Avg Dice: 0.5258\n",
            "Epoch [39/50], Step [270/350], Avg Loss: 0.4984, Avg Dice: 0.5254\n",
            "Epoch [39/50], Step [275/350], Avg Loss: 0.4992, Avg Dice: 0.5246\n",
            "Epoch [39/50], Step [280/350], Avg Loss: 0.4993, Avg Dice: 0.5249\n",
            "Epoch [39/50], Step [285/350], Avg Loss: 0.4991, Avg Dice: 0.5245\n",
            "Epoch [39/50], Step [290/350], Avg Loss: 0.4989, Avg Dice: 0.5250\n",
            "Epoch [39/50], Step [295/350], Avg Loss: 0.4991, Avg Dice: 0.5248\n",
            "Epoch [39/50], Step [300/350], Avg Loss: 0.4991, Avg Dice: 0.5251\n",
            "Epoch [39/50], Step [305/350], Avg Loss: 0.4991, Avg Dice: 0.5250\n",
            "Epoch [39/50], Step [310/350], Avg Loss: 0.4995, Avg Dice: 0.5251\n",
            "Epoch [39/50], Step [315/350], Avg Loss: 0.4997, Avg Dice: 0.5248\n",
            "Epoch [39/50], Step [320/350], Avg Loss: 0.4995, Avg Dice: 0.5253\n",
            "Epoch [39/50], Step [325/350], Avg Loss: 0.4996, Avg Dice: 0.5252\n",
            "Epoch [39/50], Step [330/350], Avg Loss: 0.4991, Avg Dice: 0.5253\n",
            "Epoch [39/50], Step [335/350], Avg Loss: 0.4998, Avg Dice: 0.5252\n",
            "Epoch [39/50], Step [340/350], Avg Loss: 0.4999, Avg Dice: 0.5249\n",
            "Epoch [39/50], Step [345/350], Avg Loss: 0.5000, Avg Dice: 0.5250\n",
            "Epoch [39/50], Step [350/350], Avg Loss: 0.5000, Avg Dice: 0.5250\n",
            "End of epoch 39: Avg Loss: 0.5000, Avg Dice: 0.5250\n",
            "Epoch [40/50], Step [5/350], Avg Loss: 0.5125, Avg Dice: 0.5558\n",
            "Epoch [40/50], Step [10/350], Avg Loss: 0.5162, Avg Dice: 0.5306\n",
            "Epoch [40/50], Step [15/350], Avg Loss: 0.5027, Avg Dice: 0.5369\n",
            "Epoch [40/50], Step [20/350], Avg Loss: 0.4983, Avg Dice: 0.5262\n",
            "Epoch [40/50], Step [25/350], Avg Loss: 0.4957, Avg Dice: 0.5164\n",
            "Epoch [40/50], Step [30/350], Avg Loss: 0.4966, Avg Dice: 0.5248\n",
            "Epoch [40/50], Step [35/350], Avg Loss: 0.4962, Avg Dice: 0.5316\n",
            "Epoch [40/50], Step [40/350], Avg Loss: 0.4945, Avg Dice: 0.5301\n",
            "Epoch [40/50], Step [45/350], Avg Loss: 0.4972, Avg Dice: 0.5327\n",
            "Epoch [40/50], Step [50/350], Avg Loss: 0.4967, Avg Dice: 0.5339\n",
            "Epoch [40/50], Step [55/350], Avg Loss: 0.4970, Avg Dice: 0.5349\n",
            "Epoch [40/50], Step [60/350], Avg Loss: 0.4964, Avg Dice: 0.5366\n",
            "Epoch [40/50], Step [65/350], Avg Loss: 0.4974, Avg Dice: 0.5319\n",
            "Epoch [40/50], Step [70/350], Avg Loss: 0.4961, Avg Dice: 0.5335\n",
            "Epoch [40/50], Step [75/350], Avg Loss: 0.4964, Avg Dice: 0.5330\n",
            "Epoch [40/50], Step [80/350], Avg Loss: 0.4946, Avg Dice: 0.5320\n",
            "Epoch [40/50], Step [85/350], Avg Loss: 0.4944, Avg Dice: 0.5291\n",
            "Epoch [40/50], Step [90/350], Avg Loss: 0.4927, Avg Dice: 0.5295\n",
            "Epoch [40/50], Step [95/350], Avg Loss: 0.4914, Avg Dice: 0.5299\n",
            "Epoch [40/50], Step [100/350], Avg Loss: 0.4911, Avg Dice: 0.5327\n",
            "Epoch [40/50], Step [105/350], Avg Loss: 0.4897, Avg Dice: 0.5351\n",
            "Epoch [40/50], Step [110/350], Avg Loss: 0.4897, Avg Dice: 0.5350\n",
            "Epoch [40/50], Step [115/350], Avg Loss: 0.4891, Avg Dice: 0.5357\n",
            "Epoch [40/50], Step [120/350], Avg Loss: 0.4895, Avg Dice: 0.5373\n",
            "Epoch [40/50], Step [125/350], Avg Loss: 0.4894, Avg Dice: 0.5376\n",
            "Epoch [40/50], Step [130/350], Avg Loss: 0.4894, Avg Dice: 0.5357\n",
            "Epoch [40/50], Step [135/350], Avg Loss: 0.4893, Avg Dice: 0.5372\n",
            "Epoch [40/50], Step [140/350], Avg Loss: 0.4890, Avg Dice: 0.5360\n",
            "Epoch [40/50], Step [145/350], Avg Loss: 0.4901, Avg Dice: 0.5353\n",
            "Epoch [40/50], Step [150/350], Avg Loss: 0.4892, Avg Dice: 0.5360\n",
            "Epoch [40/50], Step [155/350], Avg Loss: 0.4888, Avg Dice: 0.5350\n",
            "Epoch [40/50], Step [160/350], Avg Loss: 0.4888, Avg Dice: 0.5346\n",
            "Epoch [40/50], Step [165/350], Avg Loss: 0.4884, Avg Dice: 0.5338\n",
            "Epoch [40/50], Step [170/350], Avg Loss: 0.4889, Avg Dice: 0.5339\n",
            "Epoch [40/50], Step [175/350], Avg Loss: 0.4887, Avg Dice: 0.5342\n",
            "Epoch [40/50], Step [180/350], Avg Loss: 0.4894, Avg Dice: 0.5343\n",
            "Epoch [40/50], Step [185/350], Avg Loss: 0.4895, Avg Dice: 0.5336\n",
            "Epoch [40/50], Step [190/350], Avg Loss: 0.4910, Avg Dice: 0.5327\n",
            "Epoch [40/50], Step [195/350], Avg Loss: 0.4918, Avg Dice: 0.5333\n",
            "Epoch [40/50], Step [200/350], Avg Loss: 0.4925, Avg Dice: 0.5324\n",
            "Epoch [40/50], Step [205/350], Avg Loss: 0.4923, Avg Dice: 0.5321\n",
            "Epoch [40/50], Step [210/350], Avg Loss: 0.4921, Avg Dice: 0.5318\n",
            "Epoch [40/50], Step [215/350], Avg Loss: 0.4929, Avg Dice: 0.5306\n",
            "Epoch [40/50], Step [220/350], Avg Loss: 0.4925, Avg Dice: 0.5310\n",
            "Epoch [40/50], Step [225/350], Avg Loss: 0.4925, Avg Dice: 0.5309\n",
            "Epoch [40/50], Step [230/350], Avg Loss: 0.4926, Avg Dice: 0.5313\n",
            "Epoch [40/50], Step [235/350], Avg Loss: 0.4921, Avg Dice: 0.5310\n",
            "Epoch [40/50], Step [240/350], Avg Loss: 0.4922, Avg Dice: 0.5319\n",
            "Epoch [40/50], Step [245/350], Avg Loss: 0.4922, Avg Dice: 0.5305\n",
            "Epoch [40/50], Step [250/350], Avg Loss: 0.4918, Avg Dice: 0.5298\n",
            "Epoch [40/50], Step [255/350], Avg Loss: 0.4920, Avg Dice: 0.5303\n",
            "Epoch [40/50], Step [260/350], Avg Loss: 0.4918, Avg Dice: 0.5303\n",
            "Epoch [40/50], Step [265/350], Avg Loss: 0.4929, Avg Dice: 0.5305\n",
            "Epoch [40/50], Step [270/350], Avg Loss: 0.4927, Avg Dice: 0.5306\n",
            "Epoch [40/50], Step [275/350], Avg Loss: 0.4926, Avg Dice: 0.5305\n",
            "Epoch [40/50], Step [280/350], Avg Loss: 0.4923, Avg Dice: 0.5309\n",
            "Epoch [40/50], Step [285/350], Avg Loss: 0.4917, Avg Dice: 0.5316\n",
            "Epoch [40/50], Step [290/350], Avg Loss: 0.4920, Avg Dice: 0.5309\n",
            "Epoch [40/50], Step [295/350], Avg Loss: 0.4922, Avg Dice: 0.5313\n",
            "Epoch [40/50], Step [300/350], Avg Loss: 0.4925, Avg Dice: 0.5308\n",
            "Epoch [40/50], Step [305/350], Avg Loss: 0.4934, Avg Dice: 0.5311\n",
            "Epoch [40/50], Step [310/350], Avg Loss: 0.4935, Avg Dice: 0.5307\n",
            "Epoch [40/50], Step [315/350], Avg Loss: 0.4935, Avg Dice: 0.5305\n",
            "Epoch [40/50], Step [320/350], Avg Loss: 0.4937, Avg Dice: 0.5299\n",
            "Epoch [40/50], Step [325/350], Avg Loss: 0.4933, Avg Dice: 0.5301\n",
            "Epoch [40/50], Step [330/350], Avg Loss: 0.4936, Avg Dice: 0.5308\n",
            "Epoch [40/50], Step [335/350], Avg Loss: 0.4938, Avg Dice: 0.5309\n",
            "Epoch [40/50], Step [340/350], Avg Loss: 0.4943, Avg Dice: 0.5309\n",
            "Epoch [40/50], Step [345/350], Avg Loss: 0.4945, Avg Dice: 0.5302\n",
            "Epoch [40/50], Step [350/350], Avg Loss: 0.4945, Avg Dice: 0.5306\n",
            "End of epoch 40: Avg Loss: 0.4945, Avg Dice: 0.5306\n",
            "Epoch [41/50], Step [5/350], Avg Loss: 0.4869, Avg Dice: 0.5516\n",
            "Epoch [41/50], Step [10/350], Avg Loss: 0.4788, Avg Dice: 0.5478\n",
            "Epoch [41/50], Step [15/350], Avg Loss: 0.4757, Avg Dice: 0.5358\n",
            "Epoch [41/50], Step [20/350], Avg Loss: 0.4761, Avg Dice: 0.5346\n",
            "Epoch [41/50], Step [25/350], Avg Loss: 0.4839, Avg Dice: 0.5399\n",
            "Epoch [41/50], Step [30/350], Avg Loss: 0.4867, Avg Dice: 0.5362\n",
            "Epoch [41/50], Step [35/350], Avg Loss: 0.4826, Avg Dice: 0.5383\n",
            "Epoch [41/50], Step [40/350], Avg Loss: 0.4839, Avg Dice: 0.5370\n",
            "Epoch [41/50], Step [45/350], Avg Loss: 0.4847, Avg Dice: 0.5328\n",
            "Epoch [41/50], Step [50/350], Avg Loss: 0.4855, Avg Dice: 0.5337\n",
            "Epoch [41/50], Step [55/350], Avg Loss: 0.4852, Avg Dice: 0.5389\n",
            "Epoch [41/50], Step [60/350], Avg Loss: 0.4857, Avg Dice: 0.5366\n",
            "Epoch [41/50], Step [65/350], Avg Loss: 0.4863, Avg Dice: 0.5370\n",
            "Epoch [41/50], Step [70/350], Avg Loss: 0.4871, Avg Dice: 0.5353\n",
            "Epoch [41/50], Step [75/350], Avg Loss: 0.4851, Avg Dice: 0.5392\n",
            "Epoch [41/50], Step [80/350], Avg Loss: 0.4857, Avg Dice: 0.5374\n",
            "Epoch [41/50], Step [85/350], Avg Loss: 0.4861, Avg Dice: 0.5363\n",
            "Epoch [41/50], Step [90/350], Avg Loss: 0.4855, Avg Dice: 0.5370\n",
            "Epoch [41/50], Step [95/350], Avg Loss: 0.4868, Avg Dice: 0.5394\n",
            "Epoch [41/50], Step [100/350], Avg Loss: 0.4872, Avg Dice: 0.5406\n",
            "Epoch [41/50], Step [105/350], Avg Loss: 0.4884, Avg Dice: 0.5403\n",
            "Epoch [41/50], Step [110/350], Avg Loss: 0.4888, Avg Dice: 0.5420\n",
            "Epoch [41/50], Step [115/350], Avg Loss: 0.4901, Avg Dice: 0.5426\n",
            "Epoch [41/50], Step [120/350], Avg Loss: 0.4907, Avg Dice: 0.5408\n",
            "Epoch [41/50], Step [125/350], Avg Loss: 0.4886, Avg Dice: 0.5383\n",
            "Epoch [41/50], Step [130/350], Avg Loss: 0.4890, Avg Dice: 0.5378\n",
            "Epoch [41/50], Step [135/350], Avg Loss: 0.4897, Avg Dice: 0.5383\n",
            "Epoch [41/50], Step [140/350], Avg Loss: 0.4889, Avg Dice: 0.5380\n",
            "Epoch [41/50], Step [145/350], Avg Loss: 0.4885, Avg Dice: 0.5382\n",
            "Epoch [41/50], Step [150/350], Avg Loss: 0.4889, Avg Dice: 0.5379\n",
            "Epoch [41/50], Step [155/350], Avg Loss: 0.4898, Avg Dice: 0.5380\n",
            "Epoch [41/50], Step [160/350], Avg Loss: 0.4896, Avg Dice: 0.5362\n",
            "Epoch [41/50], Step [165/350], Avg Loss: 0.4897, Avg Dice: 0.5371\n",
            "Epoch [41/50], Step [170/350], Avg Loss: 0.4895, Avg Dice: 0.5386\n",
            "Epoch [41/50], Step [175/350], Avg Loss: 0.4893, Avg Dice: 0.5380\n",
            "Epoch [41/50], Step [180/350], Avg Loss: 0.4891, Avg Dice: 0.5372\n",
            "Epoch [41/50], Step [185/350], Avg Loss: 0.4895, Avg Dice: 0.5374\n",
            "Epoch [41/50], Step [190/350], Avg Loss: 0.4893, Avg Dice: 0.5392\n",
            "Epoch [41/50], Step [195/350], Avg Loss: 0.4892, Avg Dice: 0.5388\n",
            "Epoch [41/50], Step [200/350], Avg Loss: 0.4890, Avg Dice: 0.5388\n",
            "Epoch [41/50], Step [205/350], Avg Loss: 0.4891, Avg Dice: 0.5402\n",
            "Epoch [41/50], Step [210/350], Avg Loss: 0.4892, Avg Dice: 0.5398\n",
            "Epoch [41/50], Step [215/350], Avg Loss: 0.4889, Avg Dice: 0.5403\n",
            "Epoch [41/50], Step [220/350], Avg Loss: 0.4882, Avg Dice: 0.5401\n",
            "Epoch [41/50], Step [225/350], Avg Loss: 0.4886, Avg Dice: 0.5392\n",
            "Epoch [41/50], Step [230/350], Avg Loss: 0.4884, Avg Dice: 0.5390\n",
            "Epoch [41/50], Step [235/350], Avg Loss: 0.4886, Avg Dice: 0.5386\n",
            "Epoch [41/50], Step [240/350], Avg Loss: 0.4887, Avg Dice: 0.5377\n",
            "Epoch [41/50], Step [245/350], Avg Loss: 0.4886, Avg Dice: 0.5377\n",
            "Epoch [41/50], Step [250/350], Avg Loss: 0.4887, Avg Dice: 0.5372\n",
            "Epoch [41/50], Step [255/350], Avg Loss: 0.4887, Avg Dice: 0.5361\n",
            "Epoch [41/50], Step [260/350], Avg Loss: 0.4887, Avg Dice: 0.5360\n",
            "Epoch [41/50], Step [265/350], Avg Loss: 0.4885, Avg Dice: 0.5351\n",
            "Epoch [41/50], Step [270/350], Avg Loss: 0.4880, Avg Dice: 0.5355\n",
            "Epoch [41/50], Step [275/350], Avg Loss: 0.4877, Avg Dice: 0.5355\n",
            "Epoch [41/50], Step [280/350], Avg Loss: 0.4880, Avg Dice: 0.5354\n",
            "Epoch [41/50], Step [285/350], Avg Loss: 0.4878, Avg Dice: 0.5350\n",
            "Epoch [41/50], Step [290/350], Avg Loss: 0.4882, Avg Dice: 0.5345\n",
            "Epoch [41/50], Step [295/350], Avg Loss: 0.4881, Avg Dice: 0.5347\n",
            "Epoch [41/50], Step [300/350], Avg Loss: 0.4886, Avg Dice: 0.5357\n",
            "Epoch [41/50], Step [305/350], Avg Loss: 0.4881, Avg Dice: 0.5355\n",
            "Epoch [41/50], Step [310/350], Avg Loss: 0.4883, Avg Dice: 0.5361\n",
            "Epoch [41/50], Step [315/350], Avg Loss: 0.4880, Avg Dice: 0.5356\n",
            "Epoch [41/50], Step [320/350], Avg Loss: 0.4879, Avg Dice: 0.5360\n",
            "Epoch [41/50], Step [325/350], Avg Loss: 0.4880, Avg Dice: 0.5364\n",
            "Epoch [41/50], Step [330/350], Avg Loss: 0.4880, Avg Dice: 0.5369\n",
            "Epoch [41/50], Step [335/350], Avg Loss: 0.4880, Avg Dice: 0.5363\n",
            "Epoch [41/50], Step [340/350], Avg Loss: 0.4881, Avg Dice: 0.5362\n",
            "Epoch [41/50], Step [345/350], Avg Loss: 0.4880, Avg Dice: 0.5360\n",
            "Epoch [41/50], Step [350/350], Avg Loss: 0.4878, Avg Dice: 0.5360\n",
            "End of epoch 41: Avg Loss: 0.4878, Avg Dice: 0.5360\n",
            "Epoch [42/50], Step [5/350], Avg Loss: 0.4864, Avg Dice: 0.4907\n",
            "Epoch [42/50], Step [10/350], Avg Loss: 0.4852, Avg Dice: 0.5263\n",
            "Epoch [42/50], Step [15/350], Avg Loss: 0.4724, Avg Dice: 0.5352\n",
            "Epoch [42/50], Step [20/350], Avg Loss: 0.4700, Avg Dice: 0.5430\n",
            "Epoch [42/50], Step [25/350], Avg Loss: 0.4689, Avg Dice: 0.5402\n",
            "Epoch [42/50], Step [30/350], Avg Loss: 0.4718, Avg Dice: 0.5392\n",
            "Epoch [42/50], Step [35/350], Avg Loss: 0.4772, Avg Dice: 0.5425\n",
            "Epoch [42/50], Step [40/350], Avg Loss: 0.4804, Avg Dice: 0.5475\n",
            "Epoch [42/50], Step [45/350], Avg Loss: 0.4799, Avg Dice: 0.5438\n",
            "Epoch [42/50], Step [50/350], Avg Loss: 0.4823, Avg Dice: 0.5421\n",
            "Epoch [42/50], Step [55/350], Avg Loss: 0.4827, Avg Dice: 0.5396\n",
            "Epoch [42/50], Step [60/350], Avg Loss: 0.4850, Avg Dice: 0.5412\n",
            "Epoch [42/50], Step [65/350], Avg Loss: 0.4841, Avg Dice: 0.5418\n",
            "Epoch [42/50], Step [70/350], Avg Loss: 0.4840, Avg Dice: 0.5375\n",
            "Epoch [42/50], Step [75/350], Avg Loss: 0.4828, Avg Dice: 0.5396\n",
            "Epoch [42/50], Step [80/350], Avg Loss: 0.4814, Avg Dice: 0.5375\n",
            "Epoch [42/50], Step [85/350], Avg Loss: 0.4812, Avg Dice: 0.5395\n",
            "Epoch [42/50], Step [90/350], Avg Loss: 0.4825, Avg Dice: 0.5389\n",
            "Epoch [42/50], Step [95/350], Avg Loss: 0.4814, Avg Dice: 0.5402\n",
            "Epoch [42/50], Step [100/350], Avg Loss: 0.4818, Avg Dice: 0.5390\n",
            "Epoch [42/50], Step [105/350], Avg Loss: 0.4817, Avg Dice: 0.5391\n",
            "Epoch [42/50], Step [110/350], Avg Loss: 0.4817, Avg Dice: 0.5398\n",
            "Epoch [42/50], Step [115/350], Avg Loss: 0.4813, Avg Dice: 0.5384\n",
            "Epoch [42/50], Step [120/350], Avg Loss: 0.4807, Avg Dice: 0.5377\n",
            "Epoch [42/50], Step [125/350], Avg Loss: 0.4802, Avg Dice: 0.5376\n",
            "Epoch [42/50], Step [130/350], Avg Loss: 0.4798, Avg Dice: 0.5375\n",
            "Epoch [42/50], Step [135/350], Avg Loss: 0.4793, Avg Dice: 0.5376\n",
            "Epoch [42/50], Step [140/350], Avg Loss: 0.4808, Avg Dice: 0.5374\n",
            "Epoch [42/50], Step [145/350], Avg Loss: 0.4807, Avg Dice: 0.5377\n",
            "Epoch [42/50], Step [150/350], Avg Loss: 0.4803, Avg Dice: 0.5382\n",
            "Epoch [42/50], Step [155/350], Avg Loss: 0.4794, Avg Dice: 0.5390\n",
            "Epoch [42/50], Step [160/350], Avg Loss: 0.4788, Avg Dice: 0.5400\n",
            "Epoch [42/50], Step [165/350], Avg Loss: 0.4793, Avg Dice: 0.5392\n",
            "Epoch [42/50], Step [170/350], Avg Loss: 0.4799, Avg Dice: 0.5391\n",
            "Epoch [42/50], Step [175/350], Avg Loss: 0.4799, Avg Dice: 0.5373\n",
            "Epoch [42/50], Step [180/350], Avg Loss: 0.4799, Avg Dice: 0.5371\n",
            "Epoch [42/50], Step [185/350], Avg Loss: 0.4798, Avg Dice: 0.5359\n",
            "Epoch [42/50], Step [190/350], Avg Loss: 0.4796, Avg Dice: 0.5368\n",
            "Epoch [42/50], Step [195/350], Avg Loss: 0.4799, Avg Dice: 0.5364\n",
            "Epoch [42/50], Step [200/350], Avg Loss: 0.4793, Avg Dice: 0.5367\n",
            "Epoch [42/50], Step [205/350], Avg Loss: 0.4795, Avg Dice: 0.5379\n",
            "Epoch [42/50], Step [210/350], Avg Loss: 0.4794, Avg Dice: 0.5384\n",
            "Epoch [42/50], Step [215/350], Avg Loss: 0.4799, Avg Dice: 0.5386\n",
            "Epoch [42/50], Step [220/350], Avg Loss: 0.4799, Avg Dice: 0.5396\n",
            "Epoch [42/50], Step [225/350], Avg Loss: 0.4802, Avg Dice: 0.5403\n",
            "Epoch [42/50], Step [230/350], Avg Loss: 0.4800, Avg Dice: 0.5399\n",
            "Epoch [42/50], Step [235/350], Avg Loss: 0.4802, Avg Dice: 0.5402\n",
            "Epoch [42/50], Step [240/350], Avg Loss: 0.4804, Avg Dice: 0.5396\n",
            "Epoch [42/50], Step [245/350], Avg Loss: 0.4808, Avg Dice: 0.5382\n",
            "Epoch [42/50], Step [250/350], Avg Loss: 0.4803, Avg Dice: 0.5379\n",
            "Epoch [42/50], Step [255/350], Avg Loss: 0.4797, Avg Dice: 0.5382\n",
            "Epoch [42/50], Step [260/350], Avg Loss: 0.4799, Avg Dice: 0.5373\n",
            "Epoch [42/50], Step [265/350], Avg Loss: 0.4797, Avg Dice: 0.5379\n",
            "Epoch [42/50], Step [270/350], Avg Loss: 0.4793, Avg Dice: 0.5388\n",
            "Epoch [42/50], Step [275/350], Avg Loss: 0.4791, Avg Dice: 0.5388\n",
            "Epoch [42/50], Step [280/350], Avg Loss: 0.4794, Avg Dice: 0.5381\n",
            "Epoch [42/50], Step [285/350], Avg Loss: 0.4794, Avg Dice: 0.5375\n",
            "Epoch [42/50], Step [290/350], Avg Loss: 0.4792, Avg Dice: 0.5376\n",
            "Epoch [42/50], Step [295/350], Avg Loss: 0.4792, Avg Dice: 0.5371\n",
            "Epoch [42/50], Step [300/350], Avg Loss: 0.4794, Avg Dice: 0.5373\n",
            "Epoch [42/50], Step [305/350], Avg Loss: 0.4797, Avg Dice: 0.5372\n",
            "Epoch [42/50], Step [310/350], Avg Loss: 0.4797, Avg Dice: 0.5373\n",
            "Epoch [42/50], Step [315/350], Avg Loss: 0.4798, Avg Dice: 0.5372\n",
            "Epoch [42/50], Step [320/350], Avg Loss: 0.4798, Avg Dice: 0.5376\n",
            "Epoch [42/50], Step [325/350], Avg Loss: 0.4796, Avg Dice: 0.5380\n",
            "Epoch [42/50], Step [330/350], Avg Loss: 0.4799, Avg Dice: 0.5369\n",
            "Epoch [42/50], Step [335/350], Avg Loss: 0.4798, Avg Dice: 0.5373\n",
            "Epoch [42/50], Step [340/350], Avg Loss: 0.4799, Avg Dice: 0.5374\n",
            "Epoch [42/50], Step [345/350], Avg Loss: 0.4800, Avg Dice: 0.5377\n",
            "Epoch [42/50], Step [350/350], Avg Loss: 0.4802, Avg Dice: 0.5376\n",
            "End of epoch 42: Avg Loss: 0.4802, Avg Dice: 0.5376\n",
            "Epoch [43/50], Step [5/350], Avg Loss: 0.4449, Avg Dice: 0.5533\n",
            "Epoch [43/50], Step [10/350], Avg Loss: 0.4485, Avg Dice: 0.5365\n",
            "Epoch [43/50], Step [15/350], Avg Loss: 0.4544, Avg Dice: 0.5310\n",
            "Epoch [43/50], Step [20/350], Avg Loss: 0.4553, Avg Dice: 0.5484\n",
            "Epoch [43/50], Step [25/350], Avg Loss: 0.4582, Avg Dice: 0.5482\n",
            "Epoch [43/50], Step [30/350], Avg Loss: 0.4574, Avg Dice: 0.5473\n",
            "Epoch [43/50], Step [35/350], Avg Loss: 0.4576, Avg Dice: 0.5394\n",
            "Epoch [43/50], Step [40/350], Avg Loss: 0.4593, Avg Dice: 0.5370\n",
            "Epoch [43/50], Step [45/350], Avg Loss: 0.4603, Avg Dice: 0.5327\n",
            "Epoch [43/50], Step [50/350], Avg Loss: 0.4604, Avg Dice: 0.5340\n",
            "Epoch [43/50], Step [55/350], Avg Loss: 0.4589, Avg Dice: 0.5337\n",
            "Epoch [43/50], Step [60/350], Avg Loss: 0.4594, Avg Dice: 0.5352\n",
            "Epoch [43/50], Step [65/350], Avg Loss: 0.4598, Avg Dice: 0.5349\n",
            "Epoch [43/50], Step [70/350], Avg Loss: 0.4612, Avg Dice: 0.5372\n",
            "Epoch [43/50], Step [75/350], Avg Loss: 0.4619, Avg Dice: 0.5368\n",
            "Epoch [43/50], Step [80/350], Avg Loss: 0.4621, Avg Dice: 0.5380\n",
            "Epoch [43/50], Step [85/350], Avg Loss: 0.4636, Avg Dice: 0.5414\n",
            "Epoch [43/50], Step [90/350], Avg Loss: 0.4632, Avg Dice: 0.5433\n",
            "Epoch [43/50], Step [95/350], Avg Loss: 0.4626, Avg Dice: 0.5433\n",
            "Epoch [43/50], Step [100/350], Avg Loss: 0.4633, Avg Dice: 0.5418\n",
            "Epoch [43/50], Step [105/350], Avg Loss: 0.4635, Avg Dice: 0.5402\n",
            "Epoch [43/50], Step [110/350], Avg Loss: 0.4623, Avg Dice: 0.5420\n",
            "Epoch [43/50], Step [115/350], Avg Loss: 0.4616, Avg Dice: 0.5406\n",
            "Epoch [43/50], Step [120/350], Avg Loss: 0.4627, Avg Dice: 0.5429\n",
            "Epoch [43/50], Step [125/350], Avg Loss: 0.4630, Avg Dice: 0.5437\n",
            "Epoch [43/50], Step [130/350], Avg Loss: 0.4632, Avg Dice: 0.5419\n",
            "Epoch [43/50], Step [135/350], Avg Loss: 0.4630, Avg Dice: 0.5419\n",
            "Epoch [43/50], Step [140/350], Avg Loss: 0.4641, Avg Dice: 0.5420\n",
            "Epoch [43/50], Step [145/350], Avg Loss: 0.4637, Avg Dice: 0.5413\n",
            "Epoch [43/50], Step [150/350], Avg Loss: 0.4636, Avg Dice: 0.5418\n",
            "Epoch [43/50], Step [155/350], Avg Loss: 0.4631, Avg Dice: 0.5422\n",
            "Epoch [43/50], Step [160/350], Avg Loss: 0.4638, Avg Dice: 0.5426\n",
            "Epoch [43/50], Step [165/350], Avg Loss: 0.4650, Avg Dice: 0.5420\n",
            "Epoch [43/50], Step [170/350], Avg Loss: 0.4649, Avg Dice: 0.5422\n",
            "Epoch [43/50], Step [175/350], Avg Loss: 0.4643, Avg Dice: 0.5426\n",
            "Epoch [43/50], Step [180/350], Avg Loss: 0.4640, Avg Dice: 0.5433\n",
            "Epoch [43/50], Step [185/350], Avg Loss: 0.4643, Avg Dice: 0.5435\n",
            "Epoch [43/50], Step [190/350], Avg Loss: 0.4644, Avg Dice: 0.5449\n",
            "Epoch [43/50], Step [195/350], Avg Loss: 0.4643, Avg Dice: 0.5445\n",
            "Epoch [43/50], Step [200/350], Avg Loss: 0.4643, Avg Dice: 0.5445\n",
            "Epoch [43/50], Step [205/350], Avg Loss: 0.4651, Avg Dice: 0.5440\n",
            "Epoch [43/50], Step [210/350], Avg Loss: 0.4647, Avg Dice: 0.5450\n",
            "Epoch [43/50], Step [215/350], Avg Loss: 0.4656, Avg Dice: 0.5454\n",
            "Epoch [43/50], Step [220/350], Avg Loss: 0.4657, Avg Dice: 0.5451\n",
            "Epoch [43/50], Step [225/350], Avg Loss: 0.4658, Avg Dice: 0.5444\n",
            "Epoch [43/50], Step [230/350], Avg Loss: 0.4656, Avg Dice: 0.5452\n",
            "Epoch [43/50], Step [235/350], Avg Loss: 0.4659, Avg Dice: 0.5439\n",
            "Epoch [43/50], Step [240/350], Avg Loss: 0.4660, Avg Dice: 0.5438\n",
            "Epoch [43/50], Step [245/350], Avg Loss: 0.4662, Avg Dice: 0.5438\n",
            "Epoch [43/50], Step [250/350], Avg Loss: 0.4666, Avg Dice: 0.5435\n",
            "Epoch [43/50], Step [255/350], Avg Loss: 0.4673, Avg Dice: 0.5437\n",
            "Epoch [43/50], Step [260/350], Avg Loss: 0.4677, Avg Dice: 0.5440\n",
            "Epoch [43/50], Step [265/350], Avg Loss: 0.4680, Avg Dice: 0.5440\n",
            "Epoch [43/50], Step [270/350], Avg Loss: 0.4686, Avg Dice: 0.5435\n",
            "Epoch [43/50], Step [275/350], Avg Loss: 0.4685, Avg Dice: 0.5439\n",
            "Epoch [43/50], Step [280/350], Avg Loss: 0.4681, Avg Dice: 0.5437\n",
            "Epoch [43/50], Step [285/350], Avg Loss: 0.4688, Avg Dice: 0.5439\n",
            "Epoch [43/50], Step [290/350], Avg Loss: 0.4687, Avg Dice: 0.5432\n",
            "Epoch [43/50], Step [295/350], Avg Loss: 0.4692, Avg Dice: 0.5424\n",
            "Epoch [43/50], Step [300/350], Avg Loss: 0.4691, Avg Dice: 0.5429\n",
            "Epoch [43/50], Step [305/350], Avg Loss: 0.4693, Avg Dice: 0.5432\n",
            "Epoch [43/50], Step [310/350], Avg Loss: 0.4695, Avg Dice: 0.5432\n",
            "Epoch [43/50], Step [315/350], Avg Loss: 0.4696, Avg Dice: 0.5430\n",
            "Epoch [43/50], Step [320/350], Avg Loss: 0.4698, Avg Dice: 0.5418\n",
            "Epoch [43/50], Step [325/350], Avg Loss: 0.4701, Avg Dice: 0.5405\n",
            "Epoch [43/50], Step [330/350], Avg Loss: 0.4701, Avg Dice: 0.5409\n",
            "Epoch [43/50], Step [335/350], Avg Loss: 0.4702, Avg Dice: 0.5413\n",
            "Epoch [43/50], Step [340/350], Avg Loss: 0.4706, Avg Dice: 0.5415\n",
            "Epoch [43/50], Step [345/350], Avg Loss: 0.4709, Avg Dice: 0.5416\n",
            "Epoch [43/50], Step [350/350], Avg Loss: 0.4710, Avg Dice: 0.5416\n",
            "End of epoch 43: Avg Loss: 0.4710, Avg Dice: 0.5416\n",
            "Epoch [44/50], Step [5/350], Avg Loss: 0.4440, Avg Dice: 0.5853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "\n",
        "model.train()\n",
        "criterion = nn.CrossEntropyLoss()  # segmentation cross-entropy loss\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    running_dice = 0.0\n",
        "    for i, (images, masks) in enumerate(train_loader):\n",
        "        images = images.to(device)      # [B, 3, H, W]\n",
        "        masks = masks.to(device)        # [B, H, W]\n",
        "        masks = masks.long()\n",
        "        # print(np.unique(masks.detach().cpu().numpy()))\n",
        "        optimizer.zero_grad()\n",
        "        seg_logits, aux_loss = model(images)\n",
        "        assert seg_logits.shape[1] == num_classes, \"The number of output channels must equal the number of classes.\"\n",
        "\n",
        "        # seg_logits shape: [B, num_classes, H, W]\n",
        "        seg_loss = criterion(seg_logits, masks)\n",
        "        loss = seg_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Calculate Dice score on training mini-batch:\n",
        "        preds = torch.argmax(seg_logits, dim=1)  # shape: [B, H, W]\n",
        "        batch_dice = dice_score(preds, masks, num_classes)\n",
        "        running_dice += batch_dice.item() if isinstance(batch_dice, torch.Tensor) else batch_dice\n",
        "\n",
        "        # Every plot_freq iterations, plot a few example predictions from the current batch.\n",
        "        # if (i + 1) % plot_freq == 0:\n",
        "        #     print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n",
        "        #     # Plot first few images. Adjust n_samples as desired.\n",
        "        #     plot_predictions(images, masks, preds, n_samples=3, title_prefix=\"Train\")\n",
        "\n",
        "        if (i + 1) % 5 == 0:\n",
        "            avg_loss = running_loss / (i+1)\n",
        "            avg_dice = running_dice / (i+1)\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Avg Loss: {avg_loss:.4f}, Avg Dice: {avg_dice:.4f}\")\n",
        "    print(f\"End of epoch {epoch+1}: Avg Loss: {running_loss/len(train_loader):.4f}, Avg Dice: {running_dice/len(train_loader):.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "naZJNT3EfuWU",
        "outputId": "954add4c-367a-4cc4-b033-aed8e118f524"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Step [5/350], Avg Loss: 1.1815, Avg Dice: 0.3429\n",
            "Epoch [1/50], Step [10/350], Avg Loss: 1.1857, Avg Dice: 0.3346\n",
            "Epoch [1/50], Step [15/350], Avg Loss: 1.1698, Avg Dice: 0.3359\n",
            "Epoch [1/50], Step [20/350], Avg Loss: 1.1674, Avg Dice: 0.3406\n",
            "Epoch [1/50], Step [25/350], Avg Loss: 1.1587, Avg Dice: 0.3384\n",
            "Epoch [1/50], Step [30/350], Avg Loss: 1.1655, Avg Dice: 0.3368\n",
            "Epoch [1/50], Step [35/350], Avg Loss: 1.1670, Avg Dice: 0.3333\n",
            "Epoch [1/50], Step [40/350], Avg Loss: 1.1683, Avg Dice: 0.3325\n",
            "Epoch [1/50], Step [45/350], Avg Loss: 1.1726, Avg Dice: 0.3352\n",
            "Epoch [1/50], Step [50/350], Avg Loss: 1.1671, Avg Dice: 0.3343\n",
            "Epoch [1/50], Step [55/350], Avg Loss: 1.1657, Avg Dice: 0.3373\n",
            "Epoch [1/50], Step [60/350], Avg Loss: 1.1707, Avg Dice: 0.3356\n",
            "Epoch [1/50], Step [65/350], Avg Loss: 1.1702, Avg Dice: 0.3355\n",
            "Epoch [1/50], Step [70/350], Avg Loss: 1.1668, Avg Dice: 0.3389\n",
            "Epoch [1/50], Step [75/350], Avg Loss: 1.1635, Avg Dice: 0.3405\n",
            "Epoch [1/50], Step [80/350], Avg Loss: 1.1629, Avg Dice: 0.3401\n",
            "Epoch [1/50], Step [85/350], Avg Loss: 1.1644, Avg Dice: 0.3395\n",
            "Epoch [1/50], Step [90/350], Avg Loss: 1.1644, Avg Dice: 0.3380\n",
            "Epoch [1/50], Step [95/350], Avg Loss: 1.1610, Avg Dice: 0.3374\n",
            "Epoch [1/50], Step [100/350], Avg Loss: 1.1611, Avg Dice: 0.3375\n",
            "Epoch [1/50], Step [105/350], Avg Loss: 1.1632, Avg Dice: 0.3388\n",
            "Epoch [1/50], Step [110/350], Avg Loss: 1.1637, Avg Dice: 0.3385\n",
            "Epoch [1/50], Step [115/350], Avg Loss: 1.1656, Avg Dice: 0.3390\n",
            "Epoch [1/50], Step [120/350], Avg Loss: 1.1670, Avg Dice: 0.3390\n",
            "Epoch [1/50], Step [125/350], Avg Loss: 1.1632, Avg Dice: 0.3400\n",
            "Epoch [1/50], Step [130/350], Avg Loss: 1.1617, Avg Dice: 0.3391\n",
            "Epoch [1/50], Step [135/350], Avg Loss: 1.1626, Avg Dice: 0.3384\n",
            "Epoch [1/50], Step [140/350], Avg Loss: 1.1619, Avg Dice: 0.3393\n",
            "Epoch [1/50], Step [145/350], Avg Loss: 1.1592, Avg Dice: 0.3397\n",
            "Epoch [1/50], Step [150/350], Avg Loss: 1.1578, Avg Dice: 0.3388\n",
            "Epoch [1/50], Step [155/350], Avg Loss: 1.1587, Avg Dice: 0.3406\n",
            "Epoch [1/50], Step [160/350], Avg Loss: 1.1577, Avg Dice: 0.3401\n",
            "Epoch [1/50], Step [165/350], Avg Loss: 1.1589, Avg Dice: 0.3405\n",
            "Epoch [1/50], Step [170/350], Avg Loss: 1.1543, Avg Dice: 0.3406\n",
            "Epoch [1/50], Step [175/350], Avg Loss: 1.1553, Avg Dice: 0.3399\n",
            "Epoch [1/50], Step [180/350], Avg Loss: 1.1534, Avg Dice: 0.3397\n",
            "Epoch [1/50], Step [185/350], Avg Loss: 1.1506, Avg Dice: 0.3394\n",
            "Epoch [1/50], Step [190/350], Avg Loss: 1.1513, Avg Dice: 0.3399\n",
            "Epoch [1/50], Step [195/350], Avg Loss: 1.1491, Avg Dice: 0.3402\n",
            "Epoch [1/50], Step [200/350], Avg Loss: 1.1485, Avg Dice: 0.3402\n",
            "Epoch [1/50], Step [205/350], Avg Loss: 1.1472, Avg Dice: 0.3399\n",
            "Epoch [1/50], Step [210/350], Avg Loss: 1.1456, Avg Dice: 0.3407\n",
            "Epoch [1/50], Step [215/350], Avg Loss: 1.1449, Avg Dice: 0.3400\n",
            "Epoch [1/50], Step [220/350], Avg Loss: 1.1424, Avg Dice: 0.3408\n",
            "Epoch [1/50], Step [225/350], Avg Loss: 1.1419, Avg Dice: 0.3415\n",
            "Epoch [1/50], Step [230/350], Avg Loss: 1.1426, Avg Dice: 0.3418\n",
            "Epoch [1/50], Step [235/350], Avg Loss: 1.1413, Avg Dice: 0.3417\n",
            "Epoch [1/50], Step [240/350], Avg Loss: 1.1398, Avg Dice: 0.3424\n",
            "Epoch [1/50], Step [245/350], Avg Loss: 1.1381, Avg Dice: 0.3431\n",
            "Epoch [1/50], Step [250/350], Avg Loss: 1.1366, Avg Dice: 0.3431\n",
            "Epoch [1/50], Step [255/350], Avg Loss: 1.1363, Avg Dice: 0.3424\n",
            "Epoch [1/50], Step [260/350], Avg Loss: 1.1353, Avg Dice: 0.3422\n",
            "Epoch [1/50], Step [265/350], Avg Loss: 1.1350, Avg Dice: 0.3421\n",
            "Epoch [1/50], Step [270/350], Avg Loss: 1.1350, Avg Dice: 0.3421\n",
            "Epoch [1/50], Step [275/350], Avg Loss: 1.1342, Avg Dice: 0.3419\n",
            "Epoch [1/50], Step [280/350], Avg Loss: 1.1349, Avg Dice: 0.3422\n",
            "Epoch [1/50], Step [285/350], Avg Loss: 1.1352, Avg Dice: 0.3419\n",
            "Epoch [1/50], Step [290/350], Avg Loss: 1.1340, Avg Dice: 0.3428\n",
            "Epoch [1/50], Step [295/350], Avg Loss: 1.1353, Avg Dice: 0.3426\n",
            "Epoch [1/50], Step [300/350], Avg Loss: 1.1356, Avg Dice: 0.3433\n",
            "Epoch [1/50], Step [305/350], Avg Loss: 1.1362, Avg Dice: 0.3434\n",
            "Epoch [1/50], Step [310/350], Avg Loss: 1.1358, Avg Dice: 0.3434\n",
            "Epoch [1/50], Step [315/350], Avg Loss: 1.1346, Avg Dice: 0.3432\n",
            "Epoch [1/50], Step [320/350], Avg Loss: 1.1335, Avg Dice: 0.3435\n",
            "Epoch [1/50], Step [325/350], Avg Loss: 1.1335, Avg Dice: 0.3440\n",
            "Epoch [1/50], Step [330/350], Avg Loss: 1.1333, Avg Dice: 0.3439\n",
            "Epoch [1/50], Step [335/350], Avg Loss: 1.1321, Avg Dice: 0.3436\n",
            "Epoch [1/50], Step [340/350], Avg Loss: 1.1305, Avg Dice: 0.3431\n",
            "Epoch [1/50], Step [345/350], Avg Loss: 1.1298, Avg Dice: 0.3437\n",
            "Epoch [1/50], Step [350/350], Avg Loss: 1.1298, Avg Dice: 0.3438\n",
            "End of epoch 1: Avg Loss: 1.1298, Avg Dice: 0.3438\n",
            "Epoch [2/50], Step [5/350], Avg Loss: 1.0355, Avg Dice: 0.2989\n",
            "Epoch [2/50], Step [10/350], Avg Loss: 1.0435, Avg Dice: 0.3306\n",
            "Epoch [2/50], Step [15/350], Avg Loss: 1.0353, Avg Dice: 0.3338\n",
            "Epoch [2/50], Step [20/350], Avg Loss: 1.0502, Avg Dice: 0.3384\n",
            "Epoch [2/50], Step [25/350], Avg Loss: 1.0665, Avg Dice: 0.3429\n",
            "Epoch [2/50], Step [30/350], Avg Loss: 1.0586, Avg Dice: 0.3491\n",
            "Epoch [2/50], Step [35/350], Avg Loss: 1.0561, Avg Dice: 0.3554\n",
            "Epoch [2/50], Step [40/350], Avg Loss: 1.0567, Avg Dice: 0.3603\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-627a65032b30>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mseg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseg_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH6GOrtXf1Kh",
        "outputId": "7d96d3c4-741e-4408-e6ea-30eb9741e6ba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 3, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z1bS60mXlPRo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}